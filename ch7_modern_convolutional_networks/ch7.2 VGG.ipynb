{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "polished-structure",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing a vgg block\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def vgg_block(num_convs, in_channels, out_channels):\n",
    "    layers = []\n",
    "    for _ in range(num_convs):\n",
    "        layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        layers.append(nn.ReLU())\n",
    "        in_channels=out_channels\n",
    "    layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ethical-publication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing VGG11\n",
    "\n",
    "conv_arch = ((1,64), (1,128), (2,256), (2,512), (2,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "surrounded-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg(conv_arch):\n",
    "    conv_blks = []\n",
    "    in_channels = 1\n",
    "    \n",
    "    for (num_convs, out_channels) in conv_arch:\n",
    "        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))\n",
    "        in_channels=out_channels\n",
    "    \n",
    "    return nn.Sequential(\n",
    "        *conv_blks, nn.Flatten(), \n",
    "        nn.Linear(in_channels *7 *7, 4096), nn.ReLU(), nn.Dropout(p=0.5), \n",
    "        nn.Linear(4096, 4096),nn.ReLU(), nn.Dropout(p=0.5),\n",
    "        nn.Linear(4096, 10)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "conservative-disorder",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_net = vgg(conv_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "powerful-veteran",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Sequential: torch.Size([1, 64, 112, 112])\n",
      "For Sequential: torch.Size([1, 128, 56, 56])\n",
      "For Sequential: torch.Size([1, 256, 28, 28])\n",
      "For Sequential: torch.Size([1, 512, 14, 14])\n",
      "For Sequential: torch.Size([1, 512, 7, 7])\n",
      "For Flatten: torch.Size([1, 25088])\n",
      "For Linear: torch.Size([1, 4096])\n",
      "For ReLU: torch.Size([1, 4096])\n",
      "For Dropout: torch.Size([1, 4096])\n",
      "For Linear: torch.Size([1, 4096])\n",
      "For ReLU: torch.Size([1, 4096])\n",
      "For Dropout: torch.Size([1, 4096])\n",
      "For Linear: torch.Size([1, 10])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "z:\\installs\\anconda\\envs\\myenv\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(1,1,224,224)\n",
    "\n",
    "def look_at_net(net, X):\n",
    "    out = X\n",
    "    for layer in net:\n",
    "        out = layer(out)\n",
    "        print(f'For {layer.__class__.__name__}: {out.shape}')\n",
    "        \n",
    "look_at_net(vgg_net, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "chief-western",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Sequential: torch.Size([1, 16, 112, 112])\n",
      "For Sequential: torch.Size([1, 32, 56, 56])\n",
      "For Sequential: torch.Size([1, 64, 28, 28])\n",
      "For Sequential: torch.Size([1, 128, 14, 14])\n",
      "For Sequential: torch.Size([1, 128, 7, 7])\n",
      "For Flatten: torch.Size([1, 6272])\n",
      "For Linear: torch.Size([1, 4096])\n",
      "For ReLU: torch.Size([1, 4096])\n",
      "For Dropout: torch.Size([1, 4096])\n",
      "For Linear: torch.Size([1, 4096])\n",
      "For ReLU: torch.Size([1, 4096])\n",
      "For Dropout: torch.Size([1, 4096])\n",
      "For Linear: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# we reduce the ratio as it is very computationaly expensive to traina VGG model\n",
    "ratio = 4\n",
    "small_conv_arch = [(pair[0], pair[1]//ratio) for pair in conv_arch]\n",
    "net = vgg(small_conv_arch)\n",
    "\n",
    "look_at_net(net, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aerial-theory",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs, batch_size = 0.01, 20, 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "executive-catalyst",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "\n",
    "my_transforms = transforms.Compose(\n",
    "                [\n",
    "                    transforms.Resize(224),\n",
    "                    transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(download=False,root=\"../data\", train=True, transform=my_transforms)\n",
    "test_dataset = datasets.FashionMNIST(download=False, root=\"../data\", train=False, transform=my_transforms)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "protecting-atmosphere",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "conscious-sheep",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat,y):\n",
    "    return (y_hat.argmax(1)==y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "talented-scott",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "affiliated-stockholm",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_accuracy(net, data_iter):\n",
    "    net.eval()\n",
    "#     device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    net = net.to(device)\n",
    "    \n",
    "    total_acc = 0\n",
    "    total_num = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_hat = net(X)\n",
    "\n",
    "            total_acc += accuracy(y_hat, y)\n",
    "            total_num += y.numel()\n",
    "    \n",
    "    return total_acc/total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "superior-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net):\n",
    "    \n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "\n",
    "    net= net.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        acc_value = 0\n",
    "        total_number = 0\n",
    "        total_loss= 0\n",
    "        for i, data in enumerate(train_dataloader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            acc_value += accuracy(outputs, labels)\n",
    "            total_number += labels.numel()\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            print(f\"\\tEpoch {epoch} : Statistics: \")\n",
    "            print(f'\\tcurrent train loss : {total_loss} / {total_number} : {float(total_loss/total_number)}')\n",
    "            print(f'\\tcurrent train acc : {acc_value}/{total_number} : {float(acc_value/total_number)}')\n",
    "            print(f'\\tcurrent test acc : {float(full_accuracy(net, test_dataloader))}')\n",
    "\n",
    "\n",
    "            train_loss.append(float(total_loss/total_number))\n",
    "            test_acc.append(float(full_accuracy(net, test_dataloader)))\n",
    "            train_acc.append(float(acc_value/total_number))\n",
    "    \n",
    "    return train_loss, test_acc, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "harmful-armenia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 224, 224]) 128\n",
      "For Sequential: torch.Size([128, 16, 112, 112])\n",
      "For Sequential: torch.Size([128, 32, 56, 56])\n",
      "For Sequential: torch.Size([128, 64, 28, 28])\n",
      "For Sequential: torch.Size([128, 128, 14, 14])\n",
      "For Sequential: torch.Size([128, 128, 7, 7])\n",
      "For Flatten: torch.Size([128, 6272])\n",
      "For Linear: torch.Size([128, 4096])\n",
      "For ReLU: torch.Size([128, 4096])\n",
      "For Dropout: torch.Size([128, 4096])\n",
      "For Linear: torch.Size([128, 4096])\n",
      "For ReLU: torch.Size([128, 4096])\n",
      "For Dropout: torch.Size([128, 4096])\n",
      "For Linear: torch.Size([128, 10])\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_dataloader:\n",
    "    print(X.shape, len(y))\n",
    "    look_at_net(net.to(device), X.to(device).float())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "settled-answer",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 4.00 GiB total capacity; 2.69 GiB already allocated; 15.23 MiB free; 2.70 GiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    train_loss, test_acc, train_acc = train_net(net)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "determined-paintball",
   "metadata": {},
   "outputs": [],
   "source": [
    "# its difficult to train so\n",
    "# 1. lets reduce the image size\n",
    "# 2. and also create a smaller architecture\n",
    "my_transforms = transforms.Compose(\n",
    "                [\n",
    "#                     transforms.Resize(224),\n",
    "                    transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(download=False,root=\"../data\", train=True, transform=my_transforms)\n",
    "test_dataset = datasets.FashionMNIST(download=False, root=\"../data\", train=False, transform=my_transforms)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "practical-maintenance",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So it is difficult to run this lets reduce the model even further\n",
    "\n",
    "new_conv_arch = ((1,64), (1, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "reserved-pharmacology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_reduced(conv_arch):\n",
    "    conv_blks = []\n",
    "    in_channels = 1\n",
    "    \n",
    "    for (num_convs, out_channels) in conv_arch:\n",
    "        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))\n",
    "        in_channels=out_channels\n",
    "    \n",
    "    return nn.Sequential(\n",
    "        *conv_blks, nn.Flatten(), \n",
    "        nn.Linear(in_channels *7 *7, 4096), nn.ReLU(), nn.Dropout(p=0.5), \n",
    "        nn.Linear(4096, 10)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "verbal-natural",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Sequential: torch.Size([1, 64, 14, 14])\n",
      "For Sequential: torch.Size([1, 128, 7, 7])\n",
      "For Flatten: torch.Size([1, 6272])\n",
      "For Linear: torch.Size([1, 4096])\n",
      "For ReLU: torch.Size([1, 4096])\n",
      "For Dropout: torch.Size([1, 4096])\n",
      "For Linear: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(1,1,28,28)\n",
    "\n",
    "net = vgg_reduced(new_conv_arch)\n",
    "\n",
    "look_at_net(net, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "organic-australia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tEpoch 0 : Statistics: \n",
      "\tcurrent train loss : 1080.7705514431 / 60000 : 0.018012842524051668\n",
      "\tcurrent train acc : 5062/60000 : 0.08436666429042816\n",
      "\tcurrent test acc : 0.04519999772310257\n",
      "\tEpoch 1 : Statistics: \n",
      "\tcurrent train loss : 1080.732993364334 / 60000 : 0.018012216556072234\n",
      "\tcurrent train acc : 2688/60000 : 0.04480000212788582\n",
      "\tcurrent test acc : 0.04519999772310257\n",
      "\tEpoch 2 : Statistics: \n",
      "\tcurrent train loss : 1080.7324757575989 / 60000 : 0.018012207929293315\n",
      "\tcurrent train acc : 2688/60000 : 0.04480000212788582\n",
      "\tcurrent test acc : 0.04519999772310257\n",
      "\tEpoch 3 : Statistics: \n",
      "\tcurrent train loss : 1080.7336893081665 / 60000 : 0.018012228155136107\n",
      "\tcurrent train acc : 2688/60000 : 0.04480000212788582\n",
      "\tcurrent test acc : 0.04519999772310257\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    lr = 0.1\n",
    "    num_epochs=4\n",
    "    train_loss, test_acc, train_acc = train_net(net)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "pregnant-cooper",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"finished\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "num_epochs = num_epochs\n",
    "plt.plot(range(num_epochs), train_loss, label='train loss')\n",
    "plt.plot(range(num_epochs), train_acc, label = 'train acc')\n",
    "plt.plot(range(num_epochs), test_acc, label = 'test acc')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bulgarian-appointment",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torchvision\n",
    "\n",
    "# Suppose you are trying to load pre-trained resnet model in directory- models\\resnet\n",
    "\n",
    "os.environ['TORCH_HOME'] = '../models' #setting the environment variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ranging-syndication",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to ../models\\hub\\checkpoints\\vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83708d65d7c94cf3bb5850aa6bf52e57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/528M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-bd19cf8dd45d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mresnet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mz:\\installs\\anconda\\envs\\myenv\\lib\\site-packages\\torchvision\\models\\vgg.py\u001b[0m in \u001b[0;36mvgg16\u001b[1;34m(pretrained, **kwargs)\u001b[0m\n\u001b[0;32m    150\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVGG\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmake_layers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'D'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mpretrained\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 152\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_zoo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_urls\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'vgg16'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    153\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mz:\\installs\\anconda\\envs\\myenv\\lib\\site-packages\\torch\\hub.py\u001b[0m in \u001b[0;36mload_state_dict_from_url\u001b[1;34m(url, model_dir, map_location, progress, check_hash, file_name)\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[0mr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mHASH_REGEX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# r is Optional[Match[str]]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhash_prefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m         \u001b[0mdownload_url_to_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcached_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhash_prefix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprogress\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprogress\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_legacy_zip_format\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcached_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mz:\\installs\\anconda\\envs\\myenv\\lib\\site-packages\\torch\\hub.py\u001b[0m in \u001b[0;36mdownload_url_to_file\u001b[1;34m(url, dst, hash_prefix, progress)\u001b[0m\n\u001b[0;32m    439\u001b[0m                   unit='B', unit_scale=True, unit_divisor=1024) as pbar:\n\u001b[0;32m    440\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m                 \u001b[0mbuffer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mu\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m8192\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m                     \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mz:\\installs\\anconda\\envs\\myenv\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    453\u001b[0m             \u001b[1;31m# Amount is given, implement using readinto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 455\u001b[1;33m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    456\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    457\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mz:\\installs\\anconda\\envs\\myenv\\lib\\http\\client.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    497\u001b[0m         \u001b[1;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 499\u001b[1;33m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    500\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    501\u001b[0m             \u001b[1;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mz:\\installs\\anconda\\envs\\myenv\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mz:\\installs\\anconda\\envs\\myenv\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1239\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1241\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1242\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mz:\\installs\\anconda\\envs\\myenv\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1100\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "heavy-france",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to C:\\Users\\msi1/.cache\\torch\\hub\\checkpoints\\vgg16-397923af.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d28b314a821049e1ab79eada2f3321c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/528M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "'VGG' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-3c2c708b9b5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mvgg_predefined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvgg16\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mvgg_predefined\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'features'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m# = nn.Conv2d(1, 64, kernel_size=(3,3), stride=(1,1), padding=(1,1))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# vgg_predefined\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'VGG' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "vgg_predefined = models.vgg16(pretrained=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "assigned-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    lr = 0.05\n",
    "    num_epochs=4\n",
    "    train_loss, test_acc, train_acc = train_net(vgg_predefined)\n",
    "except Exception as e:\n",
    "    print(e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "complex-explanation",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "1. When printing out the dimensions of the layers we only saw 8 results rather than 11. Where\n",
    "did the remaining 3 layer information go?\n",
    "\n",
    "* in maxpool\n",
    "\n",
    "2. Compared with AlexNet, VGG is much slower in terms of computation, and it also needs\n",
    "more GPU memory. Analyze the reasons for this.\n",
    "\n",
    "* it has more conv layers\n",
    "\n",
    "3. Try changing the height and width of the images in Fashion-MNIST from 224 to 96. What\n",
    "influence does this have on the experiments?\n",
    "\n",
    "* it willrun faster\n",
    "\n",
    "4. Refer to Table 1 in the VGG paper (Simonyan & Zisserman, 2014) to construct other common\n",
    "models, such as VGG-16 or VGG-19.\n",
    "\n",
    "* it can be done but my GPU says hi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
