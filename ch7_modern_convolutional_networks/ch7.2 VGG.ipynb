{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "controversial-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing a vgg block\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def vgg_block(num_convs, in_channels, out_channels):\n",
    "    layers = []\n",
    "    for _ in range(num_convs):\n",
    "        layers.append(nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1))\n",
    "        layers.append(nn.ReLU())\n",
    "        in_channels=out_channels\n",
    "    layers.append(nn.MaxPool2d(kernel_size=2, stride=2))\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "democratic-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementing VGG11\n",
    "\n",
    "conv_arch = ((1,64), (1,128), (2,256), (2,512), (2,512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "useful-lyric",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg(conv_arch):\n",
    "    conv_blks = []\n",
    "    in_channels = 1\n",
    "    \n",
    "    for (num_convs, out_channels) in conv_arch:\n",
    "        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))\n",
    "        in_channels=out_channels\n",
    "    \n",
    "    return nn.Sequential(\n",
    "        *conv_blks, nn.Flatten(), \n",
    "        nn.Linear(in_channels *7 *7, 4096), nn.ReLU(), nn.Dropout(p=0.5), \n",
    "        nn.Linear(4096, 4096),nn.ReLU(), nn.Dropout(p=0.5),\n",
    "        nn.Linear(4096, 10)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cordless-solid",
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_net = vgg(conv_arch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "engaged-panel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Sequential: torch.Size([1, 64, 112, 112])\n",
      "For Sequential: torch.Size([1, 128, 56, 56])\n",
      "For Sequential: torch.Size([1, 256, 28, 28])\n",
      "For Sequential: torch.Size([1, 512, 14, 14])\n",
      "For Sequential: torch.Size([1, 512, 7, 7])\n",
      "For Flatten: torch.Size([1, 25088])\n",
      "For Linear: torch.Size([1, 4096])\n",
      "For ReLU: torch.Size([1, 4096])\n",
      "For Dropout: torch.Size([1, 4096])\n",
      "For Linear: torch.Size([1, 4096])\n",
      "For ReLU: torch.Size([1, 4096])\n",
      "For Dropout: torch.Size([1, 4096])\n",
      "For Linear: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(1,1,224,224)\n",
    "\n",
    "def look_at_net(net, X):\n",
    "    out = X\n",
    "    for layer in net:\n",
    "        out = layer(out)\n",
    "        print(f'For {layer.__class__.__name__}: {out.shape}')\n",
    "        \n",
    "look_at_net(vgg_net, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "alive-christopher",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Sequential: torch.Size([1, 16, 112, 112])\n",
      "For Sequential: torch.Size([1, 32, 56, 56])\n",
      "For Sequential: torch.Size([1, 64, 28, 28])\n",
      "For Sequential: torch.Size([1, 128, 14, 14])\n",
      "For Sequential: torch.Size([1, 128, 7, 7])\n",
      "For Flatten: torch.Size([1, 6272])\n",
      "For Linear: torch.Size([1, 4096])\n",
      "For ReLU: torch.Size([1, 4096])\n",
      "For Dropout: torch.Size([1, 4096])\n",
      "For Linear: torch.Size([1, 4096])\n",
      "For ReLU: torch.Size([1, 4096])\n",
      "For Dropout: torch.Size([1, 4096])\n",
      "For Linear: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "# we reduce the ratio as it is very computationaly expensive to traina VGG model\n",
    "ratio = 4\n",
    "small_conv_arch = [(pair[0], pair[1]//ratio) for pair in conv_arch]\n",
    "net = vgg(small_conv_arch)\n",
    "\n",
    "look_at_net(net, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "subjective-consumer",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs, batch_size = 0.001, 20, 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "rapid-columbia",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "\n",
    "my_transforms = transforms.Compose(\n",
    "                [\n",
    "                    transforms.Resize(224),\n",
    "                    transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(download=False,root=\"../data\", train=True, transform=my_transforms)\n",
    "test_dataset = datasets.FashionMNIST(download=False, root=\"../data\", train=False, transform=my_transforms)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "positive-journal",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr = lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eleven-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat,y):\n",
    "    return (y_hat.argmax(1)==y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "narrative-application",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "supported-visit",
   "metadata": {},
   "outputs": [],
   "source": [
    "def full_accuracy(net, data_iter):\n",
    "    net.eval()\n",
    "#     device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    net = net.to(device)\n",
    "    \n",
    "    total_acc = 0\n",
    "    total_num = 0\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_iter:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            y_hat = net(X)\n",
    "\n",
    "            total_acc += accuracy(y_hat, y)\n",
    "            total_num += y.numel()\n",
    "    \n",
    "    return total_acc/total_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "heard-cement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(net):\n",
    "    \n",
    "    train_loss = []\n",
    "    train_acc = []\n",
    "    test_acc = []\n",
    "\n",
    "    net= net.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        acc_value = 0\n",
    "        total_number = 0\n",
    "        total_loss= 0\n",
    "        for i, data in enumerate(train_dataloader):\n",
    "            inputs, labels = data\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            acc_value += accuracy(outputs, labels)\n",
    "            total_number += labels.numel()\n",
    "\n",
    "        with torch.no_grad():\n",
    "\n",
    "            print(f\"\\tEpoch {epoch} : Statistics: \")\n",
    "            print(f'\\tcurrent train loss : {float(total_loss/total_number)}')\n",
    "            print(f'\\tcurrent train acc : {float(acc_value/total_number)}')\n",
    "            print(f'\\tcurrent test acc : {float(full_accuracy(net, test_dataloader))}')\n",
    "\n",
    "\n",
    "            train_loss.append(float(total_loss/total_number))\n",
    "            test_acc.append(float(full_accuracy(net, test_dataloader)))\n",
    "            train_acc.append(float(acc_value/total_number))\n",
    "    \n",
    "    return train_loss, test_acc, train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "rural-swiss",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 224, 224]) 128\n",
      "For Sequential: torch.Size([128, 16, 112, 112])\n",
      "For Sequential: torch.Size([128, 32, 56, 56])\n",
      "For Sequential: torch.Size([128, 64, 28, 28])\n",
      "For Sequential: torch.Size([128, 128, 14, 14])\n",
      "For Sequential: torch.Size([128, 128, 7, 7])\n",
      "For Flatten: torch.Size([128, 6272])\n",
      "For Linear: torch.Size([128, 4096])\n",
      "For ReLU: torch.Size([128, 4096])\n",
      "For Dropout: torch.Size([128, 4096])\n",
      "For Linear: torch.Size([128, 4096])\n",
      "For ReLU: torch.Size([128, 4096])\n",
      "For Dropout: torch.Size([128, 4096])\n",
      "For Linear: torch.Size([128, 10])\n"
     ]
    }
   ],
   "source": [
    "for X, y in train_dataloader:\n",
    "    print(X.shape, len(y))\n",
    "    look_at_net(net.to(device), X.to(device).float())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "massive-replacement",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA out of memory. Tried to allocate 50.00 MiB (GPU 0; 4.00 GiB total capacity; 2.64 GiB already allocated; 45.23 MiB free; 2.67 GiB reserved in total by PyTorch)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    train_loss, test_acc, train_acc = train_net(net)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "acoustic-electronics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# its difficult to train so\n",
    "# 1. lets reduce the image size\n",
    "# 2. and also create a smaller architecture\n",
    "my_transforms = transforms.Compose(\n",
    "                [\n",
    "#                     transforms.Resize(224),\n",
    "                    transforms.ToTensor()]\n",
    ")\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(download=False,root=\"../data\", train=True, transform=my_transforms)\n",
    "test_dataset = datasets.FashionMNIST(download=False, root=\"../data\", train=False, transform=my_transforms)\n",
    "\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "civic-packet",
   "metadata": {},
   "outputs": [],
   "source": [
    "# So it is difficult to run this lets reduce the model even further\n",
    "\n",
    "new_conv_arch = ((1,64), (1, 128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "purple-anthropology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg_reduced(conv_arch):\n",
    "    conv_blks = []\n",
    "    in_channels = 1\n",
    "    \n",
    "    for (num_convs, out_channels) in conv_arch:\n",
    "        conv_blks.append(vgg_block(num_convs, in_channels, out_channels))\n",
    "        in_channels=out_channels\n",
    "    \n",
    "    return nn.Sequential(\n",
    "        *conv_blks, nn.Flatten(), \n",
    "        nn.Linear(in_channels *7 *7, 4096), nn.ReLU(), nn.Dropout(p=0.5), \n",
    "        nn.Linear(4096, 10)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "weird-prescription",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For Sequential: torch.Size([1, 64, 14, 14])\n",
      "For Sequential: torch.Size([1, 128, 7, 7])\n",
      "For Flatten: torch.Size([1, 6272])\n",
      "For Linear: torch.Size([1, 4096])\n",
      "For ReLU: torch.Size([1, 4096])\n",
      "For Dropout: torch.Size([1, 4096])\n",
      "For Linear: torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "X = torch.randn(1,1,28,28)\n",
    "\n",
    "net = vgg_reduced(new_conv_arch)\n",
    "\n",
    "look_at_net(net, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_loss, test_acc, train_acc = train_net(net)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "limiting-andrews",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"finished\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "num_epochs = num_epochs\n",
    "plt.plot(range(num_epochs), train_loss, label='train loss')\n",
    "plt.plot(range(num_epochs), train_acc, label = 'train acc')\n",
    "plt.plot(range(num_epochs), test_acc, label = 'test acc')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
