{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from d2l import torch as d2l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(input_channels, num_channels):\n",
    "    return nn.Sequential(nn.BatchNorm2d(input_channels), nn.ReLU(),\n",
    "                         nn.Conv2d(input_channels, num_channels,kernel_size=3, padding=1))\n",
    "                         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dense_block(nn.Module):\n",
    "    def __init__(self, num_convs, input_channels, num_channels):\n",
    "        super(dense_block, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(num_convs):\n",
    "            layers.append(conv_block(input_channels + num_channels* i, num_channels))\n",
    "        \n",
    "        self.net = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for layer in self.net:\n",
    "            y = layer(X)\n",
    "            X = torch.cat((X,y), dim=1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 23, 8, 8])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = dense_block(2, 3, 10)\n",
    "\n",
    "X = torch.randn(4,3,8,8)\n",
    "\n",
    "y = blk(X)\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transition_block(input_channels, num_channels):\n",
    "    return nn.Sequential(\n",
    "        nn.BatchNorm2d(input_channels), nn.ReLU(),\n",
    "        nn.Conv2d(input_channels, num_channels, kernel_size=1),\n",
    "        nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 10, 4, 4])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blk = transition_block(23,10)\n",
    "blk(y).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating Densenet\n",
    "\n",
    "b1 = nn.Sequential(nn.Conv2d(1,64, kernel_size=7, stride=2, padding=3),\n",
    "                   nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2, padding=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_channels = 64\n",
    "growth_rate = 32\n",
    "\n",
    "num_of_convs_in_dense_blocks = [4,4,4,4]\n",
    "\n",
    "blks = []\n",
    "\n",
    "for i, num_convs in enumerate(num_of_convs_in_dense_blocks):\n",
    "    blks.append(dense_block(num_convs, num_channels, growth_rate))\n",
    "    num_channels += num_convs * growth_rate\n",
    "    if i != len(num_of_convs_in_dense_blocks) - 1:\n",
    "        blks.append(transition_block(num_channels, num_channels//2))\n",
    "        num_channels = num_channels // 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "net= nn.Sequential(b1, *blks, nn.BatchNorm2d(num_channels),nn.ReLU(),\n",
    "                   nn.AdaptiveMaxPool2d((1,1)), nn.Flatten(), nn.Linear(num_channels, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr, num_epochs, batch_size = 0.1, 10, 256\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size, resize=96)\n",
    "#d2l.train_ch6(net, train_iter, test_iter, num_epochs, lr, d2l.try_gpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "z:\\installs\\anconda\\envs\\myenv\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 48, 48]           3,200\n",
      "       BatchNorm2d-2           [-1, 64, 48, 48]             128\n",
      "              ReLU-3           [-1, 64, 48, 48]               0\n",
      "         MaxPool2d-4           [-1, 64, 24, 24]               0\n",
      "       BatchNorm2d-5           [-1, 64, 24, 24]             128\n",
      "              ReLU-6           [-1, 64, 24, 24]               0\n",
      "            Conv2d-7           [-1, 32, 24, 24]          18,464\n",
      "       BatchNorm2d-8           [-1, 96, 24, 24]             192\n",
      "              ReLU-9           [-1, 96, 24, 24]               0\n",
      "           Conv2d-10           [-1, 32, 24, 24]          27,680\n",
      "      BatchNorm2d-11          [-1, 128, 24, 24]             256\n",
      "             ReLU-12          [-1, 128, 24, 24]               0\n",
      "           Conv2d-13           [-1, 32, 24, 24]          36,896\n",
      "      BatchNorm2d-14          [-1, 160, 24, 24]             320\n",
      "             ReLU-15          [-1, 160, 24, 24]               0\n",
      "           Conv2d-16           [-1, 32, 24, 24]          46,112\n",
      "      dense_block-17          [-1, 192, 24, 24]               0\n",
      "      BatchNorm2d-18          [-1, 192, 24, 24]             384\n",
      "             ReLU-19          [-1, 192, 24, 24]               0\n",
      "           Conv2d-20           [-1, 96, 24, 24]          18,528\n",
      "        AvgPool2d-21           [-1, 96, 12, 12]               0\n",
      "      BatchNorm2d-22           [-1, 96, 12, 12]             192\n",
      "             ReLU-23           [-1, 96, 12, 12]               0\n",
      "           Conv2d-24           [-1, 32, 12, 12]          27,680\n",
      "      BatchNorm2d-25          [-1, 128, 12, 12]             256\n",
      "             ReLU-26          [-1, 128, 12, 12]               0\n",
      "           Conv2d-27           [-1, 32, 12, 12]          36,896\n",
      "      BatchNorm2d-28          [-1, 160, 12, 12]             320\n",
      "             ReLU-29          [-1, 160, 12, 12]               0\n",
      "           Conv2d-30           [-1, 32, 12, 12]          46,112\n",
      "      BatchNorm2d-31          [-1, 192, 12, 12]             384\n",
      "             ReLU-32          [-1, 192, 12, 12]               0\n",
      "           Conv2d-33           [-1, 32, 12, 12]          55,328\n",
      "      dense_block-34          [-1, 224, 12, 12]               0\n",
      "      BatchNorm2d-35          [-1, 224, 12, 12]             448\n",
      "             ReLU-36          [-1, 224, 12, 12]               0\n",
      "           Conv2d-37          [-1, 112, 12, 12]          25,200\n",
      "        AvgPool2d-38            [-1, 112, 6, 6]               0\n",
      "      BatchNorm2d-39            [-1, 112, 6, 6]             224\n",
      "             ReLU-40            [-1, 112, 6, 6]               0\n",
      "           Conv2d-41             [-1, 32, 6, 6]          32,288\n",
      "      BatchNorm2d-42            [-1, 144, 6, 6]             288\n",
      "             ReLU-43            [-1, 144, 6, 6]               0\n",
      "           Conv2d-44             [-1, 32, 6, 6]          41,504\n",
      "      BatchNorm2d-45            [-1, 176, 6, 6]             352\n",
      "             ReLU-46            [-1, 176, 6, 6]               0\n",
      "           Conv2d-47             [-1, 32, 6, 6]          50,720\n",
      "      BatchNorm2d-48            [-1, 208, 6, 6]             416\n",
      "             ReLU-49            [-1, 208, 6, 6]               0\n",
      "           Conv2d-50             [-1, 32, 6, 6]          59,936\n",
      "      dense_block-51            [-1, 240, 6, 6]               0\n",
      "      BatchNorm2d-52            [-1, 240, 6, 6]             480\n",
      "             ReLU-53            [-1, 240, 6, 6]               0\n",
      "           Conv2d-54            [-1, 120, 6, 6]          28,920\n",
      "        AvgPool2d-55            [-1, 120, 3, 3]               0\n",
      "      BatchNorm2d-56            [-1, 120, 3, 3]             240\n",
      "             ReLU-57            [-1, 120, 3, 3]               0\n",
      "           Conv2d-58             [-1, 32, 3, 3]          34,592\n",
      "      BatchNorm2d-59            [-1, 152, 3, 3]             304\n",
      "             ReLU-60            [-1, 152, 3, 3]               0\n",
      "           Conv2d-61             [-1, 32, 3, 3]          43,808\n",
      "      BatchNorm2d-62            [-1, 184, 3, 3]             368\n",
      "             ReLU-63            [-1, 184, 3, 3]               0\n",
      "           Conv2d-64             [-1, 32, 3, 3]          53,024\n",
      "      BatchNorm2d-65            [-1, 216, 3, 3]             432\n",
      "             ReLU-66            [-1, 216, 3, 3]               0\n",
      "           Conv2d-67             [-1, 32, 3, 3]          62,240\n",
      "      dense_block-68            [-1, 248, 3, 3]               0\n",
      "      BatchNorm2d-69            [-1, 248, 3, 3]             496\n",
      "             ReLU-70            [-1, 248, 3, 3]               0\n",
      "AdaptiveMaxPool2d-71            [-1, 248, 1, 1]               0\n",
      "          Flatten-72                  [-1, 248]               0\n",
      "           Linear-73                   [-1, 10]           2,490\n",
      "================================================================\n",
      "Total params: 758,226\n",
      "Trainable params: 758,226\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.04\n",
      "Forward/backward pass size (MB): 14.29\n",
      "Params size (MB): 2.89\n",
      "Estimated Total Size (MB): 17.22\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from torchsummary import summary\n",
    "\n",
    "summary(net.to(torch.device('cuda')), (1,96,96))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "1. Why do we use average pooling rather than maximum pooling in the transition layer?\n",
    "- so that theother cells may not be eliminated and have some value addition in the model\n",
    "\n",
    "2. One of the advantages mentioned in the DenseNet paper is that its model parameters are\n",
    "smaller than those of ResNet. Why is this the case?\n",
    "- because of less number of linear layers, more memory is utilised instead disk space( I am ssuming because of the follow up question given below)\n",
    "\n",
    "```\n",
    "Total params: 758,226\n",
    "Trainable params: 758,226\n",
    "Non-trainable params: 0\n",
    "----------------------------------------------------------------\n",
    "Input size (MB): 0.04\n",
    "Forward/backward pass size (MB): 14.29\n",
    "Params size (MB): 2.89\n",
    "Estimated Total Size (MB): 17.22\n",
    "```\n",
    "\n",
    "This is the disk space, while the memory used in 3.1 GB.\n",
    "\n",
    "3. One problem for which DenseNet has been criticized is its high memory consumption.\n",
    "    1. Is this really the case? Try to change the input shape to 224 Ã— 224 to see the actual GPU\n",
    "    memory consumption.\n",
    "    - all right weiil have to try\n",
    "    \n",
    "    2. Can you think of an alternative means of reducing the memory consumption? How\n",
    "    would you need to change the framework?\n",
    "    - no Idea\n",
    "4. Implement the various DenseNet versions presented in Table 1 of the DenseNet paper\n",
    "(Huang et al., 2017).\n",
    "\n",
    "- https://arxiv.org/pdf/1608.06993.pdf\n",
    "\n",
    "5. Design an MLP-based model by applying the DenseNet idea. Apply it to the housing price\n",
    "prediction task in Section 4.10.\n",
    "\n",
    "-  This is a task! But how? I am low on motivation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop for densenet\n",
    "\n",
    "def train_net(net, train_dataloader, test_dataloader, n_epochs=10, lr=0.1, batch_size=256,device=torch.device('cuda')):\n",
    "    def init_weights(m):\n",
    "        if type(m)==nn.Linear or type(m)==nn.Conv2d:\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "        \n",
    "    net.apply(init_weights)\n",
    "    print('training on: ', device)\n",
    "    net = net.to(device)\n",
    "    optimizer = torch.optim.SGD(net.parameters(), lr=lr )\n",
    "    loss_criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    def accuracy(y_hat, y):\n",
    "        return (torch.argmax(y_hat, dim=1) == y).sum().float().mean()\n",
    "    \n",
    "    train_acc_arr = []\n",
    "    train_loss_arr = []\n",
    "    test_acc_arr = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        net.train()\n",
    "        train_acc = 0\n",
    "        train_loss = 0\n",
    "        for X, y in train_dataloader:\n",
    "            X = X.to(device)\n",
    "            y = y.to(device)\n",
    "        \n",
    "            y_hat = net(X)\n",
    "            train_acc += accuracy(y_hat, y).item()\n",
    "            #print(train_acc * len(y))\n",
    "            optimizer.zero_grad()\n",
    "            loss = loss_criterion(y_hat, y)\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            #print(train_loss*10, train_acc/10)\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()\n",
    "            \n",
    "        net.eval()\n",
    "        test_acc = 0\n",
    "        with torch.no_grad():\n",
    "            \n",
    "            for X, y in test_dataloader:\n",
    "                X = X.to(device)\n",
    "                y = y.to(device)\n",
    "            \n",
    "                y_hat = net(X)\n",
    "                test_acc += accuracy(y_hat, y).item()\n",
    "        \n",
    "        test_acc_arr.append(test_acc/len(y))\n",
    "                \n",
    "        train_acc_arr.append(train_acc/len(y))\n",
    "        train_loss_arr.append(train_loss/len(y))\n",
    "        \n",
    "        print(f'train_acc, train_loss, test_acc : {}, {train_acc}, {train_loss}')\n",
    "    \n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    plt.plot(train_acc_arr, range(n_epochs))\n",
    "    plt.plot(test_acc_arr, range(n_epochs))\n",
    "    plt.plot(train_loss_arr, range(n_epochs))\n",
    "    plt.show()\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training on:  cuda\n",
      "train_acc, train_loss, test_acc : 7275.0, 46244.0, 169.77538293600082\n",
      "train_acc, train_loss, test_acc : 7978.0, 52591.0, 79.3158895522356\n",
      "train_acc, train_loss, test_acc : 7976.0, 53687.0, 65.82091580331326\n",
      "train_acc, train_loss, test_acc : 8044.0, 54463.0, 58.812214106321335\n",
      "train_acc, train_loss, test_acc : 8838.0, 55063.0, 51.77932734787464\n",
      "train_acc, train_loss, test_acc : 8896.0, 55516.0, 47.68976314365864\n",
      "train_acc, train_loss, test_acc : 9050.0, 55853.0, 43.618239901959896\n",
      "train_acc, train_loss, test_acc : 7752.0, 56192.0, 39.982881247997284\n",
      "train_acc, train_loss, test_acc : 8348.0, 56430.0, 37.777349799871445\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_net(net, train_iter, test_iter, n_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
