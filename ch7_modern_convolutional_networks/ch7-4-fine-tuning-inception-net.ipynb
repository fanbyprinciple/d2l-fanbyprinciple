{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Googlenet/ InceptionNet\n\nThe Inception block is equivalent to a subnetwork with four paths. It extracts information\nin parallel through convolutional layers of different window shapes and maximum pooling\nlayers. 1 × 1 convolutions reduce channel dimensionality on a per-pixel level. Maximum\npooling reduces the resolution.\n\n• GoogLeNet connects multiple well-designed Inception blocks with other layers in series.\nThe ratio of the number of channels assigned in the Inception block is obtained through a\nlarge number of experiments on the ImageNet dataset.\n\n• GoogLeNet, as well as its succeeding versions, was one of the most efficient models on Im\u0002ageNet, providing similar test accuracy with lower computational complexity.","metadata":{}},{"cell_type":"markdown","source":"**Also called GoogleNetv3, a famous ConvNet trained on Imagenet from 2015**\n\n<img src=\"https://pytorch.org/assets/images/inception_v3.png\" alt=\"alt\" width=\"50%\"/>","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.nn import functional as F","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2021-09-05T17:57:09.054886Z","iopub.execute_input":"2021-09-05T17:57:09.055240Z","iopub.status.idle":"2021-09-05T17:57:09.059520Z","shell.execute_reply.started":"2021-09-05T17:57:09.055209Z","shell.execute_reply":"2021-09-05T17:57:09.058508Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"class Inception(nn.Module):\n    def __init__(self,in_channels, c1, c2, c3, c4, debug=False, **kwargs):\n        super(Inception, self).__init__(**kwargs)\n        self.p1_1 = nn.Conv2d(in_channels, c1, kernel_size=1)\n        \n        self.p2_1 = nn.Conv2d(in_channels, c2[0], kernel_size=1)\n        self.p2_2 = nn.Conv2d(c2[0], c2[1], kernel_size=3, padding=1)\n        \n        self.p3_1 = nn.Conv2d(in_channels, c3[0], kernel_size=1)\n        self.p3_2 = nn.Conv2d(c3[0], c3[1], kernel_size=5, padding=2)\n        \n        self.p4_1 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n        self.p4_2 = nn.Conv2d(in_channels, c4, kernel_size=1)\n        \n        self.debug = debug\n        \n    \n    def forward(self, X, ):\n        p1 = F.relu(self.p1_1(X))\n        p2 = F.relu(self.p2_2(F.relu(self.p2_1(X))))\n        p3 = F.relu(self.p3_2(F.relu(self.p3_1(X))))\n        p4 = F.relu(self.p4_2(self.p4_1(X)))\n        if (self.debug):\n            print(p1.shape, p2.shape,p3.shape, p4.shape)\n            \n        return torch.cat((p1,p2,p3,p4), dim=1)","metadata":{"execution":{"iopub.status.busy":"2021-09-05T17:57:09.065450Z","iopub.execute_input":"2021-09-05T17:57:09.066058Z","iopub.status.idle":"2021-09-05T17:57:09.077938Z","shell.execute_reply.started":"2021-09-05T17:57:09.066020Z","shell.execute_reply":"2021-09-05T17:57:09.077120Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"Z = torch.randn(1,1,224,224)\n\nsmall_net = Inception(1, 84, (192, 384), (48, 128), 128, debug=True)\n\nsmall_net(Z).shape","metadata":{"execution":{"iopub.status.busy":"2021-09-05T17:57:09.079339Z","iopub.execute_input":"2021-09-05T17:57:09.079674Z","iopub.status.idle":"2021-09-05T17:57:10.381895Z","shell.execute_reply.started":"2021-09-05T17:57:09.079639Z","shell.execute_reply":"2021-09-05T17:57:10.381128Z"},"trusted":true},"execution_count":34,"outputs":[{"name":"stdout","text":"torch.Size([1, 84, 224, 224]) torch.Size([1, 384, 224, 224]) torch.Size([1, 128, 224, 224]) torch.Size([1, 128, 224, 224])\n","output_type":"stream"},{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"torch.Size([1, 724, 224, 224])"},"metadata":{}}]},{"cell_type":"code","source":"# lets build the network piece by piece\nb1 = nn.Sequential(nn.Conv2d(1, 64, kernel_size=7, stride=2, padding=3),\nnn.ReLU(), nn.MaxPool2d(kernel_size=3, stride=2,\npadding=1))\n","metadata":{"execution":{"iopub.status.busy":"2021-09-05T17:57:10.383837Z","iopub.execute_input":"2021-09-05T17:57:10.384223Z","iopub.status.idle":"2021-09-05T17:57:10.389239Z","shell.execute_reply.started":"2021-09-05T17:57:10.384184Z","shell.execute_reply":"2021-09-05T17:57:10.388392Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"b2 = nn.Sequential(nn.Conv2d(64, 64, kernel_size=1), nn.ReLU(),\nnn.Conv2d(64, 192, kernel_size=3, padding=1), nn.ReLU(),\nnn.MaxPool2d(kernel_size=3, stride=2, padding=1))","metadata":{"execution":{"iopub.status.busy":"2021-09-05T17:57:10.390897Z","iopub.execute_input":"2021-09-05T17:57:10.391470Z","iopub.status.idle":"2021-09-05T17:57:10.400045Z","shell.execute_reply.started":"2021-09-05T17:57:10.391432Z","shell.execute_reply":"2021-09-05T17:57:10.399160Z"},"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"b3 = nn.Sequential(Inception(192,64, (96,128), (16,32), 32),\n                   Inception(256,128, (128,192), (32, 96), 64),\n                   nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n                   ","metadata":{"execution":{"iopub.status.busy":"2021-09-05T17:57:10.401456Z","iopub.execute_input":"2021-09-05T17:57:10.401850Z","iopub.status.idle":"2021-09-05T17:57:10.415161Z","shell.execute_reply.started":"2021-09-05T17:57:10.401813Z","shell.execute_reply":"2021-09-05T17:57:10.414369Z"},"trusted":true},"execution_count":37,"outputs":[]},{"cell_type":"code","source":"b4 = nn.Sequential(Inception(480, 192, (96, 208), (16, 48), 64),\n                    Inception(512, 160, (112, 224), (24, 64), 64),\n                    Inception(512, 128, (128, 256), (24, 64), 64),\n                    Inception(512, 112, (144, 288), (32, 64), 64),\n                    Inception(528, 256, (160, 320), (32, 128), 128),\n                    nn.MaxPool2d(kernel_size=3, stride=2, padding=1))\n","metadata":{"execution":{"iopub.status.busy":"2021-09-05T17:57:10.416335Z","iopub.execute_input":"2021-09-05T17:57:10.416663Z","iopub.status.idle":"2021-09-05T17:57:10.446752Z","shell.execute_reply.started":"2021-09-05T17:57:10.416630Z","shell.execute_reply":"2021-09-05T17:57:10.446038Z"},"trusted":true},"execution_count":38,"outputs":[]},{"cell_type":"code","source":"b5 = nn.Sequential(Inception(832, 256, (160, 320), (32, 128), 128),\n                    Inception(832, 384, (192, 384), (48, 128), 128),\n                    nn.AdaptiveAvgPool2d((1, 1)), nn.Flatten())\n","metadata":{"execution":{"iopub.status.busy":"2021-09-05T17:57:10.447872Z","iopub.execute_input":"2021-09-05T17:57:10.448231Z","iopub.status.idle":"2021-09-05T17:57:10.472669Z","shell.execute_reply.started":"2021-09-05T17:57:10.448197Z","shell.execute_reply":"2021-09-05T17:57:10.471950Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"net = nn.Sequential(b1, b2, b3, b4, b5, nn.Linear(1024,10))","metadata":{"execution":{"iopub.status.busy":"2021-09-05T17:57:10.473754Z","iopub.execute_input":"2021-09-05T17:57:10.474091Z","iopub.status.idle":"2021-09-05T17:57:10.479071Z","shell.execute_reply.started":"2021-09-05T17:57:10.474059Z","shell.execute_reply":"2021-09-05T17:57:10.477991Z"},"trusted":true},"execution_count":40,"outputs":[]},{"cell_type":"code","source":"net","metadata":{"execution":{"iopub.status.busy":"2021-09-05T17:57:10.482566Z","iopub.execute_input":"2021-09-05T17:57:10.483091Z","iopub.status.idle":"2021-09-05T17:57:10.490772Z","shell.execute_reply.started":"2021-09-05T17:57:10.483055Z","shell.execute_reply":"2021-09-05T17:57:10.489852Z"},"trusted":true},"execution_count":41,"outputs":[{"execution_count":41,"output_type":"execute_result","data":{"text/plain":"Sequential(\n  (0): Sequential(\n    (0): Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3))\n    (1): ReLU()\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  )\n  (1): Sequential(\n    (0): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n    (1): ReLU()\n    (2): Conv2d(64, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n    (3): ReLU()\n    (4): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  )\n  (2): Sequential(\n    (0): Inception(\n      (p1_1): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1))\n      (p2_1): Conv2d(192, 96, kernel_size=(1, 1), stride=(1, 1))\n      (p2_2): Conv2d(96, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (p3_1): Conv2d(192, 16, kernel_size=(1, 1), stride=(1, 1))\n      (p3_2): Conv2d(16, 32, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n      (p4_2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (1): Inception(\n      (p1_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n      (p2_1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n      (p2_2): Conv2d(128, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (p3_1): Conv2d(256, 32, kernel_size=(1, 1), stride=(1, 1))\n      (p3_2): Conv2d(32, 96, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n      (p4_2): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (2): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  )\n  (3): Sequential(\n    (0): Inception(\n      (p1_1): Conv2d(480, 192, kernel_size=(1, 1), stride=(1, 1))\n      (p2_1): Conv2d(480, 96, kernel_size=(1, 1), stride=(1, 1))\n      (p2_2): Conv2d(96, 208, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (p3_1): Conv2d(480, 16, kernel_size=(1, 1), stride=(1, 1))\n      (p3_2): Conv2d(16, 48, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n      (p4_2): Conv2d(480, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (1): Inception(\n      (p1_1): Conv2d(512, 160, kernel_size=(1, 1), stride=(1, 1))\n      (p2_1): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n      (p2_2): Conv2d(112, 224, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (p3_1): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n      (p3_2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n      (p4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (2): Inception(\n      (p1_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n      (p2_1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1))\n      (p2_2): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (p3_1): Conv2d(512, 24, kernel_size=(1, 1), stride=(1, 1))\n      (p3_2): Conv2d(24, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n      (p4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (3): Inception(\n      (p1_1): Conv2d(512, 112, kernel_size=(1, 1), stride=(1, 1))\n      (p2_1): Conv2d(512, 144, kernel_size=(1, 1), stride=(1, 1))\n      (p2_2): Conv2d(144, 288, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (p3_1): Conv2d(512, 32, kernel_size=(1, 1), stride=(1, 1))\n      (p3_2): Conv2d(32, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n      (p4_2): Conv2d(512, 64, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (4): Inception(\n      (p1_1): Conv2d(528, 256, kernel_size=(1, 1), stride=(1, 1))\n      (p2_1): Conv2d(528, 160, kernel_size=(1, 1), stride=(1, 1))\n      (p2_2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (p3_1): Conv2d(528, 32, kernel_size=(1, 1), stride=(1, 1))\n      (p3_2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n      (p4_2): Conv2d(528, 128, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (5): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n  )\n  (4): Sequential(\n    (0): Inception(\n      (p1_1): Conv2d(832, 256, kernel_size=(1, 1), stride=(1, 1))\n      (p2_1): Conv2d(832, 160, kernel_size=(1, 1), stride=(1, 1))\n      (p2_2): Conv2d(160, 320, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (p3_1): Conv2d(832, 32, kernel_size=(1, 1), stride=(1, 1))\n      (p3_2): Conv2d(32, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n      (p4_2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (1): Inception(\n      (p1_1): Conv2d(832, 384, kernel_size=(1, 1), stride=(1, 1))\n      (p2_1): Conv2d(832, 192, kernel_size=(1, 1), stride=(1, 1))\n      (p2_2): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n      (p3_1): Conv2d(832, 48, kernel_size=(1, 1), stride=(1, 1))\n      (p3_2): Conv2d(48, 128, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n      (p4_1): MaxPool2d(kernel_size=3, stride=1, padding=1, dilation=1, ceil_mode=False)\n      (p4_2): Conv2d(832, 128, kernel_size=(1, 1), stride=(1, 1))\n    )\n    (2): AdaptiveAvgPool2d(output_size=(1, 1))\n    (3): Flatten(start_dim=1, end_dim=-1)\n  )\n  (5): Linear(in_features=1024, out_features=10, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"for layer in net:\n    print(layer.__class__.__name__)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-05T17:57:10.492847Z","iopub.execute_input":"2021-09-05T17:57:10.493337Z","iopub.status.idle":"2021-09-05T17:57:10.501531Z","shell.execute_reply.started":"2021-09-05T17:57:10.493301Z","shell.execute_reply":"2021-09-05T17:57:10.500735Z"},"trusted":true},"execution_count":42,"outputs":[{"name":"stdout","text":"Sequential\nSequential\nSequential\nSequential\nSequential\nLinear\n","output_type":"stream"}]},{"cell_type":"code","source":"X = torch.rand(size=(1, 1, 96, 96))\nfor layer in net:\n    X = layer(X)\n    print(layer.__class__.__name__, 'output shape:\\t', X.shape)\n","metadata":{"execution":{"iopub.status.busy":"2021-09-05T17:57:10.502890Z","iopub.execute_input":"2021-09-05T17:57:10.503163Z","iopub.status.idle":"2021-09-05T17:57:10.542020Z","shell.execute_reply.started":"2021-09-05T17:57:10.503131Z","shell.execute_reply":"2021-09-05T17:57:10.541129Z"},"trusted":true},"execution_count":43,"outputs":[{"name":"stdout","text":"Sequential output shape:\t torch.Size([1, 64, 24, 24])\nSequential output shape:\t torch.Size([1, 192, 12, 12])\nSequential output shape:\t torch.Size([1, 480, 6, 6])\nSequential output shape:\t torch.Size([1, 832, 3, 3])\nSequential output shape:\t torch.Size([1, 1024])\nLinear output shape:\t torch.Size([1, 10])\n","output_type":"stream"}]},{"cell_type":"markdown","source":"This being done, we know it impossible (?) to train from scratch so we will use a pretrained model","metadata":{}},{"cell_type":"markdown","source":"# \"Trying\" to train","metadata":{}},{"cell_type":"markdown","source":"We take guidance from here: https://pytorch.org/hub/pytorch_vision_inception_v3/\n\nit says that :\n\n```\nAll pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 299. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225].\n```","metadata":{}},{"cell_type":"code","source":"import torchvision.transforms as transforms\nimport torchvision.datasets as datasets\n\nfrom torch.utils.data import DataLoader\nbatch_size = 128\nmy_transforms = transforms.Compose(\n                [\n                    transforms.Resize(300),\n                    transforms.ToTensor(),\n                    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))]\n)\n\ntrain_dataset = datasets.CIFAR10(download=True,root=\"../data\", train=True, transform=my_transforms)\ntest_dataset = datasets.CIFAR10(download=True, root=\"../data\", train=False, transform=my_transforms)\n\n\ntrain_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\ntest_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-05T17:57:10.543396Z","iopub.execute_input":"2021-09-05T17:57:10.543725Z","iopub.status.idle":"2021-09-05T17:57:12.082147Z","shell.execute_reply.started":"2021-09-05T17:57:10.543691Z","shell.execute_reply":"2021-09-05T17:57:12.081208Z"},"trusted":true},"execution_count":44,"outputs":[{"name":"stdout","text":"Files already downloaded and verified\nFiles already downloaded and verified\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## fine tuning an inception model","metadata":{}},{"cell_type":"markdown","source":"from https://github.com/pytorch/vision/issues/302\n\n@jamiechoi1995 @MichaelLiang12, @TiRune is correct, inception_v3 has an aux branch, and if this is not disabled the forward function will return a tuple (see here), which when passed to the criterion will throw this error.\n\nSo you have two choices:\n\n1. disable aux_logits when the model is created here by also passing aux_logits=False to the inception_v3 function.\n\n2. edit your train function to accept and unpack the returned tuple here to be something like:\n\noutput, aux = model(input_var)","metadata":{}},{"cell_type":"code","source":"import torchvision.models as models","metadata":{"execution":{"iopub.status.busy":"2021-09-05T17:57:12.083535Z","iopub.execute_input":"2021-09-05T17:57:12.083908Z","iopub.status.idle":"2021-09-05T17:57:12.088509Z","shell.execute_reply.started":"2021-09-05T17:57:12.083869Z","shell.execute_reply":"2021-09-05T17:57:12.087348Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"inception = models.inception_v3(aux_logits=False, pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-05T17:57:12.090059Z","iopub.execute_input":"2021-09-05T17:57:12.090443Z","iopub.status.idle":"2021-09-05T17:57:12.388458Z","shell.execute_reply.started":"2021-09-05T17:57:12.090407Z","shell.execute_reply":"2021-09-05T17:57:12.387552Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"inception.fc =  nn.Linear(in_features=2048, out_features=10, bias=True)","metadata":{"execution":{"iopub.status.busy":"2021-09-05T17:57:12.389823Z","iopub.execute_input":"2021-09-05T17:57:12.390186Z","iopub.status.idle":"2021-09-05T17:57:12.394890Z","shell.execute_reply.started":"2021-09-05T17:57:12.390148Z","shell.execute_reply":"2021-09-05T17:57:12.394041Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"# inception.Conv2d_1a_3x3.conv = nn.Conv2d(1, 32, kernel_size=(3,3), stride=(2,2), bias=False)","metadata":{"execution":{"iopub.status.busy":"2021-09-05T17:57:12.396353Z","iopub.execute_input":"2021-09-05T17:57:12.396937Z","iopub.status.idle":"2021-09-05T17:57:12.404495Z","shell.execute_reply.started":"2021-09-05T17:57:12.396871Z","shell.execute_reply":"2021-09-05T17:57:12.403601Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"inception","metadata":{"execution":{"iopub.status.busy":"2021-09-05T17:57:12.405877Z","iopub.execute_input":"2021-09-05T17:57:12.406265Z","iopub.status.idle":"2021-09-05T17:57:12.420893Z","shell.execute_reply.started":"2021-09-05T17:57:12.406232Z","shell.execute_reply":"2021-09-05T17:57:12.420076Z"},"trusted":true},"execution_count":49,"outputs":[{"execution_count":49,"output_type":"execute_result","data":{"text/plain":"Inception3(\n  (Conv2d_1a_3x3): BasicConv2d(\n    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (Conv2d_2a_3x3): BasicConv2d(\n    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (Conv2d_2b_3x3): BasicConv2d(\n    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (maxpool1): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (Conv2d_3b_1x1): BasicConv2d(\n    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (Conv2d_4a_3x3): BasicConv2d(\n    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (maxpool2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n  (Mixed_5b): InceptionA(\n    (branch1x1): BasicConv2d(\n      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch5x5_1): BasicConv2d(\n      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch5x5_2): BasicConv2d(\n      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_1): BasicConv2d(\n      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_2): BasicConv2d(\n      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_3): BasicConv2d(\n      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch_pool): BasicConv2d(\n      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (Mixed_5c): InceptionA(\n    (branch1x1): BasicConv2d(\n      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch5x5_1): BasicConv2d(\n      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch5x5_2): BasicConv2d(\n      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_1): BasicConv2d(\n      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_2): BasicConv2d(\n      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_3): BasicConv2d(\n      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch_pool): BasicConv2d(\n      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (Mixed_5d): InceptionA(\n    (branch1x1): BasicConv2d(\n      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch5x5_1): BasicConv2d(\n      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch5x5_2): BasicConv2d(\n      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_1): BasicConv2d(\n      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_2): BasicConv2d(\n      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_3): BasicConv2d(\n      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch_pool): BasicConv2d(\n      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (Mixed_6a): InceptionB(\n    (branch3x3): BasicConv2d(\n      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_1): BasicConv2d(\n      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_2): BasicConv2d(\n      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_3): BasicConv2d(\n      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (Mixed_6b): InceptionC(\n    (branch1x1): BasicConv2d(\n      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7_1): BasicConv2d(\n      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7_2): BasicConv2d(\n      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7_3): BasicConv2d(\n      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_1): BasicConv2d(\n      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_2): BasicConv2d(\n      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_3): BasicConv2d(\n      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_4): BasicConv2d(\n      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_5): BasicConv2d(\n      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch_pool): BasicConv2d(\n      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (Mixed_6c): InceptionC(\n    (branch1x1): BasicConv2d(\n      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7_1): BasicConv2d(\n      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7_2): BasicConv2d(\n      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7_3): BasicConv2d(\n      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_1): BasicConv2d(\n      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_2): BasicConv2d(\n      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_3): BasicConv2d(\n      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_4): BasicConv2d(\n      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_5): BasicConv2d(\n      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch_pool): BasicConv2d(\n      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (Mixed_6d): InceptionC(\n    (branch1x1): BasicConv2d(\n      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7_1): BasicConv2d(\n      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7_2): BasicConv2d(\n      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7_3): BasicConv2d(\n      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_1): BasicConv2d(\n      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_2): BasicConv2d(\n      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_3): BasicConv2d(\n      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_4): BasicConv2d(\n      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_5): BasicConv2d(\n      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch_pool): BasicConv2d(\n      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (Mixed_6e): InceptionC(\n    (branch1x1): BasicConv2d(\n      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7_1): BasicConv2d(\n      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7_2): BasicConv2d(\n      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7_3): BasicConv2d(\n      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_1): BasicConv2d(\n      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_2): BasicConv2d(\n      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_3): BasicConv2d(\n      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_4): BasicConv2d(\n      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7dbl_5): BasicConv2d(\n      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch_pool): BasicConv2d(\n      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (Mixed_7a): InceptionD(\n    (branch3x3_1): BasicConv2d(\n      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3_2): BasicConv2d(\n      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7x3_1): BasicConv2d(\n      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7x3_2): BasicConv2d(\n      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7x3_3): BasicConv2d(\n      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch7x7x3_4): BasicConv2d(\n      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (Mixed_7b): InceptionE(\n    (branch1x1): BasicConv2d(\n      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3_1): BasicConv2d(\n      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3_2a): BasicConv2d(\n      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3_2b): BasicConv2d(\n      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_1): BasicConv2d(\n      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_2): BasicConv2d(\n      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_3a): BasicConv2d(\n      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_3b): BasicConv2d(\n      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch_pool): BasicConv2d(\n      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (Mixed_7c): InceptionE(\n    (branch1x1): BasicConv2d(\n      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3_1): BasicConv2d(\n      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3_2a): BasicConv2d(\n      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3_2b): BasicConv2d(\n      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_1): BasicConv2d(\n      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_2): BasicConv2d(\n      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_3a): BasicConv2d(\n      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch3x3dbl_3b): BasicConv2d(\n      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n    (branch_pool): BasicConv2d(\n      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n    )\n  )\n  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n  (dropout): Dropout(p=0.5, inplace=False)\n  (fc): Linear(in_features=2048, out_features=10, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"for param in inception.parameters():\n    param.requires_grad = False","metadata":{"execution":{"iopub.status.busy":"2021-09-05T17:57:12.422185Z","iopub.execute_input":"2021-09-05T17:57:12.422499Z","iopub.status.idle":"2021-09-05T17:57:12.430801Z","shell.execute_reply.started":"2021-09-05T17:57:12.422466Z","shell.execute_reply":"2021-09-05T17:57:12.429851Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"for param in inception.fc.parameters():\n    param.requires_grad=True","metadata":{"execution":{"iopub.status.busy":"2021-09-05T17:57:12.432331Z","iopub.execute_input":"2021-09-05T17:57:12.432681Z","iopub.status.idle":"2021-09-05T17:57:12.438894Z","shell.execute_reply.started":"2021-09-05T17:57:12.432645Z","shell.execute_reply":"2021-09-05T17:57:12.438014Z"},"trusted":true},"execution_count":51,"outputs":[]},{"cell_type":"code","source":"# for param in inception.parameters():\n#     print(param.__class__.__name__, \" : \", param.requires_grad)","metadata":{"execution":{"iopub.status.busy":"2021-09-05T17:57:12.440306Z","iopub.execute_input":"2021-09-05T17:57:12.440686Z","iopub.status.idle":"2021-09-05T17:57:12.450472Z","shell.execute_reply.started":"2021-09-05T17:57:12.440649Z","shell.execute_reply":"2021-09-05T17:57:12.449643Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"def accuracy(y_hat,y):\n    return (y_hat.argmax(1)==y).sum()","metadata":{"execution":{"iopub.status.busy":"2021-09-05T17:57:12.451618Z","iopub.execute_input":"2021-09-05T17:57:12.452120Z","iopub.status.idle":"2021-09-05T17:57:12.458807Z","shell.execute_reply.started":"2021-09-05T17:57:12.452063Z","shell.execute_reply":"2021-09-05T17:57:12.458020Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\ndevice","metadata":{"execution":{"iopub.status.busy":"2021-09-05T17:57:12.459876Z","iopub.execute_input":"2021-09-05T17:57:12.460370Z","iopub.status.idle":"2021-09-05T17:57:12.469410Z","shell.execute_reply.started":"2021-09-05T17:57:12.460333Z","shell.execute_reply":"2021-09-05T17:57:12.468356Z"},"trusted":true},"execution_count":54,"outputs":[{"execution_count":54,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"def full_accuracy(net, data_iter):\n    net.eval()\n#     device=torch.device('cuda' if torch.cuda.is_available() else 'cpu'\n    net = net.to(device)\n    \n    total_acc = 0\n    total_num = 0\n    with torch.no_grad():\n        for X, y in data_iter:\n            X = X.to(device)\n            y = y.to(device)\n\n            y_hat = net(X)\n\n            total_acc += accuracy(y_hat, y)\n            total_num += y.numel()\n    \n    return total_acc/total_num","metadata":{"execution":{"iopub.status.busy":"2021-09-05T17:57:12.471762Z","iopub.execute_input":"2021-09-05T17:57:12.472200Z","iopub.status.idle":"2021-09-05T17:57:12.478842Z","shell.execute_reply.started":"2021-09-05T17:57:12.472100Z","shell.execute_reply":"2021-09-05T17:57:12.477975Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"code","source":"def train_net(net):\n    \n    train_loss = []\n    train_acc = []\n    test_acc = []\n\n    net= net.to(device)\n    net.train()\n    for epoch in range(num_epochs):\n\n        acc_value = 0\n        total_number = 0\n        total_loss= 0\n        for i, data in enumerate(train_dataloader):\n            inputs, labels = data\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n\n            optimizer.zero_grad()\n\n            outputs = net(inputs)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n\n            total_loss += loss.item()\n            acc_value += accuracy(outputs, labels)\n            total_number += labels.numel()\n\n        with torch.no_grad():\n\n            print(f\"\\tEpoch {epoch} : Statistics: \")\n            print(f'\\tcurrent train loss : {total_loss} / {total_number} : {float(total_loss/total_number)}')\n            print(f'\\tcurrent train acc : {acc_value}/{total_number} : {float(acc_value/total_number)}')\n            print(f'\\tcurrent test acc : {float(full_accuracy(net, test_dataloader))}')\n\n\n            train_loss.append(float(total_loss/total_number))\n            test_acc.append(float(full_accuracy(net, test_dataloader)))\n            train_acc.append(float(acc_value/total_number))\n    \n    return train_loss, test_acc, train_acc","metadata":{"execution":{"iopub.status.busy":"2021-09-05T17:57:12.480316Z","iopub.execute_input":"2021-09-05T17:57:12.480911Z","iopub.status.idle":"2021-09-05T17:57:12.490935Z","shell.execute_reply.started":"2021-09-05T17:57:12.480872Z","shell.execute_reply":"2021-09-05T17:57:12.490133Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"optimizer = torch.optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\ncriterion = nn.CrossEntropyLoss()","metadata":{"execution":{"iopub.status.busy":"2021-09-05T17:57:12.492182Z","iopub.execute_input":"2021-09-05T17:57:12.492746Z","iopub.status.idle":"2021-09-05T17:57:12.508065Z","shell.execute_reply.started":"2021-09-05T17:57:12.492711Z","shell.execute_reply":"2021-09-05T17:57:12.507349Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"%%time\nnum_epochs=3\ntrain_loss, test_acc, train_acc = train_net(inception)","metadata":{"execution":{"iopub.status.busy":"2021-09-05T17:57:12.509499Z","iopub.execute_input":"2021-09-05T17:57:12.509908Z","iopub.status.idle":"2021-09-05T18:29:38.900685Z","shell.execute_reply.started":"2021-09-05T17:57:12.509871Z","shell.execute_reply":"2021-09-05T18:29:38.899037Z"},"trusted":true},"execution_count":58,"outputs":[{"name":"stdout","text":"\tEpoch 0 : Statistics: \n\tcurrent train loss : 909.6816239356995 / 50000 : 0.01819363247871399\n\tcurrent train acc : 5723/50000 : 0.11445999890565872\n\tcurrent test acc : 0.13130000233650208\n\tEpoch 1 : Statistics: \n\tcurrent train loss : 901.2892100811005 / 50000 : 0.01802578420162201\n\tcurrent train acc : 6459/50000 : 0.12917999923229218\n\tcurrent test acc : 0.13130000233650208\n\tEpoch 2 : Statistics: \n\tcurrent train loss : 901.2962093353271 / 50000 : 0.01802592418670654\n\tcurrent train acc : 6459/50000 : 0.12917999923229218\n\tcurrent test acc : 0.13130000233650208\n\tEpoch 3 : Statistics: \n\tcurrent train loss : 901.2861149311066 / 50000 : 0.01802572229862213\n\tcurrent train acc : 6459/50000 : 0.12917999923229218\n\tcurrent test acc : 0.13130000233650208\n\tEpoch 4 : Statistics: \n\tcurrent train loss : 901.2848615646362 / 50000 : 0.018025697231292725\n\tcurrent train acc : 6459/50000 : 0.12917999923229218\n\tcurrent test acc : 0.13130000233650208\n\tEpoch 5 : Statistics: \n\tcurrent train loss : 901.2907435894012 / 50000 : 0.018025814871788025\n\tcurrent train acc : 6459/50000 : 0.12917999923229218\n\tcurrent test acc : 0.13130000233650208\nCPU times: user 29min 13s, sys: 3min 10s, total: 32min 23s\nWall time: 32min 26s\n","output_type":"stream"}]},{"cell_type":"code","source":"print(\"finished\")\n\nimport matplotlib.pyplot as plt\nnum_epochs = num_epochs\n# plt.plot(range(num_epochs), train_loss, label='train loss')\nplt.plot(range(num_epochs), train_acc, label = 'train acc')\nplt.plot(range(num_epochs), test_acc, label = 'test acc')\nplt.grid(True)\nplt.legend()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2021-09-05T18:29:38.904390Z","iopub.execute_input":"2021-09-05T18:29:38.904669Z","iopub.status.idle":"2021-09-05T18:29:39.075559Z","shell.execute_reply.started":"2021-09-05T18:29:38.904638Z","shell.execute_reply":"2021-09-05T18:29:39.074546Z"},"trusted":true},"execution_count":59,"outputs":[{"name":"stdout","text":"finished\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 432x288 with 1 Axes>","image/png":"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\n"},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":"### Exercises\n\n1. There are several iterations of GoogLeNet. Try to implement and run them. Some of them include the following:\n\n    • Add a batch normalization layer (Ioffe & Szegedy, 2015), as described later in Section 7.5.\n    https://arxiv.org/pdf/1502.03167v2.pdf\n    \n    https://stackoverflow.com/questions/37624279/how-to-properly-add-and-use-batchnormlayer#:~:text=BatchNormLayer%20should%20be%20added%20after%20the%20dense%20or,if%20you%20added%20BatchNormLayer%20after%20or%20convolution%2Fdense%20layer.\n    \n    • Make adjustments to the Inception block (Szegedy et al., 2016).\n    \n    • Use label smoothing for model regularization (Szegedy et al., 2016)\n\n    • Include it in the residual connection (Szegedy et al., 2017), as described later in Section 7.6.\n\n2. What is the minimum image size for GoogLeNet to work?\n\n* I found out that it was around 299. from https://pytorch.org/hub/pytorch_vision_inception_v3/\n\nit says that :\n\n```\nAll pre-trained models expect input images normalized in the same way, i.e. mini-batches of 3-channel RGB images of shape (3 x H x W), where H and W are expected to be at least 299. The images have to be loaded in to a range of [0, 1] and then normalized using mean = [0.485, 0.456, 0.406] and std = [0.229, 0.224, 0.225].\n```\n3. Compare the model parameter sizes of AlexNet, VGG, and NiN with GoogLeNet. How do the\nlatter two network architectures significantly reduce the model parameter size?\n\n* GoogleNet has 22 layer, and almost 12x less parameters (So faster and less then Alexnet and much more accurate).\n* without counting the aux it has 51668 parameters.\n* function to calculate the parameters\n```python\ncounter = 0\n\nfor param in inception.parameters():\n    counter += len(param)\nprint(counter)\n```","metadata":{}},{"cell_type":"code","source":"#3 \n\ncounter = 0\n\nfor param in inception.parameters():\n    counter += len(param)\nprint(counter)\n    ","metadata":{"execution":{"iopub.status.busy":"2021-09-05T18:29:39.077168Z","iopub.execute_input":"2021-09-05T18:29:39.077524Z","iopub.status.idle":"2021-09-05T18:29:39.087073Z","shell.execute_reply.started":"2021-09-05T18:29:39.077487Z","shell.execute_reply":"2021-09-05T18:29:39.086105Z"},"trusted":true},"execution_count":60,"outputs":[{"name":"stdout","text":"51668\n","output_type":"stream"}]}]}