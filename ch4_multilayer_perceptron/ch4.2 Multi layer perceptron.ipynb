{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "african-spanish",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-wednesday",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thermal-kennedy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "interesting-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_transforms = torchvision.transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pointed-netherlands",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.FashionMNIST(root='./data', download=False, train=True, transform=my_transforms)\n",
    "test_dataset = torchvision.datasets.FashionMNIST(root='./data', download=False, train=False, transform=my_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "distinguished-publicity",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = torch.utils.data.DataLoader(train_dataset, shuffle=True, batch_size=batch_size, num_workers=4)\n",
    "test_iter = torch.utils.data.DataLoader(test_dataset, shuffle=False, batch_size=batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pressing-result",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "for X, y in train_iter:\n",
    "    print(y[0])\n",
    "    pic = X[0]\n",
    "    plt.imshow(pic.permute(1,2,0))\n",
    "    break\n",
    "\n",
    "# data loaded\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "polar-tyler",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_fashion_mnist_labels(labels):\n",
    "    label_encoded = [\n",
    "        't-shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt',\n",
    "        'sneaker', 'bag', 'ankle boot']\n",
    "    label_texts = []\n",
    "    for label in labels:\n",
    "        label_texts.append(label_encoded[label])\n",
    "    \n",
    "    return label_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "welsh-movie",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "num_hidden =256\n",
    "\n",
    "W1 = torch.normal(0,1,(num_inputs,num_hidden), requires_grad=True)\n",
    "b1 = torch.zeros(num_hidden, requires_grad=True)\n",
    "\n",
    "W2 = torch.normal(0,1,(num_hidden,num_outputs), requires_grad=True)\n",
    "b2 = torch.zeros(num_outputs, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "boring-blame",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [W1, b1, W2, b2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "generous-journalism",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X):\n",
    "    a = torch.zeros_like(X)\n",
    "    return torch.max(X,a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quiet-albert",
   "metadata": {},
   "outputs": [],
   "source": [
    "def net(X):\n",
    "    X = X.reshape(-1,num_inputs)\n",
    "    H = relu(X @ W1 + b1)\n",
    "    return H @ W2 + b2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smooth-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "normal-metropolitan",
   "metadata": {},
   "outputs": [],
   "source": [
    "updater = torch.optim.SGD(params, lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-arrival",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_hat, y):\n",
    "    return (y_hat.argmax(1)==y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-industry",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "\n",
    "num_epochs = 10\n",
    "train_acc_array = []\n",
    "train_loss_array = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    train_loss = 0\n",
    "    total_n = 0\n",
    "    train_acc = 0\n",
    "\n",
    "    for X, y in train_iter:\n",
    "        y_hat = net(X)\n",
    "#         print(y_hat)\n",
    "        l = loss(y_hat, y)\n",
    "        updater.zero_grad()\n",
    "        l.backward()\n",
    "        updater.step()\n",
    "    \n",
    "        train_loss += l\n",
    "        total_n += len(y)\n",
    "        train_acc += accuracy(y_hat, y)\n",
    "    \n",
    "    avg_acc = train_acc/total_n\n",
    "    avg_loss = train_loss/total_n\n",
    "    \n",
    "    print(f\"for epoch {epoch} avg_loss {avg_loss}\")\n",
    "    \n",
    "    train_acc_array.append(avg_acc)\n",
    "    train_loss_array.append(avg_loss)\n",
    "\n",
    "\n",
    "with torch.no_grad():    \n",
    "    plt.plot(range(epoch+1), train_acc_array, label=\"train acc\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    plt.plot(range(epoch+1), train_loss_array, label=\"train loss\")\n",
    "    plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dense-combine",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prediction_ch3(net, test_iter, n=6):\n",
    "    for X,y in test_iter:\n",
    "        break\n",
    "    \n",
    "    predicted_labels = net(X[:n]).argmax(dim=1)\n",
    "    actual_labels = y[:n]\n",
    "    \n",
    "#     print(predicted_labels, actual_labels)\n",
    "    \n",
    "    show_images(X[:n], 2, 3, title=get_fashion_mnist_labels(predicted_labels))\n",
    "    print(get_fashion_mnist_labels(actual_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "driving-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_images (imgs,num_cols, num_rows, title=None, scale=0.5):\n",
    "    figsize = (num_cols* scale, num_rows * scale)\n",
    "    plt.subplots_adjust(hspace=0.8, wspace=0.2)\n",
    "    for i in range(len(imgs)):\n",
    "#         plt.figure(figsize=figsize)\n",
    "        plt.subplot(num_cols, num_rows, i+1)\n",
    "        plt.imshow(imgs[i].permute(1,2,0))\n",
    "#         plt.text(0.5, -0.02,title[i],fontsize=9 )\n",
    "        plt.title(title[i], fontsize=9)\n",
    "        plt.axis('off')\n",
    "        plt.grid(b=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "systematic-adventure",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_ch3(net, test_iter, n=6)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "democratic-effects",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "1. Change the value of the hyperparameter num_hiddens and see how this hyperparameter in\u0002fluences your results. Determine the best value of this hyperparameter, keeping all others\n",
    "constant.\n",
    "2. Try adding an additional hidden layer to see how it affects the results.\n",
    "3. How does changing the learning rate alter your results? Fixing the model architecture and\n",
    "other hyperparameters (including number of epochs), what learning rate gives you the best\n",
    "results?\n",
    "4. What is the best result you can get by optimizing over all the hyperparameters (learning rate,\n",
    "number of epochs, number of hidden layers, number of hidden units per layer) jointly?\n",
    "5. Describe why it is much more challenging to deal with multiple hyperparameters.\n",
    "6. What is the smartest strategy you can think of for structuring a search over multiple hyper\u0002parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "level-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "\n",
    "hidden_num_array = range(20,200,20)\n",
    "\n",
    "for hidden_num in hidden_num_array:\n",
    "    W1 = nn.Parameter( torch.randn(num_inputs, hidden_num, requires_grad=True) *0.01)\n",
    "    b1 = nn.Parameter(torch.zeros(hidden_num),requires_grad=True)\n",
    "    W2 = nn.Parameter(torch.randn(hidden_num,num_outputs, requires_grad=True)*0.01)\n",
    "    b2 = nn.Parameter(torch.zeros(num_outputs),requires_grad=True)\n",
    "    \n",
    "    params = [W1,b1,W2,b2]\n",
    "    \n",
    "    for param in params:\n",
    "        if param.grad:\n",
    "            param.grad.zero_()\n",
    "\n",
    "    num_epochs = 10\n",
    "    train_acc_array = []\n",
    "    train_loss_array = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = 0\n",
    "        total_n = 0\n",
    "        train_acc = 0\n",
    "\n",
    "        for X, y in train_iter:\n",
    "            y_hat = net(X)\n",
    "    #         print(y_hat)\n",
    "            l = loss(y_hat, y)\n",
    "            updater.zero_grad()\n",
    "            l.backward()\n",
    "            updater.step()\n",
    "\n",
    "            train_loss += l\n",
    "            total_n += len(y)\n",
    "            train_acc += accuracy(y_hat, y)\n",
    "\n",
    "        avg_acc = train_acc/total_n\n",
    "        avg_loss = train_loss/total_n\n",
    "\n",
    "        print(f\"for epoch {epoch} avg_loss {avg_loss}\")\n",
    "\n",
    "        train_acc_array.append(avg_acc)\n",
    "        train_loss_array.append(avg_loss)\n",
    "\n",
    "\n",
    "    with torch.no_grad():    \n",
    "        plt.plot(range(epoch+1), train_acc_array, label=\"train acc\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.show()\n",
    "        plt.plot(range(epoch+1), train_loss_array, label=\"train loss\")\n",
    "        plt.show()\n",
    "    \n",
    "    print(f\"Best value for hidden_num:  {hidden_num} : {train_loss_array[-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-cookbook",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
