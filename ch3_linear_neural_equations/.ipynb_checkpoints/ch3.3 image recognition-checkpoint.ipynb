{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "familiar-malawi",
   "metadata": {},
   "source": [
    "## Trying softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "metropolitan-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cardiac-horizontal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1362,  0.0760,  0.0305]]), tensor(-0.1362), tensor(0.8726))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let take y\n",
    "\n",
    "y = torch.normal(0,0.1,size=(1,3))\n",
    "num = torch.exp(y[0][0])\n",
    "y, y[0][0], num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "stuffed-python",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.9825])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "den = torch.exp(y).sum(dim=1)\n",
    "den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "configured-spare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.2926])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_value = num/den\n",
    "softmax_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-greenhouse",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "1. We can explore the connection between exponential families and the softmax in some more\n",
    "depth.\n",
    "    1. Compute the second derivative of the cross-entropy loss l(y, yˆ) for the softmax.\n",
    "\n",
    "    * after applying quotient rule for cross entropy loss the anaswer comes out to be zero.\n",
    "\n",
    "    2. Compute the variance of the distribution given by softmax(o) and show that it matches\n",
    "the second derivative computed above.\n",
    "\n",
    "    * Its close to zero through experiments too. but why should this happen? is second derivative essentially same as variance?\n",
    "\n",
    "    ![](variance_of_softmax.png)\n",
    "\n",
    "2. Assume that we have three classes which occur with equal probability, i.e., the probability\n",
    "vector is 1/3\n",
    "    1. What is the problem if we try to design a binary code for it?\n",
    "\n",
    "    * We would need at least 2 bits, and 00,01, 10 would be used but not 11. ?\n",
    "\n",
    "    2. Can you design a better code? Hint: what happens if we try to encode two independent\n",
    "observations? What if we encode n observations jointly?\n",
    "\n",
    "    * we can do it through one hot encoding where the size of array would be the number of observations n\n",
    "\n",
    "3. Softmax is a misnomer for the mapping introduced above (but everyone in deep learning\n",
    "uses it). The real softmax is defined as RealSoftMax(a, b) = log(exp(a) + exp(b)).\n",
    "    1. Prove that RealSoftMax(a, b) > max(a, b).\n",
    "\n",
    "    \n",
    "    2. Prove that this holds for λ\n",
    "    −1RealSoftMax(λa, λb), provided that λ > 0.\n",
    "    3. Show that for λ → ∞ we have λ\n",
    "    −1RealSoftMax(λa, λb) → max(a, b).\n",
    "    4. What does the soft-min look like?\n",
    "    5. Extend this to more than two numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-fellowship",
   "metadata": {},
   "source": [
    "### finding variance\n",
    "\n",
    "Find a mean of the set of data.\n",
    "Subtract each number from a mean.\n",
    "Square the result.\n",
    "Add the results together.\n",
    "Divide a result by the total number of numbers in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "meaning-brother",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.2926, 0.3618, 0.3457]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "\n",
    "softmax_values = torch.exp(y)/ torch.exp(y).sum(dim=1)\n",
    "softmax_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "established-stamp",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3333)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_softmax = softmax_values.sum() / softmax_values.shape[1]\n",
    "mean_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "radical-cricket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0009)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subtracting each number from mean and squaring the result and summing and deviding by totak number \n",
    "((softmax_values - mean_softmax) **2).sum()/ softmax_values.shape[1]\n",
    "\n",
    "#its close to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "nominated-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "\n",
    "def realSoftmax(a, b):\n",
    "    return torch.log(torch.exp(a) + torch.exp(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "diverse-yugoslavia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3]), tensor([3.3133]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([2])\n",
    "b = torch.tensor([3])\n",
    "\n",
    "max(a,b), realSoftmax(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "advance-vacuum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5.7580]), tensor([3]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = torch.tensor([1.5])\n",
    "\n",
    "(l)** 0.5 * realSoftmax(l * a, l * b) , max(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceramic-battery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([94.8685]), tensor([3]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = torch.tensor([10])\n",
    "\n",
    "(l)**0.5 * realSoftmax(l * a, l * b) , max(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "multiple-aurora",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmin(a,b):\n",
    "    return torch.log(torch.exp(a) - torch.exp(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "geographic-dynamics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def realSoftmaxMore(a,b,c):\n",
    "    return torch.log(torch.exp(a) + torch.exp(b) + torch.exp(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "seventh-happiness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4.4076]), tensor([4]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "realSoftmaxMore(a,b,torch.tensor([4])), max(a,b, torch.tensor([4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-charity",
   "metadata": {},
   "source": [
    "# Image recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "purple-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_transforms = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "hundred-playlist",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.FashionMNIST(download=True, transform=my_transforms, train=True, root=\"data\")\n",
    "test_dataset = torchvision.datasets.FashionMNIST(download=True, transform=my_transforms, train=False, root=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "manual-diabetes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ancient-holiday",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "brave-narrative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 9)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "thorough-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_label(labels):\n",
    "    text_labels = [\n",
    "        't-shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt',\n",
    "        'sneaker', 'bag', 'ankle boot']\n",
    "\n",
    "    return [text_labels[int(i)] for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "amateur-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "prospective-honolulu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ankle boot']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x21abff5bd60>, None)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X.permute(1,2,0)), print(get_text_from_label([y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "selected-shelf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.36 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "# the time it takes to read the data\n",
    "\n",
    "for X,y in train_dataloader:\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "interested-hours",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader= data.DataLoader(test_dataset,batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-willow",
   "metadata": {},
   "source": [
    "Exercises\n",
    "1. Does reducing the batch_size (for instance, to 1) affect the reading performance?\n",
    "\n",
    "increases\n",
    "\n",
    "2. The data iterator performance is important. Do you think the current implementation is fast\n",
    "enough? Explore various options to improve it.\n",
    "\n",
    "https://stackoverflow.com/questions/61393613/pytorch-speed-up-data-loading\n",
    "\n",
    "3. Check out the frameworkʼs online API documentation. Which other datasets are available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "loving-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "\n",
    "# train_dataloader= data.DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "raising-quarterly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3.24 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for X, y in train_dataloader:\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "iraqi-retro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CIFAR10', 'CIFAR100', 'Cityscapes', 'CocoCaptions', 'CocoDetection', 'DatasetFolder', 'EMNIST', 'FakeData', 'FashionMNIST', 'Flickr30k', 'Flickr8k', 'ImageFolder', 'KMNIST', 'LSUN', 'LSUNClass', 'MNIST', 'Omniglot', 'PhotoTour', 'SBU', 'SEMEION', 'STL10', 'SVHN', 'VOCDetection', 'VOCSegmentation', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'cifar', 'cityscapes', 'coco', 'fakedata', 'flickr', 'folder', 'lsun', 'mnist', 'omniglot', 'phototour', 'sbu', 'semeion', 'stl10', 'svhn', 'utils', 'voc']\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "\n",
    "print(dir(torchvision.datasets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-tension",
   "metadata": {},
   "source": [
    "# Implementing softmax from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "signed-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing the parameters\n",
    "\n",
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "\n",
    "w = torch.normal(0, 0.1, size=(num_inputs, num_outputs), requires_grad=True)\n",
    "b = torch.zeros(num_outputs, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "aggressive-advantage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[5., 7., 9.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum\n",
    "X = torch.tensor([[1.0,2.0,3.0], [4,5,6]])\n",
    "X.sum(axis=0, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "hundred-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    X_exp = torch.exp(X)\n",
    "    partition = X_exp.sum(dim=1, keepdim=True)\n",
    "    return X_exp/partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "amazing-snake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900, 0.2447, 0.6652],\n",
       "        [0.0900, 0.2447, 0.6652]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "certain-marina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.6650, 0.0487, 0.2863],\n",
       "         [0.5141, 0.2470, 0.2389],\n",
       "         [0.5305, 0.1736, 0.2960]]),\n",
       " tensor([1.0000, 1.0000, 1.0000]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.normal(0,1,(3,3))\n",
    "X_prob = softmax(X)\n",
    "X_prob, X_prob.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cooperative-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the model\n",
    "\n",
    "def net(X, w=w, b=b):\n",
    "    return softmax(torch.matmul(X.reshape(-1, w.shape[0]), w) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "whole-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining loss function\n",
    "\n",
    "y = [0,2,1]\n",
    "\n",
    "y_hat = softmax(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "coated-burning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6650, 0.2389, 0.1736])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[[0,1,2], y] # we got the probability of true labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "challenging-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_hat, y):\n",
    "    return -torch.log(y_hat[range(len(y_hat)), y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "oriented-german",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.4080, 1.4317, 1.7512])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "explicit-digit",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "public-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding accuracy\n",
    "def accuracy(y_hat, y):\n",
    "    if len(y_hat.shape)>1 or y_hat.shape[1]>1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    \n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "#     print(cmp)\n",
    "    return float(cmp.type(y.dtype).sum())\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "drawn-islam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "further-royalty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_hat,y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "effective-climate",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name 'Accumulator' is not defined\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    a = Accumulator(2)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "temporal-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accumulator:\n",
    "    def __init__(self,n):\n",
    "        self.data = [0] * n\n",
    "        \n",
    "    def add(self, *args):\n",
    "        self.data = [a +float(b) for a, b in zip(self.data, args)]\n",
    "    \n",
    "    def reset(self):\n",
    "         self.data = [0.0] * len(self.data)\n",
    "            \n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[idx]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "functioning-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(net, data_iter):\n",
    "    if isinstance( net,torch.nn.Module):\n",
    "        net.eval()\n",
    "    \n",
    "    metrics = []\n",
    "    with torch.no_grad():\n",
    "        for X,y in data_iter:\n",
    "            metrics.append([accuracy(net(X), y), y.numel()])\n",
    "    \n",
    "    return torch.tensor(metrics).sum(dim=0)[0]/torch.tensor(metrics).sum(dim=0)[1] \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "behind-variable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.02 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "metrics = evaluate_accuracy(net,train_dataloader )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "differential-rubber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.1036)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "challenging-solid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate=0.01\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "standing-inflation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params=[w,b], batch_size= batch_size, learning_rate=learning_rate):\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= learning_rate * param / batch_size\n",
    "            param.grad.zero_()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "identified-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "## training\n",
    "\n",
    "def train_one_epoch(net=net, data_iter=train_dataloader, optimizer=sgd, loss=cross_entropy):\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train()\n",
    "    \n",
    "    metrics = Accumulator(n=3)\n",
    "    \n",
    "    for X,y in data_iter:\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)\n",
    "        if(isinstance(optimizer, torch.nn.Module)):\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            metrics.add(float(l) * len(y), evaluate_accuracy(y_hat, y), y.numel())\n",
    "        \n",
    "        else:\n",
    "            l.sum().backward()\n",
    "            optimizer()\n",
    "            metrics.add(float(l.sum()), evaluate_accuracy(y_hat, y), y.numel())\n",
    "        \n",
    "    return metrics[0]/metrics[2], metrics[1]/metrics[2]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "manual-calvin",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'float'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-60-179735a6bb0b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_one_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-59-24fc267b7554>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[1;34m(net, data_iter, optimizer, loss)\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m             \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m             \u001b[0moptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-54-c30870b0099a>\u001b[0m in \u001b[0;36msgd\u001b[1;34m(params, batch_size, learning_rate)\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mparam\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m             \u001b[0mparam\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mparams\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m             \u001b[0mparam\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'float'"
     ]
    }
   ],
   "source": [
    "train_one_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "bulgarian-compression",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Animator:  #@save\n",
    "    \"\"\"For plotting data in animation.\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(3.5, 2.5)):\n",
    "        # Incrementally plot multiple lines\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "        d2l.use_svg_display()\n",
    "        self.fig, self.axes = d2l.plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes,]\n",
    "        # Use a lambda function to capture arguments\n",
    "        self.config_axes = lambda: d2l.set_axes(self.axes[\n",
    "            0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # Add multiple data points into the figure\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faced-counter",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all(net=net, train_iter=train_dataloader, test_iter=test_dataloader, loss=cross_entropy, \n",
    "              num_epochs=10, optimizer=sgd):\n",
    "    animator = Animator()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
