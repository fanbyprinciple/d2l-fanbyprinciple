{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "familiar-malawi",
   "metadata": {},
   "source": [
    "## Trying softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "metropolitan-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils import data\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "cardiac-horizontal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.0716,  0.0609,  0.0779]]), tensor(-0.0716), tensor(0.9309))"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let take y\n",
    "\n",
    "y = torch.normal(0,0.1,size=(1,3))\n",
    "num = torch.exp(y[0][0])\n",
    "y, y[0][0], num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "stuffed-python",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.0746])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "den = torch.exp(y).sum(dim=1)\n",
    "den"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "configured-spare",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3028])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax_value = num/den\n",
    "softmax_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-greenhouse",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "1. We can explore the connection between exponential families and the softmax in some more\n",
    "depth.\n",
    "    1. Compute the second derivative of the cross-entropy loss l(y, yˆ) for the softmax.\n",
    "\n",
    "    * after applying quotient rule for cross entropy loss the anaswer comes out to be zero.\n",
    "\n",
    "    2. Compute the variance of the distribution given by softmax(o) and show that it matches\n",
    "the second derivative computed above.\n",
    "\n",
    "    * Its close to zero through experiments too. but why should this happen? is second derivative essentially same as variance?\n",
    "\n",
    "    ![](variance_of_softmax.png)\n",
    "\n",
    "2. Assume that we have three classes which occur with equal probability, i.e., the probability\n",
    "vector is 1/3\n",
    "    1. What is the problem if we try to design a binary code for it?\n",
    "\n",
    "    * We would need at least 2 bits, and 00,01, 10 would be used but not 11. ?\n",
    "\n",
    "    2. Can you design a better code? Hint: what happens if we try to encode two independent\n",
    "observations? What if we encode n observations jointly?\n",
    "\n",
    "    * we can do it through one hot encoding where the size of array would be the number of observations n\n",
    "\n",
    "3. Softmax is a misnomer for the mapping introduced above (but everyone in deep learning\n",
    "uses it). The real softmax is defined as RealSoftMax(a, b) = log(exp(a) + exp(b)).\n",
    "    1. Prove that RealSoftMax(a, b) > max(a, b).\n",
    "\n",
    "    \n",
    "    2. Prove that this holds for λ\n",
    "    −1RealSoftMax(λa, λb), provided that λ > 0.\n",
    "    3. Show that for λ → ∞ we have λ\n",
    "    −1RealSoftMax(λa, λb) → max(a, b).\n",
    "    4. What does the soft-min look like?\n",
    "    5. Extend this to more than two numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "moved-fellowship",
   "metadata": {},
   "source": [
    "### finding variance\n",
    "\n",
    "Find a mean of the set of data.\n",
    "Subtract each number from a mean.\n",
    "Square the result.\n",
    "Add the results together.\n",
    "Divide a result by the total number of numbers in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "meaning-brother",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.3028, 0.3456, 0.3516]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "\n",
    "softmax_values = torch.exp(y)/ torch.exp(y).sum(dim=1)\n",
    "softmax_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "established-stamp",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3333)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_softmax = softmax_values.sum() / softmax_values.shape[1]\n",
    "mean_softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "radical-cricket",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0005)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# subtracting each number from mean and squaring the result and summing and deviding by totak number \n",
    "((softmax_values - mean_softmax) **2).sum()/ softmax_values.shape[1]\n",
    "\n",
    "#its close to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "nominated-lebanon",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3\n",
    "\n",
    "def realSoftmax(a, b):\n",
    "    return torch.log(torch.exp(a) + torch.exp(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "diverse-yugoslavia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([3]), tensor([3.3133]))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([2])\n",
    "b = torch.tensor([3])\n",
    "\n",
    "max(a,b), realSoftmax(a,b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "advance-vacuum",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([5.7580]), tensor([3]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = torch.tensor([1.5])\n",
    "\n",
    "(l)** 0.5 * realSoftmax(l * a, l * b) , max(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ceramic-battery",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([94.8685]), tensor([3]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l = torch.tensor([10])\n",
    "\n",
    "(l)**0.5 * realSoftmax(l * a, l * b) , max(a, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "multiple-aurora",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmin(a,b):\n",
    "    return torch.log(torch.exp(a) - torch.exp(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "geographic-dynamics",
   "metadata": {},
   "outputs": [],
   "source": [
    "def realSoftmaxMore(a,b,c):\n",
    "    return torch.log(torch.exp(a) + torch.exp(b) + torch.exp(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "seventh-happiness",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([4.4076]), tensor([4]))"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "realSoftmaxMore(a,b,torch.tensor([4])), max(a,b, torch.tensor([4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-charity",
   "metadata": {},
   "source": [
    "# Image recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "purple-apache",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_transforms = transforms.ToTensor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "hundred-playlist",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.FashionMNIST(download=True, transform=my_transforms, train=True, root=\"data\")\n",
    "test_dataset = torchvision.datasets.FashionMNIST(download=True, transform=my_transforms, train=False, root=\"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "manual-diabetes",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dataset), len(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ancient-holiday",
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = train_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "brave-narrative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 28, 28]), 9)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "thorough-vegetarian",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_from_label(labels):\n",
    "    text_labels = [\n",
    "        't-shirt', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt',\n",
    "        'sneaker', 'bag', 'ankle boot']\n",
    "\n",
    "    return [text_labels[int(i)] for i in labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "amateur-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_dataloader = data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "prospective-honolulu",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ankle boot']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<matplotlib.image.AxesImage at 0x1fa42254130>, None)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(X.permute(1,2,0)), print(get_text_from_label([y]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "selected-shelf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.09 s\n"
     ]
    }
   ],
   "source": [
    "\n",
    "%%time\n",
    "\n",
    "# the time it takes to read the data\n",
    "\n",
    "for X,y in train_dataloader:\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "interested-hours",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataloader= data.DataLoader(test_dataset,batch_size=32, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-willow",
   "metadata": {},
   "source": [
    "Exercises\n",
    "1. Does reducing the batch_size (for instance, to 1) affect the reading performance?\n",
    "\n",
    "increases\n",
    "\n",
    "2. The data iterator performance is important. Do you think the current implementation is fast\n",
    "enough? Explore various options to improve it.\n",
    "\n",
    "https://stackoverflow.com/questions/61393613/pytorch-speed-up-data-loading\n",
    "\n",
    "3. Check out the frameworkʼs online API documentation. Which other datasets are available?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "loving-prescription",
   "metadata": {},
   "outputs": [],
   "source": [
    "#1\n",
    "\n",
    "# train_dataloader= data.DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "raising-quarterly",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.17 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "for X, y in train_dataloader:\n",
    "    continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "iraqi-retro",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CIFAR10', 'CIFAR100', 'Cityscapes', 'CocoCaptions', 'CocoDetection', 'DatasetFolder', 'EMNIST', 'FakeData', 'FashionMNIST', 'Flickr30k', 'Flickr8k', 'ImageFolder', 'KMNIST', 'LSUN', 'LSUNClass', 'MNIST', 'Omniglot', 'PhotoTour', 'SBU', 'SEMEION', 'STL10', 'SVHN', 'VOCDetection', 'VOCSegmentation', '__all__', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__path__', '__spec__', 'cifar', 'cityscapes', 'coco', 'fakedata', 'flickr', 'folder', 'lsun', 'mnist', 'omniglot', 'phototour', 'sbu', 'semeion', 'stl10', 'svhn', 'utils', 'voc']\n"
     ]
    }
   ],
   "source": [
    "#3\n",
    "\n",
    "print(dir(torchvision.datasets))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brief-tension",
   "metadata": {},
   "source": [
    "# Implementing softmax from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "signed-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "#implementing the parameters\n",
    "\n",
    "num_inputs = 784\n",
    "num_outputs = 10\n",
    "\n",
    "W = torch.normal(0, 0.1, size=(num_inputs, num_outputs), requires_grad=True)\n",
    "b = torch.zeros(num_outputs, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "aggressive-advantage",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5., 7., 9.]]),\n",
       " tensor([[ 6.],\n",
       "         [15.]]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# sum\n",
    "X = torch.tensor([[1.0,2.0,3.0], [4.0,5.0,6.0]])\n",
    "X.sum(axis=0, keepdim=True), X.sum(axis=1, keepdim=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "hundred-exhaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(X):\n",
    "    X_exp = torch.exp(X)\n",
    "    partition = X_exp.sum(dim=1, keepdim=True)\n",
    "    return X_exp/partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "amazing-snake",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0900, 0.2447, 0.6652],\n",
       "        [0.0900, 0.2447, 0.6652]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "softmax(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "certain-marina",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0.1498, 0.0843, 0.7659],\n",
       "         [0.2310, 0.4954, 0.2736],\n",
       "         [0.2575, 0.4628, 0.2797]]),\n",
       " tensor([1.0000, 1.0000, 1.0000]))"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.normal(0,1,(3,3))\n",
    "X_prob = softmax(X)\n",
    "X_prob, X_prob.sum(dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "cooperative-factory",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the model\n",
    "\n",
    "def net(X):\n",
    "    return softmax(torch.matmul(X.reshape(-1, W.shape[0]), W) + b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "whole-blues",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining loss function\n",
    "\n",
    "y = [0,2,1]\n",
    "\n",
    "y_hat = softmax(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "coated-burning",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.1498, 0.2736, 0.4628])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat[[0,1,2], y] # we got the probability of true labels "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "challenging-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_entropy(y_hat, y):\n",
    "    return -torch.log(y_hat[range(len(y_hat)), y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "oriented-german",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8983, 1.2961, 0.7705])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_entropy(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "explicit-digit",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.tensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "public-lending",
   "metadata": {},
   "outputs": [],
   "source": [
    "# finding accuracy\n",
    "def accuracy(y_hat, y):\n",
    "    if len(y_hat.shape)>1 or y_hat.shape[1]>1:\n",
    "        y_hat = y_hat.argmax(axis=1)\n",
    "    \n",
    "    cmp = y_hat.type(y.dtype) == y\n",
    "#     print(cmp)\n",
    "    return float(cmp.type(y.dtype).sum())\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "drawn-islam",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_hat, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "further-royalty",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3333333333333333"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy(y_hat,y)/len(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "effective-climate",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    a = Accumulator(2)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "temporal-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Accumulator:\n",
    "    def __init__(self,n):\n",
    "        self.data = [0] * n\n",
    "        \n",
    "    def add(self, *args):\n",
    "        self.data = [a +float(b) for a, b in zip(self.data, args)]\n",
    "    \n",
    "    def reset(self):\n",
    "         self.data = [0.0] * len(self.data)\n",
    "            \n",
    "    def __getitem__(self,idx):\n",
    "        return self.data[idx]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "functioning-bradford",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_accuracy(net, data_iter):\n",
    "    if isinstance( net,torch.nn.Module):\n",
    "        net.eval()\n",
    "    \n",
    "    #metrics = []\n",
    "    metrics = Accumulator(2)\n",
    "    with torch.no_grad():\n",
    "        for X,y in data_iter:\n",
    "            metrics.add(accuracy(net(X), y), y.numel())\n",
    "    return metrics[0]/metrics[1]\n",
    "#             metrics.append([accuracy(net(X), y), y.numel()])\n",
    "        \n",
    "    \n",
    "#     return torch.tensor(metrics).sum(dim=0)[0]/torch.tensor(metrics).sum(dim=0)[1] \n",
    "            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "behind-variable",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4.98 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "metrics = evaluate_accuracy(net,train_dataloader )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "differential-rubber",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07586666666666667"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "finished-boutique",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate=0.01\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "married-technology",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(params=[W,b], batch_size= batch_size, learning_rate=learning_rate):\n",
    "    with torch.no_grad():\n",
    "        for param in params:\n",
    "            param -= learning_rate * param / batch_size\n",
    "            param.grad.zero_()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "graphic-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = train_dataloader\n",
    "loss = cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "middle-dodge",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_ch3(net, train_iter, loss, updater):  #@save\n",
    "    \"\"\"The training loop defined in Chapter 3.\"\"\"\n",
    "    # Set the model to training mode\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train()\n",
    "    # Sum of training loss, sum of training accuracy, no. of examples\n",
    "    metric = Accumulator(3)\n",
    "    for X, y in train_iter:\n",
    "        # Compute gradients and update parameters\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)\n",
    "        if isinstance(updater, torch.optim.Optimizer):\n",
    "            # Using PyTorch in-built optimizer & loss criterion\n",
    "            updater.zero_grad()\n",
    "            l.backward()\n",
    "            updater.step()\n",
    "            metric.add(float(l) * len(y), accuracy(y_hat, y), y.numel())\n",
    "        else:\n",
    "            # Using custom built optimizer & loss criterion\n",
    "            l.sum().backward()\n",
    "            updater(X.shape[0])\n",
    "            metric.add(float(l.sum()), accuracy(y_hat, y), y.numel())\n",
    "    # Return training loss and training accuracy\n",
    "    return metric[0] / metric[2], metric[1] / metric[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "identified-palace",
   "metadata": {},
   "outputs": [],
   "source": [
    "## training\n",
    "\n",
    "def train_one_epoch(net=net, data_iter=train_dataloader, optimizer=sgd, loss=cross_entropy):\n",
    "    if isinstance(net, torch.nn.Module):\n",
    "        net.train()\n",
    "    \n",
    "    metrics = Accumulator(n=3)\n",
    "    \n",
    "    for X,y in data_iter:\n",
    "        y_hat = net(X)\n",
    "        l = loss(y_hat, y)\n",
    "        if(isinstance(optimizer, torch.nn.Module)):\n",
    "            optimizer.zero_grad()\n",
    "            l.backward()\n",
    "            optimizer.step()\n",
    "            metrics.add(float(l) * len(y), accuracy(y_hat, y), y.numel())\n",
    "        \n",
    "        else:\n",
    "            l.sum().backward()\n",
    "            optimizer()\n",
    "            metrics.add(float(l.sum()), accuracy(y_hat, y), y.numel())\n",
    "        \n",
    "    return metrics[0]/metrics[2], metrics[1]/metrics[2]\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "harmful-healing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.855686782836914, 0.07586666666666667)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_one_epoch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "referenced-newark",
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2l\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "class Animator:  #@save\n",
    "    \"\"\"For plotting data in animation.\"\"\"\n",
    "    def __init__(self, xlabel=None, ylabel=None, legend=None, xlim=None,\n",
    "                 ylim=None, xscale='linear', yscale='linear',\n",
    "                 fmts=('-', 'm--', 'g-.', 'r:'), nrows=1, ncols=1,\n",
    "                 figsize=(3.5, 2.5)):\n",
    "        # Incrementally plot multiple lines\n",
    "        if legend is None:\n",
    "            legend = []\n",
    "#         d2l.use_svg_display()\n",
    "        self.fig, self.axes = plt.subplots(nrows, ncols, figsize=figsize)\n",
    "        if nrows * ncols == 1:\n",
    "            self.axes = [self.axes,]\n",
    "        # Use a lambda function to capture arguments\n",
    "        self.config_axes = lambda: plt.set_axes(self.axes[\n",
    "            0], xlabel, ylabel, xlim, ylim, xscale, yscale, legend)\n",
    "        self.X, self.Y, self.fmts = None, None, fmts\n",
    "\n",
    "    def add(self, x, y):\n",
    "        # Add multiple data points into the figure\n",
    "        if not hasattr(y, \"__len__\"):\n",
    "            y = [y]\n",
    "        n = len(y)\n",
    "        if not hasattr(x, \"__len__\"):\n",
    "            x = [x] * n\n",
    "        if not self.X:\n",
    "            self.X = [[] for _ in range(n)]\n",
    "        if not self.Y:\n",
    "            self.Y = [[] for _ in range(n)]\n",
    "        for i, (a, b) in enumerate(zip(x, y)):\n",
    "            if a is not None and b is not None:\n",
    "                self.X[i].append(a)\n",
    "                self.Y[i].append(b)\n",
    "        self.axes[0].cla()\n",
    "        for x, y, fmt in zip(self.X, self.Y, self.fmts):\n",
    "            self.axes[0].plot(x, y, fmt)\n",
    "        self.config_axes()\n",
    "        display.display(self.fig)\n",
    "        display.clear_output(wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "gross-middle",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_all(net=net, train_iter=train_dataloader, test_iter=test_dataloader, loss=cross_entropy, \n",
    "              num_epochs=10, optimizer=sgd):\n",
    "    animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3,0.9],legend=['train loss', 'train acc', 'test acc'])\n",
    "    for epoch in range(num_epochs):\n",
    "        train_metrics = train_one_epoch(net=net, data_iter=train_dataloader, loss=loss, optimizer=optimizer)\n",
    "        test_acc = evaluate_accuracy(net, test_iter)\n",
    "#         animator.add(epoch +1, train_metrics + (test_acc,))\n",
    "        print(f\"for epoch: {epoch+1} , {train_metrics}, {test_acc}\")\n",
    "    train_loss, train_acc = train_metrics\n",
    "#     assert train_loss < 0.5 , train_loss\n",
    "#     assert train_acc <=1 and train_acc>0.7, train_acc\n",
    "#     assert test_acc<=1 and test_acc>0.7, test_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "atomic-summit",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for epoch: 1 , (2.5320731493632, 0.07586666666666667), 0.0739\n",
      "for epoch: 2 , (2.4024157545725506, 0.07586666666666667), 0.0739\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-116-6d37eaef03f9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrain_all\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-115-57c999a5ba59>\u001b[0m in \u001b[0;36mtrain_all\u001b[1;34m(net, train_iter, test_iter, loss, num_epochs, optimizer)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0manimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mAnimator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'epoch'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxlim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mylim\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0.3\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0.9\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'train loss'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'train acc'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'test acc'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m         \u001b[0mtrain_metrics\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_one_epoch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m         \u001b[0mtest_acc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_accuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m#         animator.add(epoch +1, train_metrics + (test_acc,))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-112-8159af2076c3>\u001b[0m in \u001b[0;36mtrain_one_epoch\u001b[1;34m(net, data_iter, optimizer, loss)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m             \u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mz:\\installs\\anconda\\envs\\myenv\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 255\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    256\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    257\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mz:\\installs\\anconda\\envs\\myenv\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    146\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 147\u001b[1;33m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[0;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    149\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPAAAACrCAYAAABYHBGmAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAJlklEQVR4nO3db6hldb3H8ffH5lZkptEYRDlZ3DGdLNAOZQRl5L1Mc0Ef9AcHpIzBob8ERVAYFfWoooLA/kxcsYK8WQ8uB1KKakSQxjyimU4Uk1lNRWNmPhHN6NuDtaaOZ86ZvWbP2vvsH71fcGD/+e21P+xzPmevs85if1NVSGrTKZsdQNL0LLDUMAssNcwCSw2zwFLDLLDUsIkFTnJtkiNJ7tng/iT5fJJDSe5OcuH4MSWtZ8g78HXAzuPc/3pge/+1F/jiyceSNMTEAlfVLcCfj7PkMuBr1TkAnJHkOWMFlLSxMf4Gfi7w21XXD/e3SZqxLfN8siR76XazOfXUU1927rnnzvPppYV0xx13/KmqzpzmsWMU+HfAWauuP6+/7RhVtQ/YB7C0tFQrKysjPL3UtiS/nvaxY+xCLwNv6Y9GXwQ8XFV/GGG7kiaY+A6c5HrgYmBrksPAR4H/AKiqLwE3AruAQ8AjwNtmFVbSE00scFXtnnB/Ae8aLZGkwTwTS2qYBZYaZoGlhllgqWEWWGqYBZYaZoGlhllgqWEWWGqYBZYaZoGlhllgqWEWWGqYBZYaZoGlhllgqWEWWGqYBZYaNqjASXYm+Xk/PuWD69y/Lcn+JHf241V2jR9V0lpDZiM9CbiGboTKDmB3kh1rln0YuKGqLgAuB74wdlBJxxryDvxy4FBV3VdVfwX+j26cymoFPKO/fDrw+/EiStrIkA92X290yivWrPkY8L0k7wFOBS4ZJZ2k4xrrINZu4Lqqeh7dZ0R/Pckx206yN8lKkpUHHnhgpKeW/n0NKfCQ0Sl7gBsAqupHwFOBrWs3VFX7qmqpqpbOPHOqUTCSVhlS4NuB7UlekOTJdAepltes+Q3wOoAk59EV2LdYacaGzAf+G/Bu4LvAz+iONt+b5ONJLu2XvR+4KslPgOuBK/uJDZJmaNB0wqq6kW4G0urbPrLq8kHgVeNGkzSJZ2JJDbPAUsMssNQwCyw1zAJLDbPAUsMssNQwCyw1zAJLDbPAUsMssNQwCyw1zAJLDbPAUsMssNQwCyw1zAJLDbPAUsMssNSwUWYj9WvenORgknuTfGPcmJLWM/FD7VbNRvovuqkMtydZ7j/I7uia7cCHgFdV1UNJnj2rwJL+ZazZSFcB11TVQwBVdWTcmJLWM6TA681Geu6aNecA5yS5NcmBJDvX25CjVaRxjXUQawuwHbiYbk7SV5KcsXaRo1WkcY01G+kwsFxVj1fVr4Bf0BVa0gyNNRvp/+nefUmylW6X+r7xYkpaz1izkb4LPJjkILAf+EBVPTir0JI62awZZEtLS7WysrIpzy0tkiR3VNXSNI/1TCypYRZYapgFlhpmgaWGWWCpYRZYapgFlhpmgaWGWWCpYRZYapgFlhpmgaWGWWCpYRZYapgFlhpmgaWGWWCpYRZYathoo1X6dW9IUkmm+ngQSSdmYoFXjVZ5PbAD2J1kxzrrTgPeC9w2dkhJ6xtrtArAJ4BPAo+OmE/ScYwyWiXJhcBZVfWd423I0SrSuE76IFaSU4DPAu+ftNbRKtK4xhitchpwPnBzkvuBi4BlD2RJs3fSo1Wq6uGq2lpVZ1fV2cAB4NKq8lPbpRkba7SKpE2wZciiqroRuHHNbR/ZYO3FJx9L0hCeiSU1zAJLDbPAUsMssNQwCyw1zAJLDbPAUsMssNQwCyw1zAJLDbPAUsMssNQwCyw1zAJLDbPAUsMssNQwCyw1zAJLDRtltEqS9yU5mOTuJD9I8vzxo0paa6zRKncCS1X1UuDbwKfGDirpWKOMVqmq/VX1SH/1AN1nR0uasVFGq6yxB7jpZEJJGmbQx8oOleQKYAl4zQb37wX2Amzbtm3Mp5b+LY0xWgWAJJcAV9NNZXhsvQ05G0ka10mPVgFIcgHwZbryHhk/pqT1jDVa5dPA04FvJbkryfIGm5M0olFGq1TVJSPnkjSAZ2JJDbPAUsMssNQwCyw1zAJLDbPAUsMssNQwCyw1zAJLDbPAUsMssNQwCyw1zAJLDbPAUsMssNQwCyw1zAJLDbPAUsPGGq3ylCTf7O+/LcnZoyeVdIyxRqvsAR6qqv8EPgd8cuygko41ymiV/vpX+8vfBl6XJOPFlLSesUar/HNN/zG0DwPPGiOgpI2NOlplktWjVYDHktwzz+c/AVuBP212iA2YbTqLnO1F0z5wSIGHjFY5uuZwki3A6cCDazdUVfuAfQBJVqpqaZrQs2a26ZhtOklWpn3sKKNV+utv7S+/EfhhVdW0oSQNM/EduKr+luToaJUnAdceHa0CrFTVMvC/wNeTHAL+TFdySTM21miVR4E3neBz7zvB9fNktumYbTpTZ4t7ulK7PJVSatjMC7zIp2EOyPa+JAeT3J3kB0mevyjZVq17Q5JKMrcjrEOyJXlz/9rdm+Qbi5ItybYk+5Pc2X9fd80x27VJjmz079N0Pt9nvzvJhRM3WlUz+6I76PVL4IXAk4GfADvWrHkn8KX+8uXAN2eZ6QSzvRZ4Wn/5HYuUrV93GnALcABYWpRswHbgTuCZ/fVnL1C2fcA7+ss7gPvnka1/vlcDFwL3bHD/LuAmIMBFwG2Ttjnrd+BFPg1zYraq2l9Vj/RXD9D9D3wehrxuAJ+gO+/80TnlGprtKuCaqnoIoKqOLFC2Ap7RXz4d+P2cslFVt9D9l2YjlwFfq84B4IwkzzneNmdd4EU+DXNIttX20P12nIeJ2frdq7Oq6jtzynTUkNftHOCcJLcmOZBk5wJl+xhwRZLDdP9Zec98og1yoj+T8z2VslVJrgCWgNdsdhaAJKcAnwWu3OQoG9lCtxt9Md1eyy1JXlJVf9nMUL3dwHVV9Zkkr6Q7f+H8qvr7ZgebxqzfgU/kNEyOdxrmJmUjySXA1cClVfXYHHINyXYacD5wc5L76f5eWp7Tgawhr9thYLmqHq+qXwG/oCv0ImTbA9wAUFU/Ap5Kd570Ihj0M/kEM/6jfQtwH/AC/nVQ4cVr1ryLJx7EumFOBxSGZLuA7qDI9nkd6Biabc36m5nfQawhr9tO4Kv95a10u4XPWpBsNwFX9pfPo/sbOHP83p7Nxgex/ocnHsT68cTtzSHwLrrfwL8Eru5v+zjdOxp0vwG/BRwCfgy8cI4v5qRs3wf+CNzVfy0vSrY1a+dW4IGvW+h28Q8CPwUuX6BsO4Bb+3LfBfz3HLNdD/wBeJxuL2UP8Hbg7atet2v67D8d8j31TCypYZ6JJTXMAksNs8BSwyyw1DALLDXMAksNs8BSwyyw1LB/ALgTkmElDwZhAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 252x180 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minimal-percentage",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 0.1\n",
    "\n",
    "def updater(batch_size):\n",
    "    return sgd([W, b], lr, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "resident-immunology",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter = train_dataloader\n",
    "test_iter = test_dataloader\n",
    "def train_ch3(net, train_iter, test_iter, loss, num_epochs, updater):  #@save\n",
    "    \"\"\"Train a model (defined in Chapter 3).\"\"\"\n",
    "#     animator = Animator(xlabel='epoch', xlim=[1, num_epochs], ylim=[0.3, 0.9],\n",
    "#                         legend=['train loss', 'train acc', 'test acc'])\n",
    "    for epoch in range(num_epochs):\n",
    "        train_metrics = train_epoch_ch3(net, train_iter, loss, updater)\n",
    "        test_acc = evaluate_accuracy(net, test_iter)\n",
    "        print(f\"for epoch: {epoch+1} , {train_metrics}, {test_acc}\")\n",
    "#         animator.add(epoch + 1, train_metrics + (test_acc,))\n",
    "    train_loss, train_acc = train_metrics\n",
    "#     assert train_loss < 0.5, train_loss\n",
    "#     assert train_acc <= 1 and train_acc > 0.7, train_acc\n",
    "#     assert test_acc <= 1 and test_acc > 0.7, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dutch-interstate",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 10\n",
    "train_ch3(net, train_iter, test_iter, cross_entropy, num_epochs, updater)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vulnerable-south",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ch3(net, test_iter, n=6):  #@save\n",
    "    \"\"\"Predict labels (defined in Chapter 3).\"\"\"\n",
    "    for X, y in test_iter:\n",
    "        break\n",
    "    trues = d2l.get_fashion_mnist_labels(y)\n",
    "    preds = d2l.get_fashion_mnist_labels(net(X).argmax(axis=1))\n",
    "    titles = [true + '\\n' + pred for true, pred in zip(trues, preds)]\n",
    "#     d2l.show_images(X[0:n].reshape((n, 28, 28)), 1, n, titles=titles[0:n])\n",
    "\n",
    "predict_ch3(net, test_iter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
