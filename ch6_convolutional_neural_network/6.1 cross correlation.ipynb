{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "unexpected-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "colored-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X,K):\n",
    "    h,w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] -h+1), (X.shape[1] -w +1))\n",
    "    \n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            mul = (X[i:i+h, j:j+w] * K)\n",
    "#             print(mul)\n",
    "            Y[i,j] = mul.sum()\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "southeast-moore",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X, K):  #@save\n",
    "    \"\"\"Compute 2D cross-correlation.\"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "mysterious-factor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18., 26.],\n",
       "        [26., 34.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[1.0,2.0,3.0], [2.0,3.0,4.0],[3.0,4.0,5.0]])\n",
    "K = torch.tensor([[1.0,2.0], [2.0,3.0]])\n",
    "\n",
    "corr2d(X,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "posted-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return corr2d(X, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "quantitative-omega",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Conv2d(K.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "sound-balance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7474, -2.2508],\n",
       "        [-2.2508, -2.7542]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-costa",
   "metadata": {},
   "source": [
    "### Edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "competent-writing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones((8,8))\n",
    "X[:, 2:6] = 0\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "metropolitan-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.tensor([[1.0,-1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "radio-arkansas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d(X,K)\n",
    "# detects horizontal edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "assured-dollar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d(X.t(),K)\n",
    "# but not vertical edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "nominated-runner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 0., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 1., 0., 0., 1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1., -1.,  1.,  0., -1.,  0.],\n",
       "         [ 0.,  1., -1.,  1.,  0., -1.,  0.],\n",
       "         [ 0.,  1., -1.,  1.,  0., -1.,  0.],\n",
       "         [ 0.,  1., -1.,  1.,  0., -1.,  0.],\n",
       "         [ 0.,  1., -1.,  1.,  0., -1.,  0.],\n",
       "         [ 0.,  1., -1.,  1.,  0., -1.,  0.],\n",
       "         [ 0.,  1., -1.,  1.,  0., -1.,  0.],\n",
       "         [ 0.,  1., -1.,  1.,  0., -1.,  0.]]),\n",
       " torch.Size([8, 7]))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones((8,8))\n",
    "\n",
    "X[:,2:3] = 0\n",
    "X[:,4:6] = 0\n",
    "\n",
    "print(X)\n",
    "Y = corr2d(X,K)\n",
    "Y, Y.shape\n",
    "# interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "awful-medicaid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-contrast",
   "metadata": {},
   "source": [
    "### Learning a convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "local-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.ones((6,8))\n",
    "X[:,2:6] = 0\n",
    "\n",
    "Y =  corr2d(X,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "blind-antibody",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 6, 8])\n",
      "torch.Size([1, 1, 6, 7])\n",
      "batch 2, loss 13.554019927978516\n",
      "batch 4, loss 4.117298603057861\n",
      "batch 6, loss 1.4457886219024658\n",
      "batch 8, loss 0.5518197417259216\n",
      "batch 10, loss 0.21925143897533417\n"
     ]
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1,1,kernel_size=(1,2), bias=False)\n",
    "\n",
    "X = X.reshape((1,1,6,8))\n",
    "Y = Y.reshape((1,1,6,7))\n",
    "lr = 3e-2\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "for i in range(10):\n",
    "    Y_hat = conv2d(X)\n",
    "    l = (Y_hat - Y) ** 2\n",
    "    conv2d.zero_grad()\n",
    "    l.sum().backward()\n",
    "    \n",
    "    conv2d.weight.data[:] -= lr * conv2d.weight.grad\n",
    "    \n",
    "    if (i+1) % 2 == 0:\n",
    "        print(f'batch {i+1}, loss {l.sum()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "common-color",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.9395, -1.0352]]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weight.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-buying",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "1. Construct an image X with diagonal edges.\n",
    "    1. What happens if you apply the kernel K in this section to it?\n",
    "        * zero matrix.\n",
    "    2. What happens if you transpose X?\n",
    "        * No change\n",
    "    3. What happens if you transpose K?\n",
    "        * zero matrix.\n",
    "        \n",
    "2. When you try to automatically find the gradient for the Conv2D class we created, what kind\n",
    "of error message do you see?\n",
    "    * I am able to do `net.weights.grad`, when I try `net.grad` I get the error `'Conv2d' object has no attribute 'grad'`\n",
    "\n",
    "3. How do you represent a cross-correlation operation as a matrix multiplication by changing\n",
    "the input and kernel tensors?\n",
    "    * cross correlation is basically matrix multiplication between slices of tensorfrom X of the shape of kernel and summing.\n",
    "    * It can be done by padding Kand X based on what is needed to multiply\n",
    "\n",
    "4. Design some kernels manually.\n",
    "    1. What is the form of a kernel for the second derivative?\n",
    "        * okay in order to compute one way would be to manually compute the second derivative and then let see a kernel be made using backpropogation\n",
    "    2. What is the kernel for an integral?\n",
    "        * how do you actually make it manually\n",
    "3. What is the minimum size of a kernel to obtain a derivative of degree d\n",
    "        * dont know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "greatest-reform",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "\n",
    "X =  torch.zeros((8,8))\n",
    "for i in range(X.shape[0]):\n",
    "    X[i][i] = 1\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "assumed-architect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = torch.tensor([[1.0,-1.0]])\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "olympic-madrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X, K):\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j] = (Y[i:i+h, j : j +w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "complex-settlement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "matched-groove",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1.]]),\n",
       " tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1.]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.t(), X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "extreme-buffer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d(X, K.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "mineral-delta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 7])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = corr2d(X, K)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "olympic-kidney",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0.]]]]) tensor([[[[1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 1.]]]])\n",
      "for epoch 0 loss: 3.276268482208252\n",
      "for epoch 1 loss: 1.1021367311477661\n",
      "for epoch 2 loss: 0.3707587718963623\n",
      "for epoch 3 loss: 0.12472327053546906\n",
      "for epoch 4 loss: 0.041956912726163864\n",
      "for epoch 5 loss: 0.01411430537700653\n",
      "for epoch 6 loss: 0.004748052451759577\n",
      "for epoch 7 loss: 0.0015972445253282785\n",
      "for epoch 8 loss: 0.0005373131134547293\n",
      "for epoch 9 loss: 0.0001807521330192685\n"
     ]
    }
   ],
   "source": [
    "net = nn.Conv2d(1,1,K.shape, bias=False)\n",
    "\n",
    "X = X.reshape(1,1,8,8)\n",
    "Y = Y.reshape(1,1,8,7)\n",
    "\n",
    "print(Y, X)\n",
    "lr = 3e-2\n",
    "\n",
    "for i in range(10):\n",
    "    y_hat = net(X)\n",
    "#     print(y_hat.shape)\n",
    "    l = (y_hat - Y)**2\n",
    "    \n",
    "    net.zero_grad()\n",
    "    \n",
    "    l.sum().backward()\n",
    "    \n",
    "    net.weight.data -= lr * net.weight.grad\n",
    "    \n",
    "    print(f\"for epoch {i} loss: {l.sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "available-variation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0010, -0.0028]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([], size=(1, 0))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(net.weight.data[0][0])\n",
    "corr2d(X, net.weight.data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "lyric-poverty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Conv2d' object has no attribute 'grad'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    net.grad\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insured-tuesday",
   "metadata": {},
   "source": [
    "### Strides and padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "descending-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "french-columbus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones((6,8))\n",
    "X[:,2:6] = 0\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "embedded-amazon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 6, 8)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1,1)+ X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "breeding-duration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "          [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "          [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "          [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "          [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "          [1., 1., 0., 0., 0., 0., 1., 1.]]]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = X.reshape((1,1) +X.shape)\n",
    "Z\n",
    "# 1 ,1 we add for batch and channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "according-analyst",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.0957,  0.9395,  0.0000,  0.0000,  0.0000, -1.0352, -0.0957],\n",
       "          [-0.0957,  0.9395,  0.0000,  0.0000,  0.0000, -1.0352, -0.0957],\n",
       "          [-0.0957,  0.9395,  0.0000,  0.0000,  0.0000, -1.0352, -0.0957],\n",
       "          [-0.0957,  0.9395,  0.0000,  0.0000,  0.0000, -1.0352, -0.0957],\n",
       "          [-0.0957,  0.9395,  0.0000,  0.0000,  0.0000, -1.0352, -0.0957],\n",
       "          [-0.0957,  0.9395,  0.0000,  0.0000,  0.0000, -1.0352, -0.0957]]]],\n",
       "       grad_fn=<ThnnConv2DBackward>)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "respective-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_conv2d(conv2d, X):\n",
    "    X = X.reshape((1,1)+ X.shape)\n",
    "    Y = conv2d(X)\n",
    "    # we dont need batch and channels\n",
    "    return Y.reshape(Y.shape[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "thousand-church",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d= nn.Conv2d(1,1,kernel_size=3, padding=1)\n",
    "X = torch.rand(size=(8,8))\n",
    "comp_conv2d(conv2d, X).shape\n",
    "# note that here since padding 1 means to either side "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "informational-probability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d= nn.Conv2d(1,1,kernel_size=(5,3), padding=(2,1))\n",
    "\n",
    "\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "established-twins",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1,1, kernel_size=3, padding=1, stride=2)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "soviet-proposal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1,1, kernel_size=(5,3), padding=(2,1), stride=2)\n",
    "print(X.shape)\n",
    "comp_conv2d(conv2d, X).shape\n",
    "\n",
    "# it halves the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "historical-thousand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2, 2])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1,1, kernel_size=(3,5), padding=(0,1), stride=(3,4))\n",
    "conv2d(X.reshape((1,1)+ X.shape)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-shame",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "1. For the last example in this section, use mathematics to calculate the output shape to see if\n",
    "it is consistent with the experimental result.\n",
    "\n",
    "* it is consistent, |(8 -3 + 0 + 3)/3| , |(8-5+1+4)/4|\n",
    "\n",
    "2. Try other padding and stride combinations on the experiments in this section.\n",
    "\n",
    "*  hmm tried\n",
    "\n",
    "3. For audio signals, what does a stride of 2 correspond to?\n",
    "\n",
    "* it might be two time peridod long\n",
    "\n",
    "4. What are the computational benefits of a stride larger than 1\n",
    "\n",
    "* efficiency in calculation,downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-lightweight",
   "metadata": {},
   "source": [
    "## Multiple input and output channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "recognized-summer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating cross correlation for multiple channels\n",
    "def corr2d_multi_in_my(X, K):\n",
    "    sum_Y = 0\n",
    "    for x, k in zip(X,K):\n",
    "        nh, nw = x.shape\n",
    "        h, w = k.shape\n",
    "        Y = torch.zeros((nh-h+1), (nw-w+1))\n",
    "        for i in range(Y.shape[0]):\n",
    "            for j in range(Y.shape[1]):\n",
    "                x_in = x[i:i+h, j:j+w]\n",
    "#                 print(x_in.shape, k.shape)\n",
    "                Y[i][j] = ( x_in * k).sum()\n",
    "    print(Y)\n",
    "    sum_Y += Y\n",
    "    return sum_Y\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "mexican-patrol",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in(X, K):\n",
    "    return sum(corr2d(x,k) for x, k in zip(X,K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cross-grave",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in(X, K):\n",
    "    # First, iterate through the 0th dimension (channel dimension) of `X` and\n",
    "    # `K`. Then, add them together\n",
    "    return sum(corr2d(x, k) for x, k in zip(X, K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "faced-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.tensor([[[1,2],[3,4]], [[4,5],[5,6]]])\n",
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "revolutionary-orlando",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "chicken-investigator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "russian-turkish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 2.],\n",
       "         [3., 4., 5.],\n",
       "         [6., 7., 8.]],\n",
       "\n",
       "        [[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [7., 8., 9.]]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "unavailable-payroll",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2],\n",
       "         [3, 4]],\n",
       "\n",
       "        [[4, 5],\n",
       "         [5, 6]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "computational-livestock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[4, 5],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "for k in K:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "natural-study",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.],\n",
      "        [6., 7., 8.]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "for x in X:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "limited-bride",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.],\n",
      "        [6., 7., 8.]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n",
      "\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "tensor([[4, 5],\n",
      "        [5, 6]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x, k in zip(X, K):\n",
    "    print(x)\n",
    "    print(k)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "joint-blood",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
    "[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "streaming-synthesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in(X,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "injured-guess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[37., 47.],\n",
      "        [67., 77.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[37., 47.],\n",
       "        [67., 77.]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_my(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "composite-demand",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    return torch.stack([corr2d_multi_in_my(X,K) for k in K], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "institutional-handle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[37., 47.],\n",
      "        [67., 77.]])\n",
      "tensor([[37., 47.],\n",
      "        [67., 77.]])\n",
      "tensor([[[37., 47.],\n",
      "         [67., 77.]],\n",
      "\n",
      "        [[37., 47.],\n",
      "         [67., 77.]]])\n",
      "torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "res = corr2d_multi_in_out(X,K)\n",
    "print(res)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "related-disney",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2, 2])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weconstruct a convolution kernel with 3 output channel by concatenating the kernel tensor K with K+1\n",
    "K= torch.stack((K,K+1, K+2),0)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "functioning-movie",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    # Iterate through the 0th dimension of `K`, and each time, perform\n",
    "    # cross-correlation operations with input `X`. All of the results are\n",
    "    # stacked together\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "reflected-jewel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.]]])\n",
      "torch.Size([3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "res = corr2d_multi_in_out(X,K)\n",
    "print(res)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-worcester",
   "metadata": {},
   "source": [
    "You could think of the 1 × 1 convolutional layer as constituting a fully-connected\n",
    "layer applied at every single pixel location to transform the ci corresponding input values into co\n",
    "output values. Because this is still a convolutional layer, the weights are tied across pixel location.\n",
    "Thus the 1 × 1 convolutional layer requires co × ci weights (plus the bias).\n",
    "\n",
    "### 1x1 convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "occupied-bleeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.reshape((c_i, h * w))\n",
    "    K = K.reshape((c_o, c_i))\n",
    "    Y = torch.matmul(K,X)\n",
    "    return Y.reshape(c_o, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "alike-travel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24.95102310180664\n"
     ]
    }
   ],
   "source": [
    "X = torch.normal(0,1,(3,3,3))\n",
    "K = torch.normal(0,1,(2,3,1,1))\n",
    "\n",
    "Y1 = corr2d_multi_in_out_1x1(X,K)\n",
    "Y2 = corr2d_multi_in_out(X,K)\n",
    "print(float(torch.abs(Y1-Y2).sum()) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abroad-processor",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
