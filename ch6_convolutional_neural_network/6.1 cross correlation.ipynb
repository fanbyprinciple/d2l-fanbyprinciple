{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "unexpected-maker",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "colored-mitchell",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X,K):\n",
    "    h,w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] -h+1), (X.shape[1] -w +1))\n",
    "    \n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            mul = (X[i:i+h, j:j+w] * K)\n",
    "#             print(mul)\n",
    "            Y[i,j] = mul.sum()\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "southeast-moore",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X, K):  #@save\n",
    "    \"\"\"Compute 2D cross-correlation.\"\"\"\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i, j] = (X[i:i + h, j:j + w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "mysterious-factor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[18., 26.],\n",
       "        [26., 34.]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[1.0,2.0,3.0], [2.0,3.0,4.0],[3.0,4.0,5.0]])\n",
    "K = torch.tensor([[1.0,2.0], [2.0,3.0]])\n",
    "\n",
    "corr2d(X,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "posted-louis",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2d(nn.Module):\n",
    "    def __init__(self, kernel_size):\n",
    "        super().__init__()\n",
    "        self.weight = nn.Parameter(torch.randn(kernel_size))\n",
    "        self.bias = nn.Parameter(torch.zeros(1))\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return corr2d(X, self.weight) + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "quantitative-omega",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Conv2d(K.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "sound-balance",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-2.4563, -4.4002],\n",
       "        [-4.4002, -6.3442]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "occupied-costa",
   "metadata": {},
   "source": [
    "### Edge detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "competent-writing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones((8,8))\n",
    "X[:, 2:6] = 0\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "metropolitan-leadership",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.tensor([[1.0,-1.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "radio-arkansas",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.],\n",
       "        [ 0.,  1.,  0.,  0.,  0., -1.,  0.]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d(X,K)\n",
    "# detects horizontal edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "assured-dollar",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d(X.t(),K)\n",
    "# but not vertical edges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "nominated-runner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 0., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 1., 0., 0., 1., 1.],\n",
      "        [1., 1., 0., 1., 0., 0., 1., 1.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.,  1., -1.,  1.,  0., -1.,  0.],\n",
       "         [ 0.,  1., -1.,  1.,  0., -1.,  0.],\n",
       "         [ 0.,  1., -1.,  1.,  0., -1.,  0.],\n",
       "         [ 0.,  1., -1.,  1.,  0., -1.,  0.],\n",
       "         [ 0.,  1., -1.,  1.,  0., -1.,  0.],\n",
       "         [ 0.,  1., -1.,  1.,  0., -1.,  0.],\n",
       "         [ 0.,  1., -1.,  1.,  0., -1.,  0.],\n",
       "         [ 0.,  1., -1.,  1.,  0., -1.,  0.]]),\n",
       " torch.Size([8, 7]))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones((8,8))\n",
    "\n",
    "X[:,2:3] = 0\n",
    "X[:,4:6] = 0\n",
    "\n",
    "print(X)\n",
    "Y = corr2d(X,K)\n",
    "Y, Y.shape\n",
    "# interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "awful-medicaid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pursuant-contrast",
   "metadata": {},
   "source": [
    "### Learning a convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "local-great",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.ones((6,8))\n",
    "X[:,2:6] = 0\n",
    "\n",
    "Y =  corr2d(X,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "blind-antibody",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 1, 6, 8])\n",
      "torch.Size([1, 1, 6, 7])\n",
      "batch 2, loss 11.608417510986328\n",
      "batch 4, loss 2.581953287124634\n",
      "batch 6, loss 0.6930234432220459\n",
      "batch 8, loss 0.22270187735557556\n",
      "batch 10, loss 0.08095771074295044\n"
     ]
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1,1,kernel_size=(1,2), bias=False)\n",
    "\n",
    "X = X.reshape((1,1,6,8))\n",
    "Y = Y.reshape((1,1,6,7))\n",
    "lr = 3e-2\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)\n",
    "\n",
    "for i in range(10):\n",
    "    Y_hat = conv2d(X)\n",
    "    l = (Y_hat - Y) ** 2\n",
    "    conv2d.zero_grad()\n",
    "    l.sum().backward()\n",
    "    \n",
    "    conv2d.weight.data[:] -= lr * conv2d.weight.grad\n",
    "    \n",
    "    if (i+1) % 2 == 0:\n",
    "        print(f'batch {i+1}, loss {l.sum()}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "common-color",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.0125, -0.9563]]]])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d.weight.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exact-buying",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "1. Construct an image X with diagonal edges.\n",
    "    1. What happens if you apply the kernel K in this section to it?\n",
    "        * zero matrix.\n",
    "    2. What happens if you transpose X?\n",
    "        * No change\n",
    "    3. What happens if you transpose K?\n",
    "        * zero matrix.\n",
    "        \n",
    "2. When you try to automatically find the gradient for the Conv2D class we created, what kind\n",
    "of error message do you see?\n",
    "    * I am able to do `net.weights.grad`, when I try `net.grad` I get the error `'Conv2d' object has no attribute 'grad'`\n",
    "\n",
    "3. How do you represent a cross-correlation operation as a matrix multiplication by changing\n",
    "the input and kernel tensors?\n",
    "    * cross correlation is basically matrix multiplication between slices of tensorfrom X of the shape of kernel and summing.\n",
    "    * It can be done by padding Kand X based on what is needed to multiply\n",
    "\n",
    "4. Design some kernels manually.\n",
    "    1. What is the form of a kernel for the second derivative?\n",
    "        * okay in order to compute one way would be to manually compute the second derivative and then let see a kernel be made using backpropogation\n",
    "    2. What is the kernel for an integral?\n",
    "        * how do you actually make it manually\n",
    "3. What is the minimum size of a kernel to obtain a derivative of degree d\n",
    "        * dont know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "greatest-reform",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 1.]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "\n",
    "X =  torch.zeros((8,8))\n",
    "for i in range(X.shape[0]):\n",
    "    X[i][i] = 1\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "assumed-architect",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = torch.tensor([[1.0,-1.0]])\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "olympic-madrid",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X, K):\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - h + 1, X.shape[1] - w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j] = (Y[i:i+h, j : j +w] * K).sum()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "complex-settlement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "matched-groove",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1.]]),\n",
       " tensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "         [0., 0., 0., 0., 0., 0., 0., 1.]]))"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.t(), X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "extreme-buffer",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d(X, K.t())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "mineral-delta",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 7])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = corr2d(X, K)\n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "olympic-kidney",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0.]]]]) tensor([[[[1., 0., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 1., 0., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 1., 0., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 1., 0., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 1., 0., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 1., 0.],\n",
      "          [0., 0., 0., 0., 0., 0., 0., 1.]]]])\n",
      "for epoch 0 loss: 0.17383873462677002\n",
      "for epoch 1 loss: 0.05847935751080513\n",
      "for epoch 2 loss: 0.0196724571287632\n",
      "for epoch 3 loss: 0.006617813836783171\n",
      "for epoch 4 loss: 0.0022262325510382652\n",
      "for epoch 5 loss: 0.0007489045965485275\n",
      "for epoch 6 loss: 0.0002519315166864544\n",
      "for epoch 7 loss: 8.474975766148418e-05\n",
      "for epoch 8 loss: 2.850981763913296e-05\n",
      "for epoch 9 loss: 9.590703484718688e-06\n"
     ]
    }
   ],
   "source": [
    "net = nn.Conv2d(1,1,K.shape, bias=False)\n",
    "\n",
    "X = X.reshape(1,1,8,8)\n",
    "Y = Y.reshape(1,1,8,7)\n",
    "\n",
    "print(Y, X)\n",
    "lr = 3e-2\n",
    "\n",
    "for i in range(10):\n",
    "    y_hat = net(X)\n",
    "#     print(y_hat.shape)\n",
    "    l = (y_hat - Y)**2\n",
    "    \n",
    "    net.zero_grad()\n",
    "    \n",
    "    l.sum().backward()\n",
    "    \n",
    "    net.weight.data -= lr * net.weight.grad\n",
    "    \n",
    "    print(f\"for epoch {i} loss: {l.sum()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "available-variation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0006, 0.0003]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([], size=(1, 0))"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(net.weight.data[0][0])\n",
    "corr2d(X, net.weight.data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "lyric-poverty",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Conv2d' object has no attribute 'grad'\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    net.grad\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "insured-tuesday",
   "metadata": {},
   "source": [
    "### Strides and padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "descending-university",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "french-columbus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "        [1., 1., 0., 0., 0., 0., 1., 1.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.ones((6,8))\n",
    "X[:,2:6] = 0\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "embedded-amazon",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 1, 6, 8)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(1,1)+ X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "breeding-duration",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "          [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "          [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "          [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "          [1., 1., 0., 0., 0., 0., 1., 1.],\n",
       "          [1., 1., 0., 0., 0., 0., 1., 1.]]]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z = X.reshape((1,1) +X.shape)\n",
    "Z\n",
    "# 1 ,1 we add for batch and channel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "according-analyst",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.0561,  1.0125,  0.0000,  0.0000,  0.0000, -0.9563,  0.0561],\n",
       "          [ 0.0561,  1.0125,  0.0000,  0.0000,  0.0000, -0.9563,  0.0561],\n",
       "          [ 0.0561,  1.0125,  0.0000,  0.0000,  0.0000, -0.9563,  0.0561],\n",
       "          [ 0.0561,  1.0125,  0.0000,  0.0000,  0.0000, -0.9563,  0.0561],\n",
       "          [ 0.0561,  1.0125,  0.0000,  0.0000,  0.0000, -0.9563,  0.0561],\n",
       "          [ 0.0561,  1.0125,  0.0000,  0.0000,  0.0000, -0.9563,  0.0561]]]],\n",
       "       grad_fn=<ThnnConv2DBackward>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d(Z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "respective-amateur",
   "metadata": {},
   "outputs": [],
   "source": [
    "def comp_conv2d(conv2d, X):\n",
    "    X = X.reshape((1,1)+ X.shape)\n",
    "    Y = conv2d(X)\n",
    "    # we dont need batch and channels\n",
    "    return Y.reshape(Y.shape[2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "thousand-church",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d= nn.Conv2d(1,1,kernel_size=3, padding=1)\n",
    "X = torch.rand(size=(8,8))\n",
    "comp_conv2d(conv2d, X).shape\n",
    "# note that here since padding 1 means to either side "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "informational-probability",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 8])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d= nn.Conv2d(1,1,kernel_size=(5,3), padding=(2,1))\n",
    "\n",
    "\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "established-twins",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1,1, kernel_size=3, padding=1, stride=2)\n",
    "comp_conv2d(conv2d, X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "soviet-proposal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 8])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 4])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1,1, kernel_size=(5,3), padding=(2,1), stride=2)\n",
    "print(X.shape)\n",
    "comp_conv2d(conv2d, X).shape\n",
    "\n",
    "# it halves the input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "historical-thousand",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 2, 2])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv2d = nn.Conv2d(1,1, kernel_size=(3,5), padding=(0,1), stride=(3,4))\n",
    "conv2d(X.reshape((1,1)+ X.shape)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wired-shame",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "1. For the last example in this section, use mathematics to calculate the output shape to see if\n",
    "it is consistent with the experimental result.\n",
    "\n",
    "* it is consistent, |(8 -3 + 0 + 3)/3| , |(8-5+1+4)/4|\n",
    "\n",
    "2. Try other padding and stride combinations on the experiments in this section.\n",
    "\n",
    "*  hmm tried\n",
    "\n",
    "3. For audio signals, what does a stride of 2 correspond to?\n",
    "\n",
    "* it might be two time peridod long\n",
    "\n",
    "4. What are the computational benefits of a stride larger than 1\n",
    "\n",
    "* efficiency in calculation,downsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-lightweight",
   "metadata": {},
   "source": [
    "## Multiple input and output channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "recognized-summer",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating cross correlation for multiple channels\n",
    "def corr2d_multi_in_my(X, K):\n",
    "    sum_Y = 0\n",
    "    for x, k in zip(X,K):\n",
    "        nh, nw = x.shape\n",
    "        h, w = k.shape\n",
    "        Y = torch.zeros((nh-h+1), (nw-w+1))\n",
    "        for i in range(Y.shape[0]):\n",
    "            for j in range(Y.shape[1]):\n",
    "                x_in = x[i:i+h, j:j+w]\n",
    "#                 print(x_in.shape, k.shape)\n",
    "                Y[i][j] = ( x_in * k).sum()\n",
    "    print(Y)\n",
    "    sum_Y += Y\n",
    "    return sum_Y\n",
    "                \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "mexican-patrol",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in(X, K):\n",
    "    return sum(corr2d(x,k) for x, k in zip(X,K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "cross-grave",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in(X, K):\n",
    "    # First, iterate through the 0th dimension (channel dimension) of `X` and\n",
    "    # `K`. Then, add them together\n",
    "    return sum(corr2d(x, k) for x, k in zip(X, K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "faced-shepherd",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = torch.tensor([[[1,2],[3,4]], [[4,5],[5,6]]])\n",
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "revolutionary-orlando",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 3])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "chicken-investigator",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "russian-turkish",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0., 1., 2.],\n",
       "         [3., 4., 5.],\n",
       "         [6., 7., 8.]],\n",
       "\n",
       "        [[1., 2., 3.],\n",
       "         [4., 5., 6.],\n",
       "         [7., 8., 9.]]])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "unavailable-payroll",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 2],\n",
       "         [3, 4]],\n",
       "\n",
       "        [[4, 5],\n",
       "         [5, 6]]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "computational-livestock",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "tensor([[4, 5],\n",
      "        [5, 6]])\n"
     ]
    }
   ],
   "source": [
    "for k in K:\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "natural-study",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.],\n",
      "        [6., 7., 8.]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n"
     ]
    }
   ],
   "source": [
    "for x in X:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "limited-bride",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.],\n",
      "        [6., 7., 8.]])\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "\n",
      "\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.],\n",
      "        [7., 8., 9.]])\n",
      "tensor([[4, 5],\n",
      "        [5, 6]])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for x, k in zip(X, K):\n",
    "    print(x)\n",
    "    print(k)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "joint-blood",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
    "[[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "streaming-synthesis",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0.],\n",
       "        [0., 0.]])"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in(X,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "injured-guess",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[37., 47.],\n",
      "        [67., 77.]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[37., 47.],\n",
       "        [67., 77.]])"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_my(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "composite-demand",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    return torch.stack([corr2d_multi_in_my(X,K) for k in K], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "institutional-handle",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[37., 47.],\n",
      "        [67., 77.]])\n",
      "tensor([[37., 47.],\n",
      "        [67., 77.]])\n",
      "tensor([[[37., 47.],\n",
      "         [67., 77.]],\n",
      "\n",
      "        [[37., 47.],\n",
      "         [67., 77.]]])\n",
      "torch.Size([2, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "res = corr2d_multi_in_out(X,K)\n",
    "print(res)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "related-disney",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 2, 2])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weconstruct a convolution kernel with 3 output channel by concatenating the kernel tensor K with K+1\n",
    "K= torch.stack((K,K+1, K+2),0)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "functioning-movie",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X, K):\n",
    "    # Iterate through the 0th dimension of `K`, and each time, perform\n",
    "    # cross-correlation operations with input `X`. All of the results are\n",
    "    # stacked together\n",
    "    return torch.stack([corr2d_multi_in(X, k) for k in K], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "reflected-jewel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.]],\n",
      "\n",
      "        [[0., 0.],\n",
      "         [0., 0.]]])\n",
      "torch.Size([3, 2, 2])\n"
     ]
    }
   ],
   "source": [
    "res = corr2d_multi_in_out(X,K)\n",
    "print(res)\n",
    "print(res.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "humanitarian-worcester",
   "metadata": {},
   "source": [
    "You could think of the 1 × 1 convolutional layer as constituting a fully-connected\n",
    "layer applied at every single pixel location to transform the ci corresponding input values into co\n",
    "output values. Because this is still a convolutional layer, the weights are tied across pixel location.\n",
    "Thus the 1 × 1 convolutional layer requires co × ci weights (plus the bias).\n",
    "\n",
    "### 1x1 convolutional layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "occupied-bleeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X, K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.reshape((c_i, h * w))\n",
    "    K = K.reshape((c_o, c_i))\n",
    "    Y = torch.matmul(K,X)\n",
    "    return Y.reshape(c_o, h, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "alike-travel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.801506996154785\n"
     ]
    }
   ],
   "source": [
    "X = torch.normal(0,1,(3,3,3))\n",
    "K = torch.normal(0,1,(2,3,1,1))\n",
    "\n",
    "Y1 = corr2d_multi_in_out_1x1(X,K)\n",
    "Y2 = corr2d_multi_in_out(X,K)\n",
    "print(float(torch.abs(Y1-Y2).sum()) )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
