{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "selective-gateway",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "pediatric-peace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d(X, K):\n",
    "    kh, kw = K.shape\n",
    "    xh, xw = X.shape\n",
    "    \n",
    "    Y = torch.zeros((xh-kh+1), (xw-kw+1))\n",
    "    \n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            Y[i,j] = (X[i:i+kh, j:j+kw] *K).sum()\n",
    "    \n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bizarre-tracker",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "atomic-absence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in(X,K):\n",
    "    return sum(corr2d(x,k) for x,k in zip(X,K))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "operating-vessel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3, 3]) torch.Size([2, 2, 2])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 56.,  72.],\n",
       "        [104., 120.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.tensor([[[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]],\n",
    "                  [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]]])\n",
    "K = torch.tensor([[[0.0, 1.0], [2.0, 3.0]], [[1.0, 2.0], [3.0, 4.0]]])\n",
    "print(X.shape, K.shape)\n",
    "corr2d_multi_in(X, K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ordinary-simpson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = torch.normal(0,1,(1,1,1))\n",
    "corr2d_multi_in(X,K).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "first-cookie",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[ 0.0000, -0.1945, -0.3890],\n",
       "         [-0.5835, -0.7780, -0.9725],\n",
       "         [-1.1670, -1.3616, -1.5561]])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[corr2d(x,k) for x,k in zip(X,K)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "committed-botswana",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out(X,K):\n",
    "    return torch.stack([corr2d_multi_in(X,k) for k in K],0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "verified-andrew",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "temporal-parliament",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1, 1, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "K = torch.stack((K, K+1, K+2),0)\n",
    "K.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "handled-international",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.0000, -0.1945, -0.3890],\n",
       "         [-0.5835, -0.7780, -0.9725],\n",
       "         [-1.1670, -1.3616, -1.5561]],\n",
       "\n",
       "        [[ 0.0000,  0.8055,  1.6110],\n",
       "         [ 2.4165,  3.2220,  4.0275],\n",
       "         [ 4.8330,  5.6384,  6.4439]],\n",
       "\n",
       "        [[ 0.0000,  1.8055,  3.6110],\n",
       "         [ 5.4165,  7.2220,  9.0275],\n",
       "         [10.8330, 12.6384, 14.4439]]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(X,K)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "juvenile-villa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr2d_multi_in_out_1x1(X,K):\n",
    "    c_i, h, w = X.shape\n",
    "    c_o = K.shape[0]\n",
    "    X = X.reshape((c_i, h * w))\n",
    "    K = K.reshape((c_o, c_i))\n",
    "    Y = torch.matmul(K,X)\n",
    "    return Y.reshape((c_o, h, w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "southeast-likelihood",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.normal(0, 1, (3, 3, 3))\n",
    "K = torch.normal(0, 1, (2, 3, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "lined-tunnel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-0.2191,  5.6725, -2.0104],\n",
      "         [ 1.6895, -1.0932, -2.2256],\n",
      "         [-1.5367, -3.5512,  2.4376]],\n",
      "\n",
      "        [[-2.0566,  4.4244, -1.6383],\n",
      "         [ 0.4864, -0.1387, -0.1849],\n",
      "         [ 0.9553, -3.5452, -0.6145]]]) tensor([[[-0.2191,  5.6725, -2.0104],\n",
      "         [ 1.6895, -1.0932, -2.2256],\n",
      "         [-1.5367, -3.5512,  2.4376]],\n",
      "\n",
      "        [[-2.0566,  4.4244, -1.6383],\n",
      "         [ 0.4864, -0.1387, -0.1849],\n",
      "         [ 0.9553, -3.5452, -0.6145]]])\n",
      "tensor([[[True, True, True],\n",
      "         [True, True, True],\n",
      "         [True, True, True]],\n",
      "\n",
      "        [[True, True, True],\n",
      "         [True, True, True],\n",
      "         [True, True, True]]])\n"
     ]
    }
   ],
   "source": [
    "Y1 = corr2d_multi_in_out_1x1(X,K)\n",
    "Y2 = corr2d_multi_in_out(X,K)\n",
    "print(Y1, Y2)\n",
    "\n",
    "print(Y1==Y2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "excited-trader",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "1. Assume that we have two convolution kernels of size $k_1$ and $k_2$, respectively (with no nonlinearity in between).\n",
    "    1. Prove that the result of the operation can be expressed by a single convolution.\n",
    "    * not sure\n",
    "    1. What is the dimensionality of the equivalent single convolution?\n",
    "    * dont know\n",
    "    1. Is the converse true?\n",
    "    * dont know\n",
    "    \n",
    "1. Assume an input of shape $c_i\\times h\\times w$ and a convolution kernel of shape $c_o\\times c_i\\times k_h\\times k_w$, padding of $(p_h, p_w)$, and stride of $(s_h, s_w)$.\n",
    "    1. What is the computational cost (multiplications and additions) for the forward propagation?\n",
    "    1. What is the memory footprint?\n",
    "    \n",
    "    1. What is the memory footprint for the backward computation?\n",
    "    * dont know\n",
    "    \n",
    "    1. What is the computational cost for the backpropagation?\n",
    "    * dont know\n",
    "    \n",
    "1. By what factor does the number of calculations increase if we double the number of input channels $c_i$ and the number of output channels $c_o$? What happens if we double the padding?\n",
    "\n",
    "    * calculations would be multiplied by $c_i$  and if $c_o$ it would be multiplied by length of $c_o$\n",
    "    * if we double the padding then calculation would be h-kh+ph* 2,w - kw + pw * 2\n",
    "    \n",
    "1. If the height and width of a convolution kernel is $k_h=k_w=1$, what is the computational complexity of the forward propagation?\n",
    "\n",
    "    * h - kh + 1, w - kw + 1 =  h, w\n",
    "    \n",
    "1. Are the variables `Y1` and `Y2` in the last example of this section exactly the same? Why?\n",
    "    \n",
    "    * it cameout same for me !\n",
    "    \n",
    "1. How would you implement convolutions using matrix multiplication when the convolution window is not $1\\times 1$?\n",
    "    \n",
    "    * DONT KNOW. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "flush-wright",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1\n",
    "\n",
    "k1 = torch.normal(0,1,(2,3,2,2))\n",
    "k2 = torch.normal(0,1,(2,3,2,2))\n",
    "\n",
    "X = torch.normal(0,1,(3,3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "accepting-colombia",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-4.4373,  0.7733],\n",
      "         [ 2.7726,  0.0287]],\n",
      "\n",
      "        [[-1.4538, -2.1907],\n",
      "         [-3.5141, -6.7401]]])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[17.7520]],\n",
       "\n",
       "        [[-4.3148]]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = corr2d_multi_in_out(X,k1)\n",
    "print(Y)\n",
    "\n",
    "corr2d_multi_in_out(Y, k2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "biblical-heading",
   "metadata": {},
   "outputs": [],
   "source": [
    "k1 = k1 + k2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "healthy-struggle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  1.8279, -11.1181],\n",
       "         [  4.4133,   2.9503]],\n",
       "\n",
       "        [[ -1.7347,  -2.0985],\n",
       "         [ -4.2719, -13.0135]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr2d_multi_in_out(X, k1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cooked-surveillance",
   "metadata": {},
   "outputs": [],
   "source": [
    "#6\n",
    "\n",
    "def corr2d_multi_in_out_nxn(X,K):\n",
    "    c_i , h, w = X.shape\n",
    "    c_o, _, kh, kw = K.shape\n",
    "    \n",
    "    X = X.reshape((c_i, h * w))\n",
    "    K = K.reshape((c_o * kh * kw, c_i))\n",
    "    Y = torch.matmul(K, X)\n",
    "    return Y.reshape((c_o, -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "noble-helicopter",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = torch.normal(0, 1, (3, 3, 3))\n",
    "K = torch.normal(0, 1, (2, 3, 2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "explicit-gasoline",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.2263,  3.6681],\n",
       "         [-1.1259, -1.3209]],\n",
       "\n",
       "        [[ 7.2328,  3.0686],\n",
       "         [-3.7975,  1.4645]]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y2 = corr2d_multi_in_out(X, K)\n",
    "Y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "further-bennett",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-2.1815, -0.5035, -0.4300,  1.6996,  0.6384,  2.6970,  0.5897,  0.1399,\n",
      "          3.0734, -0.6737, -1.6015, -0.7622,  2.7148, -0.2910,  2.4581, -1.3849,\n",
      "         -1.0349, -0.5919, -3.2290, -2.5474, -0.3056,  2.1638,  1.2308,  3.7177,\n",
      "          1.4757, -1.7264,  2.9952,  0.7533,  3.9835, -0.2855, -0.5765, -0.6120,\n",
      "         -0.8988, -0.8695,  3.8986,  2.3110],\n",
      "        [ 0.8602,  0.1394,  0.9779, -2.8848,  0.3971, -2.7169,  1.6146, -0.5404,\n",
      "         -1.0008,  1.3272,  0.3577, -0.1431,  0.0679, -0.7134, -0.8180, -1.2816,\n",
      "          0.1790, -1.9554,  0.7060, -3.7375,  0.6292, -0.6867,  0.2309, -1.0002,\n",
      "          0.5955, -4.1104, -4.4322, -1.7866, -0.0259, -0.2931,  1.1082,  0.5658,\n",
      "          1.9996,  0.6516,  0.4604,  2.8930]])\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    Y1 = corr2d_multi_in_out_nxn(X,K)\n",
    "    print(Y1)\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "disabled-pollution",
   "metadata": {},
   "source": [
    "### Max poolinglayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "other-motion",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_mean(Y_sub):\n",
    "    total = 0\n",
    "    counter = 0\n",
    "    for i in range(Y_sub.shape[0]):\n",
    "        for j in range(Y_sub.shape[1]):\n",
    "            total +=Y_sub[i][j]\n",
    "            counter += 1\n",
    "    return total/counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "trying-rider",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.9042)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "find_mean(torch.normal(0,1,(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "compliant-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool2d(X, pool_size, mode='max'):\n",
    "    p_h, p_w = pool_size\n",
    "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if mode == 'max':\n",
    "                Y[i,j] = X[i:i+p_h, j:j+p_h].max()\n",
    "            elif mode == 'avg':\n",
    "                Y[i,j] = X[i:i+p_h, j:j+p_h].mean()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "animated-writing",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 3]) torch.Size([3, 3])\n"
     ]
    }
   ],
   "source": [
    "X = torch.tensor([[0.0, 1.0, 2.0], [3.0, 4.0, 5.0], [6.0, 7.0, 8.0]])\n",
    "\n",
    "X1 = torch.normal(0,1,(3,3))\n",
    "\n",
    "print(X1.shape, X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "active-estonia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 1., 2.],\n",
       "         [3., 4., 5.],\n",
       "         [6., 7., 8.]]),\n",
       " tensor([[ 2.0692,  2.6693, -0.2633],\n",
       "         [-0.0327,  0.1380,  2.0699],\n",
       "         [ 0.5216,  0.3013, -0.5565]]))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "handled-shepherd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.4278, -1.1468,  0.3987,  0.5388,  0.5868,  1.0652,  2.2685, -1.6087,\n",
       "         -0.0755]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2 = torch.normal(0,1, (1,9))\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "hollywood-forestry",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[4., 5.],\n",
       "        [7., 8.]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d(X, (2,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "verbal-robert",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[2., 3.],\n",
       "        [5., 6.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d(X,(2,2), 'avg')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "destroyed-danger",
   "metadata": {},
   "source": [
    "### padding and stride in pooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "featured-representative",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "           [ 4.,  5.,  6.,  7.],\n",
       "           [ 8.,  9., 10., 11.],\n",
       "           [12., 13., 14., 15.]]]]),\n",
       " torch.Size([1, 1, 4, 4]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(16, dtype=torch.float32).reshape(1,1,4,4)\n",
    "X,X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "residential-boost",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "pool2d= nn.MaxPool2d(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "particular-sharp",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "z:\\installs\\anconda\\envs\\myenv\\lib\\site-packages\\torch\\nn\\functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  ..\\c10/core/TensorImpl.h:1156.)\n",
      "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[10.]]]])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fantastic-whale",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "sweet-billion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]]]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d((2,3),stride=(2,3), padding=(0,1))\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "capable-december",
   "metadata": {},
   "source": [
    "### Multiple channels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "wicked-resort",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "          [ 4.,  5.,  6.,  7.],\n",
       "          [ 8.,  9., 10., 11.],\n",
       "          [12., 13., 14., 15.]]]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "engaged-campaign",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 1.,  2.,  3.,  4.],\n",
       "          [ 5.,  6.,  7.,  8.],\n",
       "          [ 9., 10., 11., 12.],\n",
       "          [13., 14., 15., 16.]]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "acceptable-hearts",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[ 0.,  1.,  2.,  3.],\n",
       "           [ 4.,  5.,  6.,  7.],\n",
       "           [ 8.,  9., 10., 11.],\n",
       "           [12., 13., 14., 15.]],\n",
       " \n",
       "          [[ 1.,  2.,  3.,  4.],\n",
       "           [ 5.,  6.,  7.,  8.],\n",
       "           [ 9., 10., 11., 12.],\n",
       "           [13., 14., 15., 16.]]]]),\n",
       " torch.Size([1, 2, 4, 4]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.cat((X, X+1), 1)\n",
    "X, X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "pursuant-light",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 5.,  7.],\n",
       "          [13., 15.]],\n",
       "\n",
       "         [[ 6.,  8.],\n",
       "          [14., 16.]]]])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(3, padding=1, stride=2)\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "understood-mainstream",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "\n",
    "1. Can you implement average pooling as a special case of a convolution layer? If so, do it.\n",
    "2. Can you implement maximum pooling as a special case of a convolution layer? If so, do it.\n",
    "3. What is the computational cost of the pooling layer? Assume that the input to the pooling\n",
    "layer is of size c×h×w, the pooling window has a shape of ph ×pw with a padding of (ph, pw)\n",
    "and a stride of (sh, sw).\n",
    "\n",
    "\n",
    "\n",
    "4. Why do you expect maximum pooling and average pooling to work differently?\n",
    "\n",
    "* because max pooling will give maximum value from the neighbors while average pooling would consider all the neighbors. I expect max pooling to be faster.\n",
    "\n",
    "5. Do we need a separate minimum pooling layer? Can you replace it with another operation?\n",
    "\n",
    "* This seems like a trick question, but one way is to multiply X by -1 and then do max pooling.\n",
    "\n",
    "6. Is there another operation between average and maximum pooling that you could consider\n",
    "(hint: recall the softmax)? Why might it not be so popular?\n",
    "\n",
    "* taking average of the log and then computing the maximum value devide by sum of log. It might be computationally intensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "august-harris",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.2500, 0.5000],\n",
      "        [0.7500, 1.0000]])\n",
      "tensor(4.)\n",
      "tensor(2.5000)\n"
     ]
    }
   ],
   "source": [
    "# 1 # 2\n",
    "\n",
    "\n",
    "K = torch.tensor([[0.25,0.25], [0.25,0.25]])\n",
    "\n",
    "X = torch.tensor([[1,2],[3,4]])\n",
    "\n",
    "print(X * K)\n",
    "\n",
    "# what I am looking for is a kernel when multiplied with X gives me 4 as output\n",
    "# one wayot achieve it would be\n",
    "\n",
    "K = torch.tensor([[1.0,1.0],[1.0,1.0]])\n",
    "\n",
    "print((X * K).max())\n",
    "print((X *K).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "annoying-confidence",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pool_using_corr(X,K=K,mode=\"max\"):\n",
    "    p_h, p_w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] - p_h + 1, X.shape[1] - p_w + 1))\n",
    "    for i in range(Y.shape[0]):\n",
    "        for j in range(Y.shape[1]):\n",
    "            if(mode==\"max\"):\n",
    "                Y[i,j] = (X[i:i+p_h, j:j+p_w] * K).max()\n",
    "            elif(mode==\"avg\"):\n",
    "                Y[i,j] = (X[i:i+p_h, j:j:p_w] * K).mean()\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "assigned-norfolk",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 1.],\n",
       "        [2., 3.]])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(4, dtype=torch.float32).reshape(1,1,2,2) \n",
    "X1 = torch.arange(4, dtype=torch.float32).reshape(2,2)\n",
    "X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "neural-solid",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[3.]]]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool2d = nn.MaxPool2d(2)\n",
    "\n",
    "pool2d(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "trying-bloom",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pool_using_corr(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "amazing-karen",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
