{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0117b38",
   "metadata": {},
   "source": [
    "https://github.com/odegeasslbc/Progressive-GAN-pytorch/blob/master/progan_modules.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7196acc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import random\n",
    "\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable, grad\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "from os import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "1ca1a7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(100):\n",
    "#     sys.stdout.write(\"\\rDoing thing %i\" % i)\n",
    "#     time.sleep(2)\n",
    "#     sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "9d7475aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EqualLR:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def compute_weight(self, module):\n",
    "        weight = getattr(module, self.name + '_orig')\n",
    "        fan_in = weight.data.size(1) * weight.data[0][0].numel()\n",
    "\n",
    "        return weight * sqrt(2 / fan_in)\n",
    "\n",
    "    @staticmethod\n",
    "    def apply(module, name):\n",
    "        fn = EqualLR(name)\n",
    "\n",
    "        weight = getattr(module, name)\n",
    "        del module._parameters[name]\n",
    "        module.register_parameter(name + '_orig', nn.Parameter(weight.data))\n",
    "        module.register_forward_pre_hook(fn)\n",
    "\n",
    "        return fn\n",
    "\n",
    "    def __call__(self, module, input):\n",
    "        weight = self.compute_weight(module)\n",
    "        setattr(module, self.name, weight)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "26e0b83a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_lr(module, name='weight'):\n",
    "    EqualLR.apply(module, name)\n",
    "\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "044cb033",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input / torch.sqrt(torch.mean(input ** 2, dim=1, keepdim=True)\n",
    "                                  + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "e347f7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EqualConv2d(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        conv = nn.Conv2d(*args, **kwargs)\n",
    "        conv.weight.data.normal_()\n",
    "        conv.bias.data.zero_()\n",
    "        self.conv = equal_lr(conv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.conv(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f00626bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EqualConvTranspose2d(nn.Module):\n",
    "    ### additional module for OOGAN usage\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        conv = nn.ConvTranspose2d(*args, **kwargs)\n",
    "        conv.weight.data.normal_()\n",
    "        conv.bias.data.zero_()\n",
    "        self.conv = equal_lr(conv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.conv(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e07f83d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EqualLinear(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        linear = nn.Linear(in_dim, out_dim)\n",
    "        linear.weight.data.normal_()\n",
    "        linear.bias.data.zero_()\n",
    "\n",
    "        self.linear = equal_lr(linear)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.linear(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "cc5cfc45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, padding, kernel_size2=None, padding2=None, pixel_norm=True):\n",
    "        super().__init__()\n",
    "\n",
    "        pad1 = padding\n",
    "        pad2 = padding\n",
    "        if padding2 is not None:\n",
    "            pad2 = padding2\n",
    "\n",
    "        kernel1 = kernel_size\n",
    "        kernel2 = kernel_size\n",
    "        if kernel_size2 is not None:\n",
    "            kernel2 = kernel_size2\n",
    "\n",
    "        convs = [EqualConv2d(in_channel, out_channel, kernel1, padding=pad1)]\n",
    "        if pixel_norm:\n",
    "            convs.append(PixelNorm())\n",
    "        convs.append(nn.LeakyReLU(0.1))\n",
    "        convs.append(EqualConv2d(out_channel, out_channel, kernel2, padding=pad2))\n",
    "        if pixel_norm:\n",
    "            convs.append(PixelNorm())\n",
    "        convs.append(nn.LeakyReLU(0.1))\n",
    "\n",
    "        self.conv = nn.Sequential(*convs)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.conv(input)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0ee0bd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale(feat):\n",
    "    return F.interpolate(feat, scale_factor=2, mode='bilinear', align_corners=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7790c495",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_code_dim=128, in_channel=128, pixel_norm=True, tanh=True):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_code_dim\n",
    "        self.tanh = tanh\n",
    "        self.input_layer = nn.Sequential(\n",
    "            EqualConvTranspose2d(input_code_dim, in_channel, 4, 1, 0),\n",
    "            PixelNorm(),\n",
    "            nn.LeakyReLU(0.1))\n",
    "\n",
    "        self.progression_4 = ConvBlock(in_channel, in_channel, 3, 1, pixel_norm=pixel_norm)\n",
    "        self.progression_8 = ConvBlock(in_channel, in_channel, 3, 1, pixel_norm=pixel_norm)\n",
    "        self.progression_16 = ConvBlock(in_channel, in_channel, 3, 1, pixel_norm=pixel_norm)\n",
    "        self.progression_32 = ConvBlock(in_channel, in_channel, 3, 1, pixel_norm=pixel_norm)\n",
    "        self.progression_64 = ConvBlock(in_channel, in_channel//2, 3, 1, pixel_norm=pixel_norm)\n",
    "        self.progression_128 = ConvBlock(in_channel//2, in_channel//4, 3, 1, pixel_norm=pixel_norm)\n",
    "        self.progression_256 = ConvBlock(in_channel//4, in_channel//4, 3, 1, pixel_norm=pixel_norm)\n",
    "\n",
    "        self.to_rgb_8 = EqualConv2d(in_channel, 3, 1)\n",
    "        self.to_rgb_16 = EqualConv2d(in_channel, 3, 1)\n",
    "        self.to_rgb_32 = EqualConv2d(in_channel, 3, 1)\n",
    "        self.to_rgb_64 = EqualConv2d(in_channel//2, 3, 1)\n",
    "        self.to_rgb_128 = EqualConv2d(in_channel//4, 3, 1)\n",
    "        self.to_rgb_256 = EqualConv2d(in_channel//4, 3, 1)\n",
    "        \n",
    "        self.max_step = 6\n",
    "\n",
    "    def progress(self, feat, module):\n",
    "        out = F.interpolate(feat, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        out = module(out)\n",
    "        return out\n",
    "\n",
    "    def output(self, feat1, feat2, module1, module2, alpha):\n",
    "        if 0 <= alpha < 1:\n",
    "            skip_rgb = upscale(module1(feat1))\n",
    "            out = (1-alpha)*skip_rgb + alpha*module2(feat2)\n",
    "        else:\n",
    "            out = module2(feat2)\n",
    "        if self.tanh:\n",
    "            return torch.tanh(out)\n",
    "        return out\n",
    "\n",
    "    def forward(self, input, step=0, alpha=-1):\n",
    "        if step > self.max_step:\n",
    "            step = self.max_step\n",
    "\n",
    "        out_4 = self.input_layer(input.view(-1, self.input_dim, 1, 1))\n",
    "        out_4 = self.progression_4(out_4)\n",
    "        out_8 = self.progress(out_4, self.progression_8)\n",
    "        if step==1:\n",
    "            if self.tanh:\n",
    "                return torch.tanh(self.to_rgb_8(out_8))\n",
    "            return self.to_rgb_8(out_8)\n",
    "        \n",
    "        out_16 = self.progress(out_8, self.progression_16)\n",
    "        if step==2:\n",
    "            return self.output( out_8, out_16, self.to_rgb_8, self.to_rgb_16, alpha )\n",
    "        \n",
    "        out_32 = self.progress(out_16, self.progression_32)\n",
    "        if step==3:\n",
    "            return self.output( out_16, out_32, self.to_rgb_16, self.to_rgb_32, alpha )\n",
    "\n",
    "        out_64 = self.progress(out_32, self.progression_64)\n",
    "        if step==4:\n",
    "            return self.output( out_32, out_64, self.to_rgb_32, self.to_rgb_64, alpha )\n",
    "        \n",
    "        out_128 = self.progress(out_64, self.progression_128)\n",
    "        if step==5:\n",
    "            return self.output( out_64, out_128, self.to_rgb_64, self.to_rgb_128, alpha )\n",
    "\n",
    "        out_256 = self.progress(out_128, self.progression_256)\n",
    "        if step==6:\n",
    "            return self.output( out_128, out_256, self.to_rgb_128, self.to_rgb_256, alpha )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "8d281580",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, feat_dim=128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.progression = nn.ModuleList([ConvBlock(feat_dim//4, feat_dim//4, 3, 1),\n",
    "                                          ConvBlock(feat_dim//4, feat_dim//2, 3, 1),\n",
    "                                          ConvBlock(feat_dim//2, feat_dim, 3, 1),\n",
    "                                          ConvBlock(feat_dim, feat_dim, 3, 1),\n",
    "                                          ConvBlock(feat_dim, feat_dim, 3, 1),\n",
    "                                          ConvBlock(feat_dim, feat_dim, 3, 1),\n",
    "                                          ConvBlock(feat_dim+1, feat_dim, 3, 1, 4, 0)])\n",
    "\n",
    "        self.from_rgb = nn.ModuleList([EqualConv2d(3, feat_dim//4, 1),\n",
    "                                       EqualConv2d(3, feat_dim//4, 1),\n",
    "                                       EqualConv2d(3, feat_dim//2, 1),\n",
    "                                       EqualConv2d(3, feat_dim, 1),\n",
    "                                       EqualConv2d(3, feat_dim, 1),\n",
    "                                       EqualConv2d(3, feat_dim, 1),\n",
    "                                       EqualConv2d(3, feat_dim, 1)])\n",
    "\n",
    "        self.n_layer = len(self.progression)\n",
    "\n",
    "        self.linear = EqualLinear(feat_dim, 1)\n",
    "\n",
    "    def forward(self, input, step=0, alpha=-1):\n",
    "        for i in range(step, -1, -1):\n",
    "            index = self.n_layer - i - 1\n",
    "\n",
    "            if i == step:\n",
    "                out = self.from_rgb[index](input)\n",
    "\n",
    "            if i == 0:\n",
    "                out_std = torch.sqrt(out.var(0, unbiased=False) + 1e-8)\n",
    "                mean_std = out_std.mean()\n",
    "                mean_std = mean_std.expand(out.size(0), 1, 4, 4)\n",
    "                out = torch.cat([out, mean_std], 1)\n",
    "\n",
    "            out = self.progression[index](out)\n",
    "\n",
    "            if i > 0:\n",
    "                # out = F.avg_pool2d(out, 2)\n",
    "                out = F.interpolate(out, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
    "\n",
    "                if i == step and 0 <= alpha < 1:\n",
    "                    # skip_rgb = F.avg_pool2d(input, 2)\n",
    "                    skip_rgb = F.interpolate(input, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
    "                    skip_rgb = self.from_rgb[index + 1](skip_rgb)\n",
    "                    out = (1 - alpha) * skip_rgb + alpha * out\n",
    "\n",
    "        out = out.squeeze(2).squeeze(2)\n",
    "        # print(input.size(), out.size(), step)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "bf6414b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate(model1, model2, decay=0.999):\n",
    "    par1 = dict(model1.named_parameters())\n",
    "    par2 = dict(model2.named_parameters())\n",
    "    \n",
    "    for k in par1.keys():\n",
    "        par1[k].data.mul_(decay).add_(1 - decay, par2[k].data)\n",
    "        \n",
    "# def accumulate(model1, model2, decay=0.999):\n",
    "#     par1 = dict(model1.named_parameters())\n",
    "#     par2 = dict(model2.named_parameters())\n",
    "    \n",
    "    \n",
    "#     print(len(par1.keys()))\n",
    "#     print(len(par2.keys()))\n",
    "    \n",
    "#     for k in par1.keys():\n",
    "#         k_module = \"module.\" + k\n",
    "#         par1[k].data.mul_(decay).add_(1 - decay, par2[k_module].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d502ed24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imagefolder_loader(path):\n",
    "    def loader(transform):\n",
    "        data = datasets.ImageFolder(path, transform=transform)\n",
    "        print(len(data))\n",
    "        data_loader = DataLoader(data, shuffle=True, batch_size=batch_size,\n",
    "                                 num_workers=4)\n",
    "        return data_loader\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7a8892ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_data(dataloader, image_size=4):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(image_size+int(image_size*0.2)+1),\n",
    "        transforms.RandomCrop(image_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    loader = dataloader(transform)\n",
    "\n",
    "    return loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "ea819ac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(generator, discriminator, init_step, loader, total_iter=600000):\n",
    "    step = init_step # can be 1 = 8, 2 = 16, 3 = 32, 4 = 64, 5 = 128, 6 = 128\n",
    "    data_loader = sample_data(loader, 4 * 2 ** step)\n",
    "    dataset = iter(data_loader)\n",
    "\n",
    "    #total_iter = 600000\n",
    "    total_iter_remain = total_iter - (total_iter//6)*(step-1)\n",
    "\n",
    "    pbar = tqdm(range(total_iter_remain))\n",
    "\n",
    "    disc_loss_val = 0\n",
    "    gen_loss_val = 0\n",
    "    grad_loss_val = 0\n",
    "\n",
    "    from datetime import datetime\n",
    "    import os\n",
    "    date_time = datetime.now()\n",
    "    post_fix = '%s_%s_%d_%d.txt'%(trial_name, date_time.date(), date_time.hour, date_time.minute)\n",
    "    log_folder = 'trial_%s_%s_%d_%d'%(trial_name, date_time.date(), date_time.hour, date_time.minute)\n",
    "    \n",
    "    os.mkdir(log_folder)\n",
    "    os.mkdir(log_folder+'/checkpoint')\n",
    "    os.mkdir(log_folder+'/sample')\n",
    "\n",
    "    config_file_name = os.path.join(log_folder, 'train_config_'+post_fix)\n",
    "    config_file = open(config_file_name, 'w')\n",
    "    config_file.write(str(args))\n",
    "    config_file.close()\n",
    "\n",
    "    log_file_name = os.path.join(log_folder, 'train_log_'+post_fix)\n",
    "    log_file = open(log_file_name, 'w')\n",
    "    log_file.write('g,d,nll,onehot\\n')\n",
    "    log_file.close()\n",
    "\n",
    "#     from shutil import copy\n",
    "#     copy('train.py', log_folder+'/train_%s.py'%post_fix)\n",
    "#     copy('progan_modules.py', log_folder+'/model_%s.py'%post_fix)\n",
    "\n",
    "    alpha = 0\n",
    "    #one = torch.FloatTensor([1]).to(device)\n",
    "    one = torch.tensor(1, dtype=torch.float).to(device)\n",
    "    mone = one * -1\n",
    "    iteration = 0\n",
    "\n",
    "    for i in pbar:\n",
    "        discriminator.zero_grad()\n",
    "\n",
    "        alpha = min(1, (2/(total_iter//6)) * iteration)\n",
    "\n",
    "        if iteration > total_iter//6:\n",
    "            alpha = 0\n",
    "            iteration = 0\n",
    "            step += 1\n",
    "\n",
    "            if step > 6:\n",
    "                alpha = 1\n",
    "                step = 6\n",
    "            data_loader = sample_data(loader, 4 * 2 ** step)\n",
    "            dataset = iter(data_loader)\n",
    "\n",
    "        try:\n",
    "            real_image, label = next(dataset)\n",
    "\n",
    "        except (OSError, StopIteration):\n",
    "            dataset = iter(data_loader)\n",
    "            real_image, label = next(dataset)\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "        ### 1. train Discriminator\n",
    "        b_size = real_image.size(0)\n",
    "        real_image = real_image.to(device)\n",
    "        label = label.to(device)\n",
    "        real_predict = discriminator(\n",
    "            real_image, step=step, alpha=alpha)\n",
    "        real_predict = real_predict.mean() \\\n",
    "            - 0.001 * (real_predict ** 2).mean()\n",
    "        real_predict.backward(mone)\n",
    "\n",
    "        # sample input data: vector for Generator\n",
    "        gen_z = torch.randn(b_size, input_code_size).to(device)\n",
    "\n",
    "        fake_image = generator(gen_z, step=step, alpha=alpha)\n",
    "        fake_predict = discriminator(\n",
    "            fake_image.detach(), step=step, alpha=alpha)\n",
    "        fake_predict = fake_predict.mean()\n",
    "        fake_predict.backward(one)\n",
    "\n",
    "        ### gradient penalty for D\n",
    "        eps = torch.rand(b_size, 1, 1, 1).to(device)\n",
    "        x_hat = eps * real_image.data + (1 - eps) * fake_image.detach().data\n",
    "        x_hat.requires_grad = True\n",
    "        hat_predict = discriminator(x_hat, step=step, alpha=alpha)\n",
    "        grad_x_hat = grad(\n",
    "            outputs=hat_predict.sum(), inputs=x_hat, create_graph=True)[0]\n",
    "        grad_penalty = ((grad_x_hat.view(grad_x_hat.size(0), -1)\n",
    "                         .norm(2, dim=1) - 1)**2).mean()\n",
    "        grad_penalty = 10 * grad_penalty\n",
    "        grad_penalty.backward()\n",
    "        grad_loss_val += grad_penalty.item()\n",
    "        disc_loss_val += (real_predict - fake_predict).item()\n",
    "\n",
    "        d_optimizer.step()\n",
    "\n",
    "        ### 2. train Generator\n",
    "        if (i + 1) % n_critic == 0:\n",
    "            generator.zero_grad()\n",
    "            discriminator.zero_grad()\n",
    "            \n",
    "            predict = discriminator(fake_image, step=step, alpha=alpha)\n",
    "\n",
    "            loss = -predict.mean()\n",
    "            gen_loss_val += loss.item()\n",
    "\n",
    "\n",
    "            loss.backward()\n",
    "            g_optimizer.step()\n",
    "            accumulate(g_running, generator)\n",
    "\n",
    "        if (i + 1) % 1000 == 0 or i==0:\n",
    "            with torch.no_grad():\n",
    "                images = g_running(torch.randn(5 * 10, input_code_size).to(device), step=step, alpha=alpha).data.cpu()\n",
    "                \n",
    "                utils.save_image(\n",
    "                    images,\n",
    "                    f'{log_folder}/sample/{str(i + 1).zfill(6)}.png',\n",
    "                    nrow=10,\n",
    "                    normalize=True,\n",
    "                    range=(-1, 1))\n",
    " \n",
    "        if (i+1) % 10000 == 0 or i==0:\n",
    "            try:\n",
    "                torch.save(g_running.state_dict(), f'{log_folder}/checkpoint/{str(i + 1).zfill(6)}_g.model')\n",
    "                torch.save(discriminator.state_dict(), f'{log_folder}/checkpoint/{str(i + 1).zfill(6)}_d.model')\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if (i+1)%500 == 0:\n",
    "            state_msg = (f'{i + 1}; G: {gen_loss_val/(500//n_critic):.3f}; D: {disc_loss_val/500:.3f};'\n",
    "                f' Grad: {grad_loss_val/500:.3f}; Alpha: {alpha:.3f}')\n",
    "            \n",
    "            log_file = open(log_file_name, 'a+')\n",
    "            new_line = \"%.5f,%.5f\"%(gen_loss_val/(500//n_critic), disc_loss_val/500) + f\"step: {step}, alpha: {alpha}, iter: {i}\\n\"\n",
    "            log_file.write(new_line)\n",
    "            log_file.close()\n",
    "\n",
    "            disc_loss_val = 0\n",
    "            gen_loss_val = 0\n",
    "            grad_loss_val = 0\n",
    "            \n",
    "#             sys.stdout.write(state_msg)\n",
    "#             sys.stdout.flush()\n",
    "            pbar.set_description(state_msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "73644848",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args_wrapper:\n",
    "    def __init__(self):\n",
    "        self.path = \"../data/celebb\"\n",
    "        self.trial_name = \"progressive_gans\"\n",
    "        self.z_dim = 100\n",
    "        self.channel = 512\n",
    "        self.batch_size = 4\n",
    "        self.init_step = 2\n",
    "        self.total_iter = 100000\n",
    "        self.pixel_norm=True\n",
    "        self.tanh=True\n",
    "        self.gpu_id=2\n",
    "        self.lr=0.001\n",
    "        self.n_critic=1\n",
    "        self.init_step=1\n",
    "               \n",
    "args = Args_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "41078410",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/celebb'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1e6c476d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## adding code to train for multiple gpus\n",
    "ngpu = torch.cuda.device_count()\n",
    "ngpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "e8551744",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Args_wrapper object at 0x7f1ce191b5e0>\n"
     ]
    }
   ],
   "source": [
    "print(str(args))\n",
    "\n",
    "trial_name = args.trial_name\n",
    "\n",
    "device = torch.device(\"cuda:%d\"%(args.gpu_id))\n",
    "\n",
    "input_code_size = args.z_dim\n",
    "batch_size = args.batch_size\n",
    "n_critic = args.n_critic\n",
    "\n",
    "generator = Generator(in_channel=args.channel, input_code_dim=input_code_size, pixel_norm=args.pixel_norm, tanh=args.tanh)\n",
    "#generator = nn.DataParallel(generator, list(range(ngpu)))\n",
    "generator = generator.to(device)\n",
    "\n",
    "discriminator = Discriminator(feat_dim=args.channel)\n",
    "#discriminator = nn.DataParallel(discriminator, list(range(ngpu)))\n",
    "discriminator = discriminator.to(device)\n",
    "\n",
    "g_running = Generator(in_channel=args.channel, input_code_dim=input_code_size, pixel_norm=args.pixel_norm, tanh=args.tanh).to(device)\n",
    "    \n",
    "    \n",
    "g_running.train(False)\n",
    "\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=args.lr, betas=(0.0, 0.99))\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=args.lr, betas=(0.0, 0.99))\n",
    "\n",
    "accumulate(g_running, generator, 0)\n",
    "\n",
    "loader = imagefolder_loader(args.path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "0ccb7670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "function"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2003ec5c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1500; G: 0.408; D: 0.403; Grad: 0.149; Alpha: 0.180:   2%| | 1681/100000 [01:04<"
     ]
    }
   ],
   "source": [
    "train(generator, discriminator, args.init_step, loader, args.total_iter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
