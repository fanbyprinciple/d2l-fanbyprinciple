{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9401beb4",
   "metadata": {},
   "source": [
    "https://github.com/odegeasslbc/Progressive-GAN-pytorch/blob/master/progan_modules.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e01af53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "\n",
    "class EqualLR:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def compute_weight(self, module):\n",
    "        weight = getattr(module, self.name + '_orig')\n",
    "        fan_in = weight.data.size(1) * weight.data[0][0].numel()\n",
    "\n",
    "        return weight * sqrt(2 / fan_in)\n",
    "\n",
    "    @staticmethod\n",
    "    def apply(module, name):\n",
    "        fn = EqualLR(name)\n",
    "\n",
    "        weight = getattr(module, name)\n",
    "        del module._parameters[name]\n",
    "        module.register_parameter(name + '_orig', nn.Parameter(weight.data))\n",
    "        module.register_forward_pre_hook(fn)\n",
    "\n",
    "        return fn\n",
    "\n",
    "    def __call__(self, module, input):\n",
    "        weight = self.compute_weight(module)\n",
    "        setattr(module, self.name, weight)\n",
    "\n",
    "\n",
    "def equal_lr(module, name='weight'):\n",
    "    EqualLR.apply(module, name)\n",
    "\n",
    "    return module\n",
    "\n",
    "\n",
    "class PixelNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input / torch.sqrt(torch.mean(input ** 2, dim=1, keepdim=True)\n",
    "                                  + 1e-8)\n",
    "\n",
    "\n",
    "class EqualConv2d(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        conv = nn.Conv2d(*args, **kwargs)\n",
    "        conv.weight.data.normal_()\n",
    "        conv.bias.data.zero_()\n",
    "        self.conv = equal_lr(conv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.conv(input)\n",
    "\n",
    "\n",
    "class EqualConvTranspose2d(nn.Module):\n",
    "    ### additional module for OOGAN usage\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        conv = nn.ConvTranspose2d(*args, **kwargs)\n",
    "        conv.weight.data.normal_()\n",
    "        conv.bias.data.zero_()\n",
    "        self.conv = equal_lr(conv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.conv(input)\n",
    "\n",
    "class EqualLinear(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        linear = nn.Linear(in_dim, out_dim)\n",
    "        linear.weight.data.normal_()\n",
    "        linear.bias.data.zero_()\n",
    "\n",
    "        self.linear = equal_lr(linear)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.linear(input)\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, padding, kernel_size2=None, padding2=None, pixel_norm=True):\n",
    "        super().__init__()\n",
    "\n",
    "        pad1 = padding\n",
    "        pad2 = padding\n",
    "        if padding2 is not None:\n",
    "            pad2 = padding2\n",
    "\n",
    "        kernel1 = kernel_size\n",
    "        kernel2 = kernel_size\n",
    "        if kernel_size2 is not None:\n",
    "            kernel2 = kernel_size2\n",
    "\n",
    "        convs = [EqualConv2d(in_channel, out_channel, kernel1, padding=pad1)]\n",
    "        if pixel_norm:\n",
    "            convs.append(PixelNorm())\n",
    "        convs.append(nn.LeakyReLU(0.1))\n",
    "        convs.append(EqualConv2d(out_channel, out_channel, kernel2, padding=pad2))\n",
    "        if pixel_norm:\n",
    "            convs.append(PixelNorm())\n",
    "        convs.append(nn.LeakyReLU(0.1))\n",
    "\n",
    "        self.conv = nn.Sequential(*convs)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.conv(input)\n",
    "        return out\n",
    "\n",
    "\n",
    "def upscale(feat):\n",
    "    return F.interpolate(feat, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_code_dim=128, in_channel=128, pixel_norm=True, tanh=True):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_code_dim\n",
    "        self.tanh = tanh\n",
    "        self.input_layer = nn.Sequential(\n",
    "            EqualConvTranspose2d(input_code_dim, in_channel, 4, 1, 0),\n",
    "            PixelNorm(),\n",
    "            nn.LeakyReLU(0.1))\n",
    "\n",
    "        self.progression_4 = ConvBlock(in_channel, in_channel, 3, 1, pixel_norm=pixel_norm)\n",
    "        self.progression_8 = ConvBlock(in_channel, in_channel, 3, 1, pixel_norm=pixel_norm)\n",
    "        self.progression_16 = ConvBlock(in_channel, in_channel, 3, 1, pixel_norm=pixel_norm)\n",
    "        self.progression_32 = ConvBlock(in_channel, in_channel, 3, 1, pixel_norm=pixel_norm)\n",
    "        self.progression_64 = ConvBlock(in_channel, in_channel//2, 3, 1, pixel_norm=pixel_norm)\n",
    "        self.progression_128 = ConvBlock(in_channel//2, in_channel//4, 3, 1, pixel_norm=pixel_norm)\n",
    "        self.progression_256 = ConvBlock(in_channel//4, in_channel//4, 3, 1, pixel_norm=pixel_norm)\n",
    "\n",
    "        self.to_rgb_8 = EqualConv2d(in_channel, 3, 1)\n",
    "        self.to_rgb_16 = EqualConv2d(in_channel, 3, 1)\n",
    "        self.to_rgb_32 = EqualConv2d(in_channel, 3, 1)\n",
    "        self.to_rgb_64 = EqualConv2d(in_channel//2, 3, 1)\n",
    "        self.to_rgb_128 = EqualConv2d(in_channel//4, 3, 1)\n",
    "        self.to_rgb_256 = EqualConv2d(in_channel//4, 3, 1)\n",
    "        \n",
    "        self.max_step = 6\n",
    "\n",
    "    def progress(self, feat, module):\n",
    "        out = F.interpolate(feat, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        out = module(out)\n",
    "        return out\n",
    "\n",
    "    def output(self, feat1, feat2, module1, module2, alpha):\n",
    "        if 0 <= alpha < 1:\n",
    "            skip_rgb = upscale(module1(feat1))\n",
    "            out = (1-alpha)*skip_rgb + alpha*module2(feat2)\n",
    "        else:\n",
    "            out = module2(feat2)\n",
    "        if self.tanh:\n",
    "            return torch.tanh(out)\n",
    "        return out\n",
    "\n",
    "    def forward(self, input, step=0, alpha=-1):\n",
    "        if step > self.max_step:\n",
    "            step = self.max_step\n",
    "\n",
    "        out_4 = self.input_layer(input.view(-1, self.input_dim, 1, 1))\n",
    "        out_4 = self.progression_4(out_4)\n",
    "        out_8 = self.progress(out_4, self.progression_8)\n",
    "        if step==1:\n",
    "            if self.tanh:\n",
    "                return torch.tanh(self.to_rgb_8(out_8))\n",
    "            return self.to_rgb_8(out_8)\n",
    "        \n",
    "        out_16 = self.progress(out_8, self.progression_16)\n",
    "        if step==2:\n",
    "            return self.output( out_8, out_16, self.to_rgb_8, self.to_rgb_16, alpha )\n",
    "        \n",
    "        out_32 = self.progress(out_16, self.progression_32)\n",
    "        if step==3:\n",
    "            return self.output( out_16, out_32, self.to_rgb_16, self.to_rgb_32, alpha )\n",
    "\n",
    "        out_64 = self.progress(out_32, self.progression_64)\n",
    "        if step==4:\n",
    "            return self.output( out_32, out_64, self.to_rgb_32, self.to_rgb_64, alpha )\n",
    "        \n",
    "        out_128 = self.progress(out_64, self.progression_128)\n",
    "        if step==5:\n",
    "            return self.output( out_64, out_128, self.to_rgb_64, self.to_rgb_128, alpha )\n",
    "\n",
    "        out_256 = self.progress(out_128, self.progression_256)\n",
    "        if step==6:\n",
    "            return self.output( out_128, out_256, self.to_rgb_128, self.to_rgb_256, alpha )\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, feat_dim=128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.progression = nn.ModuleList([ConvBlock(feat_dim//4, feat_dim//4, 3, 1),\n",
    "                                          ConvBlock(feat_dim//4, feat_dim//2, 3, 1),\n",
    "                                          ConvBlock(feat_dim//2, feat_dim, 3, 1),\n",
    "                                          ConvBlock(feat_dim, feat_dim, 3, 1),\n",
    "                                          ConvBlock(feat_dim, feat_dim, 3, 1),\n",
    "                                          ConvBlock(feat_dim, feat_dim, 3, 1),\n",
    "                                          ConvBlock(feat_dim+1, feat_dim, 3, 1, 4, 0)])\n",
    "\n",
    "        self.from_rgb = nn.ModuleList([EqualConv2d(3, feat_dim//4, 1),\n",
    "                                       EqualConv2d(3, feat_dim//4, 1),\n",
    "                                       EqualConv2d(3, feat_dim//2, 1),\n",
    "                                       EqualConv2d(3, feat_dim, 1),\n",
    "                                       EqualConv2d(3, feat_dim, 1),\n",
    "                                       EqualConv2d(3, feat_dim, 1),\n",
    "                                       EqualConv2d(3, feat_dim, 1)])\n",
    "\n",
    "        self.n_layer = len(self.progression)\n",
    "\n",
    "        self.linear = EqualLinear(feat_dim, 1)\n",
    "\n",
    "    def forward(self, input, step=0, alpha=-1):\n",
    "        for i in range(step, -1, -1):\n",
    "            index = self.n_layer - i - 1\n",
    "\n",
    "            if i == step:\n",
    "                out = self.from_rgb[index](input)\n",
    "\n",
    "            if i == 0:\n",
    "                out_std = torch.sqrt(out.var(0, unbiased=False) + 1e-8)\n",
    "                mean_std = out_std.mean()\n",
    "                mean_std = mean_std.expand(out.size(0), 1, 4, 4)\n",
    "                out = torch.cat([out, mean_std], 1)\n",
    "\n",
    "            out = self.progression[index](out)\n",
    "\n",
    "            if i > 0:\n",
    "                # out = F.avg_pool2d(out, 2)\n",
    "                out = F.interpolate(out, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
    "\n",
    "                if i == step and 0 <= alpha < 1:\n",
    "                    # skip_rgb = F.avg_pool2d(input, 2)\n",
    "                    skip_rgb = F.interpolate(input, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
    "                    skip_rgb = self.from_rgb[index + 1](skip_rgb)\n",
    "                    out = (1 - alpha) * skip_rgb + alpha * out\n",
    "\n",
    "        out = out.squeeze(2).squeeze(2)\n",
    "        # print(input.size(), out.size(), step)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb7f5e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import argparse\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable, grad\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms, utils\n",
    "\n",
    "\n",
    "\n",
    "def accumulate(model1, model2, decay=0.999):\n",
    "    par1 = dict(model1.named_parameters())\n",
    "    par2 = dict(model2.named_parameters())\n",
    "\n",
    "    for k in par1.keys():\n",
    "        par1[k].data.mul_(decay).add_(1 - decay, par2[k].data)\n",
    "\n",
    "\n",
    "def imagefolder_loader(path):\n",
    "    def loader(transform):\n",
    "        data = datasets.ImageFolder(path, transform=transform)\n",
    "        data_loader = DataLoader(data, shuffle=True, batch_size=batch_size,\n",
    "                                 num_workers=4)\n",
    "        return data_loader\n",
    "    return loader\n",
    "\n",
    "\n",
    "def sample_data(dataloader, image_size=4):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(image_size+int(image_size*0.2)+1),\n",
    "        transforms.RandomCrop(image_size),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "    ])\n",
    "\n",
    "    loader = dataloader(transform)\n",
    "\n",
    "    return loader\n",
    "\n",
    "\n",
    "def train(generator, discriminator, init_step, loader, total_iter=600000):\n",
    "    step = init_step # can be 1 = 8, 2 = 16, 3 = 32, 4 = 64, 5 = 128, 6 = 128\n",
    "    data_loader = sample_data(loader, 4 * 2 ** step)\n",
    "    dataset = iter(data_loader)\n",
    "\n",
    "    #total_iter = 600000\n",
    "    total_iter_remain = total_iter - (total_iter//6)*(step-1)\n",
    "\n",
    "    pbar = tqdm(range(total_iter_remain))\n",
    "\n",
    "    disc_loss_val = 0\n",
    "    gen_loss_val = 0\n",
    "    grad_loss_val = 0\n",
    "\n",
    "    from datetime import datetime\n",
    "    import os\n",
    "    date_time = datetime.now()\n",
    "    post_fix = '%s_%s_%d_%d.txt'%(trial_name, date_time.date(), date_time.hour, date_time.minute)\n",
    "    log_folder = 'trial_%s_%s_%d_%d'%(trial_name, date_time.date(), date_time.hour, date_time.minute)\n",
    "    \n",
    "    os.mkdir(log_folder)\n",
    "    os.mkdir(log_folder+'/checkpoint')\n",
    "    os.mkdir(log_folder+'/sample')\n",
    "\n",
    "    config_file_name = os.path.join(log_folder, 'train_config_'+post_fix)\n",
    "    config_file = open(config_file_name, 'w')\n",
    "    config_file.write(str(args))\n",
    "    config_file.close()\n",
    "\n",
    "    log_file_name = os.path.join(log_folder, 'train_log_'+post_fix)\n",
    "    log_file = open(log_file_name, 'w')\n",
    "    log_file.write('g,d,nll,onehot\\n')\n",
    "    log_file.close()\n",
    "\n",
    "#     from shutil import copy\n",
    "#     copy('train.py', log_folder+'/train_%s.py'%post_fix)\n",
    "#     copy('progan_modules.py', log_folder+'/model_%s.py'%post_fix)\n",
    "\n",
    "    alpha = 0\n",
    "    #one = torch.FloatTensor([1]).to(device)\n",
    "    one = torch.tensor(1, dtype=torch.float).to(device)\n",
    "    mone = one * -1\n",
    "    iteration = 0\n",
    "\n",
    "    for i in pbar:\n",
    "        discriminator.zero_grad()\n",
    "\n",
    "        alpha = min(1, (2/(total_iter//6)) * iteration)\n",
    "\n",
    "        if iteration > total_iter//6:\n",
    "            alpha = 0\n",
    "            iteration = 0\n",
    "            step += 1\n",
    "\n",
    "            if step > 6:\n",
    "                alpha = 1\n",
    "                step = 6\n",
    "            data_loader = sample_data(loader, 4 * 2 ** step)\n",
    "            dataset = iter(data_loader)\n",
    "\n",
    "        try:\n",
    "            real_image, label = next(dataset)\n",
    "\n",
    "        except (OSError, StopIteration):\n",
    "            dataset = iter(data_loader)\n",
    "            real_image, label = next(dataset)\n",
    "\n",
    "        iteration += 1\n",
    "\n",
    "        ### 1. train Discriminator\n",
    "        b_size = real_image.size(0)\n",
    "        real_image = real_image.to(device)\n",
    "        label = label.to(device)\n",
    "        real_predict = discriminator(\n",
    "            real_image, step=step, alpha=alpha)\n",
    "        real_predict = real_predict.mean() \\\n",
    "            - 0.001 * (real_predict ** 2).mean()\n",
    "        real_predict.backward(mone)\n",
    "\n",
    "        # sample input data: vector for Generator\n",
    "        gen_z = torch.randn(b_size, input_code_size).to(device)\n",
    "\n",
    "        fake_image = generator(gen_z, step=step, alpha=alpha)\n",
    "        fake_predict = discriminator(\n",
    "            fake_image.detach(), step=step, alpha=alpha)\n",
    "        fake_predict = fake_predict.mean()\n",
    "        fake_predict.backward(one)\n",
    "\n",
    "        ### gradient penalty for D\n",
    "        eps = torch.rand(b_size, 1, 1, 1).to(device)\n",
    "        x_hat = eps * real_image.data + (1 - eps) * fake_image.detach().data\n",
    "        x_hat.requires_grad = True\n",
    "        hat_predict = discriminator(x_hat, step=step, alpha=alpha)\n",
    "        grad_x_hat = grad(\n",
    "            outputs=hat_predict.sum(), inputs=x_hat, create_graph=True)[0]\n",
    "        grad_penalty = ((grad_x_hat.view(grad_x_hat.size(0), -1)\n",
    "                         .norm(2, dim=1) - 1)**2).mean()\n",
    "        grad_penalty = 10 * grad_penalty\n",
    "        grad_penalty.backward()\n",
    "        grad_loss_val += grad_penalty.item()\n",
    "        disc_loss_val += (real_predict - fake_predict).item()\n",
    "\n",
    "        d_optimizer.step()\n",
    "\n",
    "        ### 2. train Generator\n",
    "        if (i + 1) % n_critic == 0:\n",
    "            generator.zero_grad()\n",
    "            discriminator.zero_grad()\n",
    "            \n",
    "            predict = discriminator(fake_image, step=step, alpha=alpha)\n",
    "\n",
    "            loss = -predict.mean()\n",
    "            gen_loss_val += loss.item()\n",
    "\n",
    "\n",
    "            loss.backward()\n",
    "            g_optimizer.step()\n",
    "            accumulate(g_running, generator)\n",
    "\n",
    "        if (i + 1) % 1000 == 0 or i==0:\n",
    "            with torch.no_grad():\n",
    "                images = g_running(torch.randn(5 * 10, input_code_size).to(device), step=step, alpha=alpha).data.cpu()\n",
    "\n",
    "                utils.save_image(\n",
    "                    images,\n",
    "                    f'{log_folder}/sample/{str(i + 1).zfill(6)}.png',\n",
    "                    nrow=10,\n",
    "                    normalize=True,\n",
    "                    range=(-1, 1))\n",
    " \n",
    "        if (i+1) % 10000 == 0 or i==0:\n",
    "            try:\n",
    "                torch.save(g_running.state_dict(), f'{log_folder}/checkpoint/{str(i + 1).zfill(6)}_g.model')\n",
    "                torch.save(discriminator.state_dict(), f'{log_folder}/checkpoint/{str(i + 1).zfill(6)}_d.model')\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "        if (i+1)%500 == 0:\n",
    "            state_msg = (f'{i + 1}; G: {gen_loss_val/(500//n_critic):.3f}; D: {disc_loss_val/500:.3f};'\n",
    "                f' Grad: {grad_loss_val/500:.3f}; Alpha: {alpha:.3f}')\n",
    "            \n",
    "            log_file = open(log_file_name, 'a+')\n",
    "            new_line = \"%.5f,%.5f\\n\"%(gen_loss_val/(500//n_critic), disc_loss_val/500)\n",
    "            log_file.write(new_line)\n",
    "            log_file.close()\n",
    "\n",
    "            disc_loss_val = 0\n",
    "            gen_loss_val = 0\n",
    "            grad_loss_val = 0\n",
    "\n",
    "            print(state_msg)\n",
    "            #pbar.set_description(state_msg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ba9eb60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args_wrapper:\n",
    "    def __init__(self):\n",
    "        self.path = \"../data/celeba\"\n",
    "        self.trial_name = \"progressive_gans\"\n",
    "        self.z_dim = 100\n",
    "        self.channel = 512\n",
    "        self.batch_size = 4\n",
    "        self.init_step = 2\n",
    "        self.total_iter = 300000\n",
    "        self.pixel_norm=True\n",
    "        self.tanh=True\n",
    "        self.gpu_id=1\n",
    "        self.lr=0.001\n",
    "        self.n_critic=1\n",
    "        self.init_step=1\n",
    "               \n",
    "args = Args_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b736a93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../data/celeba'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4412a574",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Args_wrapper object at 0x7feaac4f5b50>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_131327/2648786968.py:21: UserWarning: This overload of add_ is deprecated:\n",
      "\tadd_(Number alpha, Tensor other)\n",
      "Consider using one of the following signatures instead:\n",
      "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /opt/conda/conda-bld/pytorch_1646756402876/work/torch/csrc/utils/python_arg_parser.cpp:1055.)\n",
      "  par1[k].data.mul_(decay).add_(1 - decay, par2[k].data)\n",
      "  0%|                                                | 0/300000 [00:00<?, ?it/s]"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'train.py'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 23>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m accumulate(g_running, generator, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     21\u001b[0m loader \u001b[38;5;241m=\u001b[39m imagefolder_loader(args\u001b[38;5;241m.\u001b[39mpath)\n\u001b[0;32m---> 23\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgenerator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdiscriminator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minit_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtotal_iter\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(generator, discriminator, init_step, loader, total_iter)\u001b[0m\n\u001b[1;32m     79\u001b[0m log_file\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mshutil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m copy\n\u001b[0;32m---> 82\u001b[0m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain.py\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog_folder\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/train_\u001b[39;49m\u001b[38;5;132;43;01m%s\u001b[39;49;00m\u001b[38;5;124;43m.py\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43mpost_fix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     83\u001b[0m copy(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprogan_modules.py\u001b[39m\u001b[38;5;124m'\u001b[39m, log_folder\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/model_\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m.py\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m%\u001b[39mpost_fix)\n\u001b[1;32m     85\u001b[0m alpha \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/shutil.py:427\u001b[0m, in \u001b[0;36mcopy\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(dst):\n\u001b[1;32m    426\u001b[0m     dst \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dst, os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mbasename(src))\n\u001b[0;32m--> 427\u001b[0m \u001b[43mcopyfile\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_symlinks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_symlinks\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    428\u001b[0m copymode(src, dst, follow_symlinks\u001b[38;5;241m=\u001b[39mfollow_symlinks)\n\u001b[1;32m    429\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m dst\n",
      "File \u001b[0;32m~/anaconda3/envs/myenv/lib/python3.9/shutil.py:264\u001b[0m, in \u001b[0;36mcopyfile\u001b[0;34m(src, dst, follow_symlinks)\u001b[0m\n\u001b[1;32m    262\u001b[0m     os\u001b[38;5;241m.\u001b[39msymlink(os\u001b[38;5;241m.\u001b[39mreadlink(src), dst)\n\u001b[1;32m    263\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 264\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m fsrc:\n\u001b[1;32m    265\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    266\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(dst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m fdst:\n\u001b[1;32m    267\u001b[0m                 \u001b[38;5;66;03m# macOS\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'train.py'"
     ]
    }
   ],
   "source": [
    "\n",
    "print(str(args))\n",
    "\n",
    "trial_name = args.trial_name\n",
    "device = torch.device(\"cuda:%d\"%(args.gpu_id))\n",
    "input_code_size = args.z_dim\n",
    "batch_size = args.batch_size\n",
    "n_critic = args.n_critic\n",
    "\n",
    "generator = Generator(in_channel=args.channel, input_code_dim=input_code_size, pixel_norm=args.pixel_norm, tanh=args.tanh).to(device)\n",
    "discriminator = Discriminator(feat_dim=args.channel).to(device)\n",
    "g_running = Generator(in_channel=args.channel, input_code_dim=input_code_size, pixel_norm=args.pixel_norm, tanh=args.tanh).to(device)\n",
    "    \n",
    "    \n",
    "g_running.train(False)\n",
    "\n",
    "g_optimizer = optim.Adam(generator.parameters(), lr=args.lr, betas=(0.0, 0.99))\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=args.lr, betas=(0.0, 0.99))\n",
    "\n",
    "accumulate(g_running, generator, 0)\n",
    "\n",
    "loader = imagefolder_loader(args.path)\n",
    "\n",
    "train(generator, discriminator, args.init_step, loader, args.total_iter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
