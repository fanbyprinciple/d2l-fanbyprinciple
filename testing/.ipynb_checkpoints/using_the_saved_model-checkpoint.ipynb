{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "c2490667",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch import nn, optim\n",
    "from math import sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "5d642047",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EqualLR:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "\n",
    "    def compute_weight(self, module):\n",
    "        weight = getattr(module, self.name + '_orig')\n",
    "        fan_in = weight.data.size(1) * weight.data[0][0].numel()\n",
    "\n",
    "        return weight * sqrt(2 / fan_in)\n",
    "\n",
    "    @staticmethod\n",
    "    def apply(module, name):\n",
    "        fn = EqualLR(name)\n",
    "\n",
    "        weight = getattr(module, name)\n",
    "        del module._parameters[name]\n",
    "        module.register_parameter(name + '_orig', nn.Parameter(weight.data))\n",
    "        module.register_forward_pre_hook(fn)\n",
    "\n",
    "        return fn\n",
    "\n",
    "    def __call__(self, module, input):\n",
    "        weight = self.compute_weight(module)\n",
    "        setattr(module, self.name, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "e78a7ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def equal_lr(module, name='weight'):\n",
    "    EqualLR.apply(module, name)\n",
    "\n",
    "    return module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "e231ab15",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PixelNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, input):\n",
    "        return input / torch.sqrt(torch.mean(input ** 2, dim=1, keepdim=True)\n",
    "                                  + 1e-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "169fca1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EqualConv2d(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        conv = nn.Conv2d(*args, **kwargs)\n",
    "        conv.weight.data.normal_()\n",
    "        conv.bias.data.zero_()\n",
    "        self.conv = equal_lr(conv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.conv(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "2afb363e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EqualConvTranspose2d(nn.Module):\n",
    "    ### additional module for OOGAN usage\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        conv = nn.ConvTranspose2d(*args, **kwargs)\n",
    "        conv.weight.data.normal_()\n",
    "        conv.bias.data.zero_()\n",
    "        self.conv = equal_lr(conv)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.conv(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "3703a72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EqualLinear(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "\n",
    "        linear = nn.Linear(in_dim, out_dim)\n",
    "        linear.weight.data.normal_()\n",
    "        linear.bias.data.zero_()\n",
    "\n",
    "        self.linear = equal_lr(linear)\n",
    "\n",
    "    def forward(self, input):\n",
    "        return self.linear(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "7675add8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, kernel_size, padding, kernel_size2=None, padding2=None, pixel_norm=True):\n",
    "        super().__init__()\n",
    "\n",
    "        pad1 = padding\n",
    "        pad2 = padding\n",
    "        if padding2 is not None:\n",
    "            pad2 = padding2\n",
    "\n",
    "        kernel1 = kernel_size\n",
    "        kernel2 = kernel_size\n",
    "        if kernel_size2 is not None:\n",
    "            kernel2 = kernel_size2\n",
    "\n",
    "        convs = [EqualConv2d(in_channel, out_channel, kernel1, padding=pad1)]\n",
    "        if pixel_norm:\n",
    "            convs.append(PixelNorm())\n",
    "        convs.append(nn.LeakyReLU(0.1))\n",
    "        convs.append(EqualConv2d(out_channel, out_channel, kernel2, padding=pad2))\n",
    "        if pixel_norm:\n",
    "            convs.append(PixelNorm())\n",
    "        convs.append(nn.LeakyReLU(0.1))\n",
    "\n",
    "        self.conv = nn.Sequential(*convs)\n",
    "\n",
    "    def forward(self, input):\n",
    "        out = self.conv(input)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "3dba7b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def upscale(feat):\n",
    "    return F.interpolate(feat, scale_factor=2, mode='bilinear', align_corners=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "7ce97f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_code_dim=128, in_channel=128, pixel_norm=True, tanh=True):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_code_dim\n",
    "        self.tanh = tanh\n",
    "        self.input_layer = nn.Sequential(\n",
    "            EqualConvTranspose2d(input_code_dim, in_channel, 4, 1, 0),\n",
    "            PixelNorm(),\n",
    "            nn.LeakyReLU(0.1))\n",
    "\n",
    "        self.progression_4 = ConvBlock(in_channel, in_channel, 3, 1, pixel_norm=pixel_norm)\n",
    "        self.progression_8 = ConvBlock(in_channel, in_channel, 3, 1, pixel_norm=pixel_norm)\n",
    "        self.progression_16 = ConvBlock(in_channel, in_channel, 3, 1, pixel_norm=pixel_norm)\n",
    "        self.progression_32 = ConvBlock(in_channel, in_channel, 3, 1, pixel_norm=pixel_norm)\n",
    "        self.progression_64 = ConvBlock(in_channel, in_channel//2, 3, 1, pixel_norm=pixel_norm)\n",
    "        self.progression_128 = ConvBlock(in_channel//2, in_channel//4, 3, 1, pixel_norm=pixel_norm)\n",
    "        self.progression_256 = ConvBlock(in_channel//4, in_channel//4, 3, 1, pixel_norm=pixel_norm)\n",
    "\n",
    "        self.to_rgb_8 = EqualConv2d(in_channel, 3, 1)\n",
    "        self.to_rgb_16 = EqualConv2d(in_channel, 3, 1)\n",
    "        self.to_rgb_32 = EqualConv2d(in_channel, 3, 1)\n",
    "        self.to_rgb_64 = EqualConv2d(in_channel//2, 3, 1)\n",
    "        self.to_rgb_128 = EqualConv2d(in_channel//4, 3, 1)\n",
    "        self.to_rgb_256 = EqualConv2d(in_channel//4, 3, 1)\n",
    "        \n",
    "        self.max_step = 6\n",
    "\n",
    "    def progress(self, feat, module):\n",
    "        out = F.interpolate(feat, scale_factor=2, mode='bilinear', align_corners=False)\n",
    "        out = module(out)\n",
    "        return out\n",
    "\n",
    "    def output(self, feat1, feat2, module1, module2, alpha):\n",
    "        if 0 <= alpha < 1:\n",
    "            skip_rgb = upscale(module1(feat1))\n",
    "            out = (1-alpha)*skip_rgb + alpha*module2(feat2)\n",
    "        else:\n",
    "            out = module2(feat2)\n",
    "        if self.tanh:\n",
    "            return torch.tanh(out)\n",
    "        return out\n",
    "\n",
    "    def forward(self, input, step=0, alpha=-1):\n",
    "        if step > self.max_step:\n",
    "            step = self.max_step\n",
    "\n",
    "        out_4 = self.input_layer(input.view(-1, self.input_dim, 1, 1))\n",
    "        out_4 = self.progression_4(out_4)\n",
    "        out_8 = self.progress(out_4, self.progression_8)\n",
    "        if step==1:\n",
    "            if self.tanh:\n",
    "                return torch.tanh(self.to_rgb_8(out_8))\n",
    "            return self.to_rgb_8(out_8)\n",
    "        \n",
    "        out_16 = self.progress(out_8, self.progression_16)\n",
    "        if step==2:\n",
    "            return self.output( out_8, out_16, self.to_rgb_8, self.to_rgb_16, alpha )\n",
    "        \n",
    "        out_32 = self.progress(out_16, self.progression_32)\n",
    "        if step==3:\n",
    "            return self.output( out_16, out_32, self.to_rgb_16, self.to_rgb_32, alpha )\n",
    "\n",
    "        out_64 = self.progress(out_32, self.progression_64)\n",
    "        if step==4:\n",
    "            return self.output( out_32, out_64, self.to_rgb_32, self.to_rgb_64, alpha )\n",
    "        \n",
    "        out_128 = self.progress(out_64, self.progression_128)\n",
    "        if step==5:\n",
    "            return self.output( out_64, out_128, self.to_rgb_64, self.to_rgb_128, alpha )\n",
    "\n",
    "        out_256 = self.progress(out_128, self.progression_256)\n",
    "        if step==6:\n",
    "            return self.output( out_128, out_256, self.to_rgb_128, self.to_rgb_256, alpha )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "bb2c18ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, feat_dim=128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.progression = nn.ModuleList([ConvBlock(feat_dim//4, feat_dim//4, 3, 1),\n",
    "                                          ConvBlock(feat_dim//4, feat_dim//2, 3, 1),\n",
    "                                          ConvBlock(feat_dim//2, feat_dim, 3, 1),\n",
    "                                          ConvBlock(feat_dim, feat_dim, 3, 1),\n",
    "                                          ConvBlock(feat_dim, feat_dim, 3, 1),\n",
    "                                          ConvBlock(feat_dim, feat_dim, 3, 1),\n",
    "                                          ConvBlock(feat_dim+1, feat_dim, 3, 1, 4, 0)])\n",
    "\n",
    "        self.from_rgb = nn.ModuleList([EqualConv2d(3, feat_dim//4, 1),\n",
    "                                       EqualConv2d(3, feat_dim//4, 1),\n",
    "                                       EqualConv2d(3, feat_dim//2, 1),\n",
    "                                       EqualConv2d(3, feat_dim, 1),\n",
    "                                       EqualConv2d(3, feat_dim, 1),\n",
    "                                       EqualConv2d(3, feat_dim, 1),\n",
    "                                       EqualConv2d(3, feat_dim, 1)])\n",
    "\n",
    "        self.n_layer = len(self.progression)\n",
    "\n",
    "        self.linear = EqualLinear(feat_dim, 1)\n",
    "\n",
    "    def forward(self, input, step=0, alpha=-1):\n",
    "        for i in range(step, -1, -1):\n",
    "            index = self.n_layer - i - 1\n",
    "\n",
    "            if i == step:\n",
    "                out = self.from_rgb[index](input)\n",
    "\n",
    "            if i == 0:\n",
    "                out_std = torch.sqrt(out.var(0, unbiased=False) + 1e-8)\n",
    "                mean_std = out_std.mean()\n",
    "                mean_std = mean_std.expand(out.size(0), 1, 4, 4)\n",
    "                out = torch.cat([out, mean_std], 1)\n",
    "\n",
    "            out = self.progression[index](out)\n",
    "\n",
    "            if i > 0:\n",
    "                # out = F.avg_pool2d(out, 2)\n",
    "                out = F.interpolate(out, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
    "\n",
    "                if i == step and 0 <= alpha < 1:\n",
    "                    # skip_rgb = F.avg_pool2d(input, 2)\n",
    "                    skip_rgb = F.interpolate(input, scale_factor=0.5, mode='bilinear', align_corners=False)\n",
    "                    skip_rgb = self.from_rgb[index + 1](skip_rgb)\n",
    "                    out = (1 - alpha) * skip_rgb + alpha * out\n",
    "\n",
    "        out = out.squeeze(2).squeeze(2)\n",
    "        # print(input.size(), out.size(), step)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "7b22f303",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accumulate(model1, model2, decay=0.999):\n",
    "    par1 = dict(model1.named_parameters())\n",
    "    par2 = dict(model2.named_parameters())\n",
    "    \n",
    "    for k in par1.keys():\n",
    "        par1[k].data.mul_(decay).add_(1 - decay, par2[k].data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "8a705fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args_wrapper:\n",
    "    def __init__(self):\n",
    "        self.path = \"../data/celebb\"\n",
    "        self.trial_name = \"progressive_gans\"\n",
    "        self.z_dim = 100\n",
    "        self.channel = 512\n",
    "        self.batch_size = 4\n",
    "        self.init_step = 2\n",
    "        self.total_iter = 100000\n",
    "        self.pixel_norm=True\n",
    "        self.tanh=True\n",
    "        self.gpu_id=2\n",
    "        self.lr=0.001\n",
    "        self.n_critic=1\n",
    "        self.init_step=1\n",
    "               \n",
    "args = Args_wrapper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "6f698a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.Args_wrapper object at 0x7f2bd36f2c70>\n"
     ]
    }
   ],
   "source": [
    "print(str(args))\n",
    "\n",
    "trial_name = args.trial_name\n",
    "\n",
    "device = torch.device(\"cuda:%d\"%(args.gpu_id))\n",
    "\n",
    "input_code_size = args.z_dim\n",
    "batch_size = args.batch_size\n",
    "n_critic = args.n_critic\n",
    "\n",
    "generator = Generator(in_channel=args.channel, input_code_dim=input_code_size, pixel_norm=args.pixel_norm, tanh=args.tanh)\n",
    "#generator = nn.DataParallel(generator, list(range(ngpu)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "bacfefc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = Discriminator(feat_dim=args.channel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "d89020d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_running = Generator(in_channel=args.channel, input_code_dim=input_code_size, pixel_norm=args.pixel_norm, tanh=args.tanh).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "fba3b751",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_optimizer = optim.Adam(generator.parameters(), lr=args.lr, betas=(0.0, 0.99))\n",
    "d_optimizer = optim.Adam(discriminator.parameters(), lr=args.lr, betas=(0.0, 0.99))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "c57f10af",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_PATH = \"/home/misthios/Documents/d2l-fanbyprinciple/testing/trial_progressive_gans_2022-04-20_15_8/checkpoint/150000_g.model\"\n",
    "D_PATH = \"/home/misthios/Documents/d2l-fanbyprinciple/testing/trial_progressive_gans_2022-04-20_15_8/checkpoint/150000_d.model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "8d5992d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_checkpoint = torch.load(G_PATH)\n",
    "D_checkpoint = torch.load(D_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "b071bbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "odict_keys(['input_layer.0.conv.bias', 'input_layer.0.conv.weight_orig', 'progression_4.conv.0.conv.bias', 'progression_4.conv.0.conv.weight_orig', 'progression_4.conv.3.conv.bias', 'progression_4.conv.3.conv.weight_orig', 'progression_8.conv.0.conv.bias', 'progression_8.conv.0.conv.weight_orig', 'progression_8.conv.3.conv.bias', 'progression_8.conv.3.conv.weight_orig', 'progression_16.conv.0.conv.bias', 'progression_16.conv.0.conv.weight_orig', 'progression_16.conv.3.conv.bias', 'progression_16.conv.3.conv.weight_orig', 'progression_32.conv.0.conv.bias', 'progression_32.conv.0.conv.weight_orig', 'progression_32.conv.3.conv.bias', 'progression_32.conv.3.conv.weight_orig', 'progression_64.conv.0.conv.bias', 'progression_64.conv.0.conv.weight_orig', 'progression_64.conv.3.conv.bias', 'progression_64.conv.3.conv.weight_orig', 'progression_128.conv.0.conv.bias', 'progression_128.conv.0.conv.weight_orig', 'progression_128.conv.3.conv.bias', 'progression_128.conv.3.conv.weight_orig', 'progression_256.conv.0.conv.bias', 'progression_256.conv.0.conv.weight_orig', 'progression_256.conv.3.conv.bias', 'progression_256.conv.3.conv.weight_orig', 'to_rgb_8.conv.bias', 'to_rgb_8.conv.weight_orig', 'to_rgb_16.conv.bias', 'to_rgb_16.conv.weight_orig', 'to_rgb_32.conv.bias', 'to_rgb_32.conv.weight_orig', 'to_rgb_64.conv.bias', 'to_rgb_64.conv.weight_orig', 'to_rgb_128.conv.bias', 'to_rgb_128.conv.weight_orig', 'to_rgb_256.conv.bias', 'to_rgb_256.conv.weight_orig'])"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "G_checkpoint.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "853506a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g_running.load_state_dict(G_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "fc975393",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "discriminator.load_state_dict(D_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "380790fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.8784, -2.1372, -0.5575,  ...,  0.5112,  0.4631, -0.6862],\n",
       "        [ 0.2292, -1.1222,  0.2686,  ...,  1.8446, -0.1479, -0.2290],\n",
       "        [-0.5751, -1.1901,  0.3560,  ...,  1.0936,  0.0292, -0.2377],\n",
       "        ...,\n",
       "        [ 1.1955,  0.8432, -0.2938,  ..., -1.7986,  0.1316,  0.7277],\n",
       "        [-0.6199, -0.9528,  1.0585,  ...,  1.1389,  0.4161,  0.6267],\n",
       "        [-0.5158, -0.7683, -0.3314,  ...,  0.3381,  0.3096,  1.3006]])"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.randn(50, input_code_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "b0ed1846",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "72855414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generating images from GAN\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for i in range(1,20):\n",
    "#         for j in range(1,10):\n",
    "#             well = g_running(torch.randn(5*10, input_code_size).to(device),step=i, alpha=j)\n",
    "#             images = well.data.cpu()\n",
    "   \n",
    "#             utils.save_image(images,f'sample/output_{j}_{i}.png',nrow=10,normalize=True,range=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12f282d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    for i in range(1,100):\n",
    "        well = g_running(torch.randn(5*10, input_code_size).to(device),step=i, alpha=3)\n",
    "        images = well.data.cpu()\n",
    "   \n",
    "        utils.save_image(images,f'sample/output_{i}.png',nrow=10,normalize=True,range=(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "a96b0058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 3, 128, 128])"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "a94df7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n",
    "from PIL import Image\n",
    "\n",
    "import torch \n",
    "import torchvision \n",
    "import torchvision.transforms as T \n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "e9757617",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128, 3])"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = images[random.choice(range(len(images)))].permute(1,2,0)\n",
    "image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "96bf1619",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.3300, -0.7495, -0.8336],\n",
       "         [-0.1920, -0.7292, -0.8867],\n",
       "         [-0.3949, -0.8221, -0.8951],\n",
       "         ...,\n",
       "         [-0.6640,  0.0598, -0.8246],\n",
       "         [-0.6572,  0.4752, -0.3779],\n",
       "         [-0.6547,  0.5924, -0.0616]],\n",
       "\n",
       "        [[ 0.0699, -0.7656, -0.8919],\n",
       "         [-0.3734, -0.7808, -0.8897],\n",
       "         [-0.6226, -0.7853, -0.9135],\n",
       "         ...,\n",
       "         [-0.8086, -0.0013, -0.8118],\n",
       "         [-0.8458,  0.2582, -0.3757],\n",
       "         [-0.6873,  0.3565, -0.1776]],\n",
       "\n",
       "        [[ 0.2562, -0.7732, -0.8194],\n",
       "         [-0.3267, -0.8363, -0.7066],\n",
       "         [-0.6636, -0.8369, -0.7521],\n",
       "         ...,\n",
       "         [-0.8078, -0.2446, -0.7564],\n",
       "         [-0.9036, -0.1636, -0.4582],\n",
       "         [-0.8638, -0.1054, -0.2646]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[ 0.7367, -0.4961, -0.1694],\n",
       "         [ 0.2487, -0.7649, -0.4509],\n",
       "         [-0.1515, -0.8378, -0.6042],\n",
       "         ...,\n",
       "         [-0.4168, -0.6379, -0.1905],\n",
       "         [-0.0760, -0.4377, -0.3842],\n",
       "         [-0.3912, -0.4277, -0.6551]],\n",
       "\n",
       "        [[ 0.7200, -0.4255, -0.0313],\n",
       "         [ 0.3843, -0.7545, -0.2651],\n",
       "         [ 0.0594, -0.8380, -0.3600],\n",
       "         ...,\n",
       "         [-0.5826, -0.7916, -0.3206],\n",
       "         [-0.1167, -0.5449, -0.3298],\n",
       "         [-0.3105, -0.5990, -0.6811]],\n",
       "\n",
       "        [[ 0.6819, -0.2603,  0.0484],\n",
       "         [ 0.5154, -0.4944, -0.1295],\n",
       "         [ 0.1817, -0.6759, -0.1989],\n",
       "         ...,\n",
       "         [-0.4775, -0.7556, -0.5839],\n",
       "         [ 0.0347, -0.6509, -0.7293],\n",
       "         [ 0.0503, -0.4760, -0.8087]]])"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "90a16bdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(image * 1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "20ebbdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "5e489785",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = transform(images[random.choice(range(len(images)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "45fb3f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "ed7a00e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## openning a normal image\n",
    "im = Image.open(r\"gan.png\") \n",
    "  \n",
    "# This method will show image in any image viewer \n",
    "#im.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "6d5f9ee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = T.Compose([T.PILToTensor()])\n",
    "\n",
    "tensor = transform(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b94ec12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[184,  91,  81,  ..., 170, 158, 181],\n",
       "         [107,  52,  36,  ...,  58,  72,  70],\n",
       "         [113,  51,  25,  ...,  24,  36,  33],\n",
       "         ...,\n",
       "         [ 61,  35,  59,  ..., 145,   7, 234],\n",
       "         [ 41,  39,  47,  ..., 108, 228, 206],\n",
       "         [ 30,  22,  33,  ..., 100, 203, 232]],\n",
       "\n",
       "        [[108, 115,  78,  ..., 223, 227, 198],\n",
       "         [103, 117, 105,  ..., 193, 166, 155],\n",
       "         [101, 108, 102,  ..., 141, 114, 116],\n",
       "         ...,\n",
       "         [ 66,  47,  44,  ...,  62,  78,  58],\n",
       "         [ 52,  41,  46,  ...,  35,  69,  47],\n",
       "         [ 37,  44,  88,  ...,  30,  42,  49]],\n",
       "\n",
       "        [[ 41,  23,  21,  ...,  59, 122, 235],\n",
       "         [ 26,  24,  25,  ...,  69, 136, 177],\n",
       "         [ 48,  63,  86,  ...,  63, 112, 145],\n",
       "         ...,\n",
       "         [ 55,   4,  43,  ..., 246, 191, 117],\n",
       "         [ 40, 226, 252,  ..., 184, 181,  92],\n",
       "         [ 85,  39,  18,  ..., 119,  79,  55]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "1ce2ddf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this for training models\n",
    "\n",
    "# model = TheModelClass(*args, **kwargs)\n",
    "# optimizer = TheOptimizerClass(*args, **kwargs)\n",
    "\n",
    "# checkpoint = torch.load(PATH)\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "# optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "# epoch = checkpoint['epoch']\n",
    "# loss = checkpoint['loss']\n",
    "\n",
    "# model.eval()\n",
    "# # - or -\n",
    "# model.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
