{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "academic-departure",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import nn\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "smart-communications",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_steps = 32, 35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "soviet-formula",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#!curl --output pap.txt https://www.gutenberg.org/files/1342/1342-0.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "lonely-identity",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "def read_text(text_name='pap.txt'):\n",
    "    with open(text_name, 'r', encoding='utf-8') as text_input:\n",
    "        lines = text_input.readlines()\n",
    "    \n",
    "    return [re.sub('[^A-Za-z]+', ' ', line).strip().lower() for line in lines] # only alphabets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "failing-thursday",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_input = read_text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "contemporary-serial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the project gutenberg ebook of pride and prejudice by jane austen',\n",
       " '',\n",
       " 'this ebook is for the use of anyone anywhere in the united states and',\n",
       " 'most other parts of the world at no cost and with almost no restrictions',\n",
       " 'whatsoever you may copy it give it away or re use it under the terms']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_input[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "confidential-encyclopedia",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(lines, token_type='word'):\n",
    "    if token_type == 'char':\n",
    "        return [list(line) for line in lines]\n",
    "    elif token_type == 'word':\n",
    "        return [line.split() for line in lines]\n",
    "    else:\n",
    "        'Wrong token type.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "intermediate-console",
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "def count_corpus(tokens):\n",
    "    tokens = [token for line in tokens for token in line]\n",
    "    return collections.Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "grand-retreat",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defined in file: ./chapter_recurrent-neural-networks/text-preprocessing.md\n",
    "class Vocab:\n",
    "    def __init__(self, tokens=None,min_freq=0):\n",
    "        if tokens == None:\n",
    "            tokens = []\n",
    "        \n",
    "        tokens = [token for line in tokens for token in line]\n",
    "        counter = collections.Counter(tokens)\n",
    "        \n",
    "        self._token_freqs = sorted(counter.items(),key=lambda x:x[1], reverse=True)\n",
    "        self.idx_to_token = ['<unk>']\n",
    "        self.token_to_idx = { token:idx for idx, token in enumerate(self.idx_to_token)}\n",
    "        \n",
    "        for token, freq in self._token_freqs:\n",
    "            if freq < min_freq:\n",
    "                #print(f\"for {freq} : {token} breaking\")\n",
    "                continue\n",
    "            elif token not in self.idx_to_token:\n",
    "                #print(token + \"adding\")\n",
    "                self.idx_to_token.append(token)\n",
    "                self.token_to_idx[token] = len(self.idx_to_token)-1\n",
    "            else:\n",
    "                print(token + \" found already\")\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.idx_to_token)\n",
    "    \n",
    "    def __getitem__(self, tokens):\n",
    "        if isinstance(tokens, list):\n",
    "            return_list = []\n",
    "            for t in tokens:\n",
    "                for token in t:\n",
    "                    if token in self.token_to_idx.keys():\n",
    "                        return_list.append(self.token_to_idx[token])\n",
    "                    else:\n",
    "                        return_list.append(self.unk)\n",
    "            return return_list\n",
    "        else:\n",
    "            if tokens in self.token_to_idx.keys():\n",
    "                return self.token_to_idx[tokens]\n",
    "            else:\n",
    "                return self.unk\n",
    "            \n",
    "    def to_tokens(self, indices):\n",
    "        return [self.idx_to_token[index] for index in indices]\n",
    "\n",
    "    @property\n",
    "    def unk(self):  # Index for the unknown token\n",
    "        return 0\n",
    "\n",
    "    @property\n",
    "    def token_freqs(self):  # Index for the unknown token\n",
    "        return self._token_freqs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "occupied-johns",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['the',\n",
       "  'project',\n",
       "  'gutenberg',\n",
       "  'ebook',\n",
       "  'of',\n",
       "  'pride',\n",
       "  'and',\n",
       "  'prejudice',\n",
       "  'by',\n",
       "  'jane',\n",
       "  'austen']]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = tokenize(text_input)\n",
    "tokens[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "photographic-biography",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokens = [token for line in tokens for token in line]\n",
    "# tokens[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "outer-bracket",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vocab = Vocab(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "crucial-stuart",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('the', 4521)\n"
     ]
    }
   ],
   "source": [
    "for i in vocab.token_freqs:\n",
    "    if i[0] == 'the':\n",
    "        print(i)\n",
    "# print(vocab.token_freqs)\n",
    "# vocab.token_to_idx\n",
    "\n",
    "# the error is that we are using the entire sentece for creating token\n",
    "# problem in tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "moving-antigua",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "visible-messenger",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 4521), ('to', 4246), ('of', 3735), ('and', 3657), ('her', 2226)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.token_freqs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "grand-silver",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_corpus(max_tokens=-1, text_input=text_input):\n",
    "    tokens = tokenize(text_input)\n",
    "    vocab = Vocab(tokens)\n",
    "    \n",
    "    corpus = [vocab[token] for line in tokens for token in line]\n",
    "    if max_tokens > 0:\n",
    "        corpus = corpus[:max_tokens]\n",
    "    return corpus, vocab\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "behind-wrist",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus, vocab = load_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "negative-memphis",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqDataLoader:\n",
    "    def __init__(self, batch_size, num_steps, use_random_iter, max_tokens):\n",
    "        if use_random_iter:\n",
    "            self.data_iter_fn = seq_data_iter_random\n",
    "        else :\n",
    "            self.data_iter_fn = seq_data_iter_sequential\n",
    "        \n",
    "        self.corpus, self.vocab = load_corpus(max_tokens=max_tokens)\n",
    "        self.batch_size, self.num_steps = batch_size, num_steps\n",
    "    \n",
    "    def __iter__(self):\n",
    "        return self.data_iter_fn(self.corpus, self.batch_size, self.steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "annoying-flush",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_data_iter_random(corpus, batch_size, num_steps):\n",
    "    print(\"Dont use random seq data iter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "indonesian-casino",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "num_steps = 5\n",
    "batch_size=5\n",
    "offset = random.randint(0, num_steps)\n",
    "    \n",
    "print(offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "greek-equity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126014"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)-offset-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "czech-median",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "126010"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_tokens = (len(corpus) -offset -1)//batch_size * batch_size # ensuring num_tokens is perfectly divisible\n",
    "num_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "flying-pavilion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126010, tensor([ 317,    4, 1159,   31,   69]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs = torch.tensor(corpus[offset:offset+num_tokens])\n",
    "len(Xs),Xs[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "american-success",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(126010, tensor([   4, 1159,   31,   69, 2494]))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ys = torch.tensor(corpus[offset+1:offset+1+num_tokens])\n",
    "len(Ys),Ys[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "changed-region",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " tensor([[ 317,    4, 1159,  ...,   44,  415,    3],\n",
       "         [ 407,   23,   72,  ...,  438,   11,    1],\n",
       "         [ 800,    3,   53,  ...,   41,  173,    8],\n",
       "         [ 470, 5558,   54,  ...,   33,    9,  417],\n",
       "         [   3,   12,  170,  ...,  198, 4057, 6522]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs = Xs.reshape(batch_size,-1)\n",
    "len(Xs), Xs[:5]\n",
    "\n",
    "# okay Xs devided into 5 batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "starting-institution",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5040"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_batches = Xs.shape[1]//num_steps\n",
    "num_batches\n",
    "\n",
    "# these many times we will go through the sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "laden-arrangement",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_data_iter_sequential(corpus, batch_size, num_steps):\n",
    "    offset = random.randint(0, num_steps)\n",
    "    num_tokens = ((len(corpus)-offset-1)//batch_size)*batch_size\n",
    "    \n",
    "    Xs = torch.tensor(corpus[offset:offset + num_tokens])\n",
    "    Ys = torch.tensor(corpus[offset + 1:offset + 1 + num_tokens])\n",
    "    Xs, Ys = Xs.reshape(batch_size, -1), Ys.reshape(batch_size, -1)\n",
    "    num_batches = Xs.shape[1]//num_steps\n",
    "    for i in range(0, num_steps * num_batches, num_steps):\n",
    "        Xs = Xs[i:i+num_steps]\n",
    "        Ys = Ys[i:i+num_steps]\n",
    "        yield X, Y\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "political-insulin",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(batch_size, num_steps, use_random_iter=False, max_tokens=10000):\n",
    "    data_iter = SeqDataLoader(batch_size, num_steps, use_random_iter, max_tokens)\n",
    "    \n",
    "    return data_iter, data_iter.vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "intermediate-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size, num_steps = 32, 35\n",
    "train_iter, vocab = load_data(batch_size, num_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "saving-joining",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 1,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one hot encoding\n",
    "\n",
    "F.one_hot(torch.tensor([0,2]), len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "thirty-camel",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 2, 28])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.arange(10).reshape((2,5))\n",
    "F.one_hot(X.T, 28,).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "forced-nepal",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(vocab_size, num_hiddens, device):\n",
    "    num_inputs = num_outputs = num_hiddens\n",
    "    \n",
    "    def normal(shape):\n",
    "        return torch.randn(size=shape, device=device)\n",
    "    \n",
    "    W_xh = normal((num_inputs, num_hiddens))\n",
    "    W_hh = normal((num_hiddens, num_hiddens))\n",
    "    b_h = torch.zeros(num_hiddens, device=device)\n",
    "    \n",
    "    W_hq = normal((num_hiddens, num_outputs))\n",
    "    b_q = torch.zeros(num_outputs, device=device)\n",
    "    \n",
    "    params = [W_xh, W_hh, b_h, W_hq, b_q]\n",
    "    for param in params:\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "veterinary-idaho",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a torch of zeros\n",
    "def init_rnn_state(batch_size, num_hiddens, device):\n",
    "    return (torch.zeros((batch_size, num_hiddens), device=device),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "disturbed-lying",
   "metadata": {},
   "outputs": [],
   "source": [
    "#computing hidden state ans output in a time step\n",
    "def rnn(inputs, state, params):\n",
    "    W_xh, W_hh, b_h, W_hq, b_q = params\n",
    "    H, = state\n",
    "    outputs = []\n",
    "    \n",
    "    for X in inputs:\n",
    "        H = torch.tanh(torch.mm(X, W_xh) + torch.mm(H, W_hh) + b_h)\n",
    "        Y = torch.mm(H, W_hq) + b_q\n",
    "        outputs.append(Y)\n",
    "    return torch.cat(outputs, dim=0), (H,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "statutory-classroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class to wrap up the functions and state togeter\n",
    "\n",
    "class RNNModelScratch:\n",
    "    def __init__(self, vocab_size, num_hiddens, device, get_params, init_state, forward_fn ):\n",
    "        self.vocab_size, self.num_hiddens = vocab_size, num_hiddens\n",
    "        self.params = get_params(self.vocab_size, num_hiddens, device)\n",
    "        self.init_state, self.forward_fn = init_state, forward_fn\n",
    "    \n",
    "    def __call__(self, X, state):\n",
    "        X = F.one_hot(X.T, self.vocab_size).type(torch.float32)\n",
    "        return self.forward_fn(X, state, self.params)\n",
    "    \n",
    "    def begin_state(self, batch_size, device):\n",
    "        return self.init_state(batch_size, self.num_hiddens, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "interior-prospect",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking if output gave fixd dusze\n",
    "num_hiddens = 512\n",
    "net = RNNModelScratch(len(vocab), num_hiddens, torch.device('cuda'), get_params, init_rnn_state, rnn)\n",
    "state = net.begin_state(X.shape[0], torch.device('cuda'))\n",
    "Y,new_state = net(X.to(torch.device('cuda')), state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "instructional-table",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 512]), 1, torch.Size([2, 512]))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape, len(new_state), new_state[0].shape\n",
    "\n",
    "#We can see that the output shape is (number of time steps × batch size, vocabulary size), \n",
    "#while the hidden state shape remains the same, i.e., (batch size, number of hidden units).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "whole-gazette",
   "metadata": {},
   "source": [
    "Let us first define the prediction function to generate new characters following the user-provided\n",
    "prefix, which is a string containing several characters. When looping through these beginning\n",
    "characters in prefix, we keep passing the hidden state to the next time step without generating\n",
    "any output. This is called the warm-up period, during which the model updates itself (e.g., update\n",
    "the hidden state) but does not make predictions. After the warm-up period, the hidden state is\n",
    "generally better than its initialized value at the beginning. So we generate the predicted characters\n",
    "and emit them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "sunset-polish",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_ch8(prefix, num_preds, net, vocab, device):\n",
    "    state = net.begin_state(batch_size=1, device=device)\n",
    "    outputs = [vocab[prefix[0]]]\n",
    "    get_input = lambda: torch.tensor([outputs[-1]], device=device).reshape((1,1))\n",
    "    for y in prefix[1:]:\n",
    "        _, state = net(get_input(), state)\n",
    "        outputs.append(vocab[y])\n",
    "    \n",
    "    for _ in range(num_preds):\n",
    "        y, state = net(get_input(), state)\n",
    "        outputs.append(int(y.argmax(dim=1).reshape(1)))\n",
    "    \n",
    "    return ''.join([vocab.idx_to_token[i] for i in outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "statutory-circumstances",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'time<unk>t<unk>a<unk>e<unk><unk>e<unk><unk>poorifonplaceshorttogethertowardssocietyowncivility'"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_ch8('time traveller ', 10, net, vocab, torch.device('cuda'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
