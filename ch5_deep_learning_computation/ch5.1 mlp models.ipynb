{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "social-condition",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0267, -0.1398, -0.1535,  0.2704, -0.1317, -0.0803,  0.1115, -0.1180,\n",
       "         -0.0575,  0.0261],\n",
       "        [-0.1520, -0.0102, -0.0867,  0.2081,  0.0496, -0.0767,  0.1521,  0.0031,\n",
       "          0.0163, -0.0364]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "net = nn.Sequential(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))\n",
    "\n",
    "X = torch.rand(2, 20)\n",
    "net(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "compact-robertson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0267, -0.1398, -0.1535,  0.2704, -0.1317, -0.0803,  0.1115, -0.1180,\n",
       "         -0.0575,  0.0261],\n",
       "        [-0.1520, -0.0102, -0.0867,  0.2081,  0.0496, -0.0767,  0.1521,  0.0031,\n",
       "          0.0163, -0.0364]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.__call__(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "devoted-reception",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional as F\n",
    "class mlp(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.hidden = nn.Linear(20,256)\n",
    "        self.out = nn.Linear(256, 10)\n",
    "    \n",
    "    def forward(self,X):\n",
    "        ou = self.hidden(X)\n",
    "        ou = F.relu(ou)\n",
    "        return self.out(ou)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "controlling-editing",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0974, -0.0831, -0.0361,  0.2019, -0.0806,  0.1315, -0.0562,  0.0412,\n",
       "          0.1765, -0.1411],\n",
       "        [-0.0278, -0.1247, -0.1779,  0.1820, -0.0789,  0.0394,  0.0219,  0.1239,\n",
       "          0.1645, -0.1352]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = mlp()\n",
    "\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "protecting-shoot",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sequential_mlp(nn.Module):\n",
    "    def __init__(self, *args):\n",
    "        super().__init__()\n",
    "        for idx, module in enumerate(args):\n",
    "            self._modules[idx] = module\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for block in self._modules.values():\n",
    "            X = block(X)\n",
    "        return X\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dense-enough",
   "metadata": {},
   "outputs": [],
   "source": [
    "net =  Sequential_mlp(nn.Linear(20, 256), nn.ReLU(), nn.Linear(256, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "capital-camcorder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.1608,  0.0721, -0.1787,  0.1526,  0.0990,  0.1479, -0.0612, -0.0483,\n",
       "           0.1327,  0.2173],\n",
       "         [-0.0300,  0.1611, -0.1256,  0.1131,  0.0620,  0.1523, -0.0266,  0.0035,\n",
       "           0.0300,  0.1187]], grad_fn=<AddmmBackward>),\n",
       " torch.Size([2, 10]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X), net(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ordinary-attachment",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using constant parameters\n",
    "class FixedHiddenMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.rand_weight = torch.rand((20,20), requires_grad=False)\n",
    "        self.Linear = nn.Linear(20,20)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.Linear(X)\n",
    "        \n",
    "        X = F.relu(torch.mm(X, self.rand_weight) + 1)\n",
    "        \n",
    "        X = self.Linear(X)\n",
    "        \n",
    "        while X.abs().sum() > 1:\n",
    "            X /= 2\n",
    "        return X.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "compliant-input",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = FixedHiddenMLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "worst-enough",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0882, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "disciplinary-genome",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NestMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(nn.Linear(20,64),nn.ReLU(), nn.Linear(64,32), nn.ReLU())\n",
    "        self.linear = nn.Linear(32,16)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.linear(self.net(X))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "underlying-italian",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(-0.0221, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = nn.Sequential(NestMLP(), nn.Linear(16,20), FixedHiddenMLP())\n",
    "net(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medium-mission",
   "metadata": {},
   "source": [
    "Exercises\n",
    "1. What kinds of problems will occur if you change MySequential to store blocks in a Python\n",
    "list?\n",
    "\n",
    "* Whats MySequential\n",
    "\n",
    "2. Implement a block that takes two blocks as an argument, say net1 and net2 and returns\n",
    "the concatenated output of both networks in the forward propagation. This is also called a\n",
    "parallel block.\n",
    "\n",
    "* okayy\n",
    "\n",
    "3. Assume that you want to concatenate multiple instances of the same network. Implement\n",
    "a factory function that generates multiple instances of the same block and build a larger\n",
    "network from it.\n",
    "\n",
    "* hmm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "valued-mystery",
   "metadata": {},
   "outputs": [],
   "source": [
    "net1 = NestMLP()\n",
    "net2 = NestMLP()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "awful-delight",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.2302, -0.0296, -0.0628,  0.1758, -0.0982, -0.2383,  0.1589, -0.0850,\n",
       "           0.0350,  0.0720,  0.0218, -0.0485,  0.1184,  0.1400,  0.1794,  0.0982],\n",
       "         [-0.2164, -0.0383, -0.0141,  0.1605, -0.1239, -0.2609,  0.2106, -0.0793,\n",
       "           0.0125,  0.0606, -0.0071, -0.0718,  0.1286,  0.1397,  0.1545,  0.0735]],\n",
       "        grad_fn=<AddmmBackward>),\n",
       " tensor([[-0.0945,  0.2564,  0.0341, -0.1094, -0.1193, -0.0155,  0.1945,  0.0521,\n",
       "          -0.0302,  0.1418, -0.0156, -0.0660, -0.1055,  0.1927, -0.0262, -0.0785],\n",
       "         [-0.0649,  0.1984, -0.0085, -0.1119, -0.1481,  0.0093,  0.2208,  0.0252,\n",
       "          -0.0319,  0.0775, -0.0511, -0.0918, -0.0681,  0.1275, -0.0444, -0.0251]],\n",
       "        grad_fn=<AddmmBackward>))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net1(X),net2(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "expected-field",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2\n",
    "\n",
    "class parallel_mlp(nn.Module):\n",
    "    def __init__(self, block1, block2):\n",
    "        super().__init__()\n",
    "        self.block1 = block1\n",
    "        self.block2 = block2\n",
    "\n",
    "    def forward(self, X):\n",
    "        first = self.block1(X)\n",
    "        second = self.block2(X)\n",
    "        print(first, second)\n",
    "        return torch.cat((first, second))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "explicit-hebrew",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = parallel_mlp(net1, net2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "industrial-oxygen",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.2302, -0.0296, -0.0628,  0.1758, -0.0982, -0.2383,  0.1589, -0.0850,\n",
      "          0.0350,  0.0720,  0.0218, -0.0485,  0.1184,  0.1400,  0.1794,  0.0982],\n",
      "        [-0.2164, -0.0383, -0.0141,  0.1605, -0.1239, -0.2609,  0.2106, -0.0793,\n",
      "          0.0125,  0.0606, -0.0071, -0.0718,  0.1286,  0.1397,  0.1545,  0.0735]],\n",
      "       grad_fn=<AddmmBackward>) tensor([[-0.0945,  0.2564,  0.0341, -0.1094, -0.1193, -0.0155,  0.1945,  0.0521,\n",
      "         -0.0302,  0.1418, -0.0156, -0.0660, -0.1055,  0.1927, -0.0262, -0.0785],\n",
      "        [-0.0649,  0.1984, -0.0085, -0.1119, -0.1481,  0.0093,  0.2208,  0.0252,\n",
      "         -0.0319,  0.0775, -0.0511, -0.0918, -0.0681,  0.1275, -0.0444, -0.0251]],\n",
      "       grad_fn=<AddmmBackward>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[-0.2302, -0.0296, -0.0628,  0.1758, -0.0982, -0.2383,  0.1589, -0.0850,\n",
       "          0.0350,  0.0720,  0.0218, -0.0485,  0.1184,  0.1400,  0.1794,  0.0982],\n",
       "        [-0.2164, -0.0383, -0.0141,  0.1605, -0.1239, -0.2609,  0.2106, -0.0793,\n",
       "          0.0125,  0.0606, -0.0071, -0.0718,  0.1286,  0.1397,  0.1545,  0.0735],\n",
       "        [-0.0945,  0.2564,  0.0341, -0.1094, -0.1193, -0.0155,  0.1945,  0.0521,\n",
       "         -0.0302,  0.1418, -0.0156, -0.0660, -0.1055,  0.1927, -0.0262, -0.0785],\n",
       "        [-0.0649,  0.1984, -0.0085, -0.1119, -0.1481,  0.0093,  0.2208,  0.0252,\n",
       "         -0.0319,  0.0775, -0.0511, -0.0918, -0.0681,  0.1275, -0.0444, -0.0251]],\n",
       "       grad_fn=<CatBackward>)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "reverse-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "class hydra(nn.Module):\n",
    "    def __init__(self, module, mutation_number):\n",
    "        super().__init__()\n",
    "        self.block = module\n",
    "        self.m_n = mutation_number\n",
    "        self.linear = nn.Linear(16, 20)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        for i in range(self.m_n):\n",
    "            X = self.block(X)\n",
    "            X = self.linear(X) \n",
    "        \n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "functioning-therapist",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = hydra(net1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "cheap-hawaii",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0164, -0.2997, -0.1305,  0.1128, -0.0724, -0.1320, -0.1583, -0.1120,\n",
       "         -0.1174,  0.0622,  0.0573,  0.2024,  0.0312,  0.1781,  0.2409, -0.0051,\n",
       "          0.2348, -0.1194,  0.1917, -0.0742],\n",
       "        [-0.0163, -0.2997, -0.1305,  0.1127, -0.0723, -0.1321, -0.1583, -0.1121,\n",
       "         -0.1174,  0.0622,  0.0572,  0.2024,  0.0312,  0.1781,  0.2409, -0.0051,\n",
       "          0.2348, -0.1193,  0.1917, -0.0742]], grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
